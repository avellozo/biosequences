%TODO exemplos, figuras
%TODO considerar \romega(j',j)
%TODO repetições inexatas
%TODO restrições dos modelos

\documentclass[12pt,openright,twoside,fleqn]{report}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[brazil]{babel} 
\usepackage[latin1]{inputenc} 
\usepackage[normalem]{ulem} 
\usepackage[portuguese]{alg}
\usepackage{graphicx,color}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage{subfigure}
\usepackage{hyperref}
\usepackage{ntheorem}

%\usepackage[portuguese]{alg}
%\usepackage{alg}
% \usepackage{alg}
%% %% \usepackage[boxed,chapter]{algorithm}
%% %% \renewcommand{\listalgorithmname}{Lista de Algoritmos}
%% %% \floatname{algorithm}{Algoritmo}
\usepackage{float}
%%\floatstyle{boxed}
\floatstyle{ruled}
\newfloat{algorithm}{htbp}{loa}%[chapter]
\newcommand{\listofalgorithms}{\listof{algorithm}{Lista de Algoritmos}}
\floatname{algorithm}{Algoritmo} 
 
%layout
%\renewcommand{\baselinestretch}{1.7}

% % Para controlar diferentes versões
% % getting the time and using it via \now
% \newcount\hour
% \newcount\minute
% \hour=\time \divide \hour by 60 \minute=\time \loop \ifnum \minute
% > 59 \advance \minute by -60 \repeat
% \def\now{%
% \ifnum \hour<13 \ifnum \hour<1 12:\else\number\hour:\fi \ifnum
% \minute<10 0\fi
% \number\minute%
% %\ifnum \hour<12 \ AM \else \ PM \fi
% \else \advance \hour by -12 \number\hour:%
% \ifnum \minute<10 0\fi
% \number\minute%
% %\ PM%
% \fi%
% }
% \let\oldthepage=\thepage
% \renewcommand{\thepage}{\today{} \now \qquad (\oldthepage)}
% 
%Teoremas, Lemas, etc.
\newtheorem{teorema}{Teorema}[chapter]
\newtheorem{lema}[teorema]{Lema}
\newtheorem{proposicao}[teorema]{Proposição}
\newtheorem{observacao}[teorema]{Observação}
\newtheorem{corolario}[teorema]{Corolário}
\newtheorem{definicao}[teorema]{Definição}
\newtheorem{exemplo}[teorema]{Exemplo}
\newtheorem{problema}[teorema]{Problema}

\newenvironment{prova}[1][Prova.]{\begin{trivlist}
\item[\hskip \labelsep {\itshape #1}]}{\end{trivlist}}
% \newenvironment{definicao}[1][Definição]{\begin{trivlist}
% \item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
% \newenvironment{problema}[1][Problema]{\begin{trivlist}
% \item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
% % \newenvironment{exemplo}[1][Exemplo]{\begin{trivlist}
% % \item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{comentario}[1][Comentário]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\cqd}{\nobreak \ifvmode \relax \else \ifdim\lastskip<1.5em
\hskip-\lastskip \hskip1.5em plus0em minus0.5em \fi \nobreak \vrule
height0.75em width0.5em depth0.25em\fi}
\newcommand{\tq}{\mathrel{|}}
\newcommand{\invert}[1]{\mathord{\overline{{#1}}}}
\newcommand{\invertsym}{\mathord{\overline{\ \ {\vspace{3 mm}}}}}
\newcommand{\aplica}{\longrightarrow}              
\newcommand{\implica}{\Longrightarrow}   
\newcommand{\sse}{\Longleftrightarrow}   
\newcommand{\natset}{\ensuremath{\mathbb{N}}}
\newcommand{\intset}{\ensuremath{\mathbb{Z}}}
\newcommand{\realset}{\ensuremath{\mathbb{R}}}
\newcommand{\tabenum}{\hspace{20 pt}}

%alfabeto das seqeuncias
\newcommand{\alfabeto}{\Sigma}
%alfabeto de um alinhamento simples
\newcommand{\alfabetoaligngap}{\alfabeto'}

% símbolos das operações
\newcommand{\opedsym}{\ensuremath{\gamma}}

\newcommand{\opedseqsym}{\ensuremath{\Psi}}

%operação composta
\newcommand{\opedcompsym}[1]{\ensuremath{\phi_{#1}}}

%operaçao de inserção
\newcommand{\opedinssym}[2]{\ensuremath{\iota_{#1,#2}}}

%operaçao de remoção
\newcommand{\opeddelsym}[2]{\ensuremath{\rho_{#1,#2}}}

%operaçao de substituição
\newcommand{\opedsubsym}[3]{\ensuremath{\sigma_{#1,#2,#3}}}

%operaçao de inversão
\newcommand{\opedinvsym}[2]{\ensuremath{\pi_{#1,#2}}}

%operaçao de duplicação
\newcommand{\opeddupsym}[3]{\ensuremath{\delta_{#1,#2,#3}}}

%operaçao de excisão
\newcommand{\opedexcsym}[3]{\ensuremath{\varepsilon_{#1,#2,#3}}}

% Conjunto das \opeds 
\newcommand{\opedset}{\ensuremath{\Gamma}}

% Conjunto das \opeds pontuais
\newcommand{\opedpontset}{\ensuremath{\opedset_P}}

% Conjunto das \opeds de inversao
\newcommand{\opedinvset}{\ensuremath{\widehat{\opedset}}}

%peso para a oped de inversão
\newcommand{\opedweiginv}{\ensuremath{\omega_{inv}}}

%pontuação para uma oped 
\newcommand{\opedweigsym}{\ensuremath{\omega_{op}}}

%concatenação de duas opeds
\newcommand{\opedconcat}{\cdot}




% Grafo de edição
% vértice inicial de uma aresta
\newcommand{\startedge}[1]{\ensuremath{\textrm{start}(#1)}}
% vértice final de uma aresta
\newcommand{\finishedge}[1]{\ensuremath{\textrm{end}(#1)}}
%linha do 'vertice v
\newcommand{\egrowv}[1]{\ensuremath{\textrm{row}(#1)}}
%coluna do 'vertice v
\newcommand{\egcolv}[1]{\ensuremath{\textrm{col}(#1)}}

%conjunto dos caminhos de um grafo de edição de u a v
\newcommand{\egpathset}[2]{\ensuremath{\Pi_{#1,#2}}}

%conjunto dos caminhos de um grafo de edição de u a v
\newcommand{\egepathset}[2]{\ensuremath{\widehat{\Pi}_{#1,#2}}}

% aresta qualquer
\newcommand{\egesym}{\ensuremath{\epsilon}}

% aresta horizontal
\newcommand{\egeh}[1]{\ensuremath{\egesym_H^{#1}}}

% aresta vertical
\newcommand{\egev}[1]{\ensuremath{\egesym_V^{#1}}}

% aresta diagonal
\newcommand{\eged}[1]{\ensuremath{\egesym_D^{#1}}}

% aresta estendida
\newcommand{\egex}[2]{\ensuremath{\egesym_{#1}^{#2}}}

% função peso weight
\newcommand{\egweigsym}{\ensuremath{\omega}}

% peso de uma aresta
\newcommand{\egweige}[1]{\ensuremath{\egweigsym(#1)}}

% peso de uma caminho
\newcommand{\egweigp}[2]{\ensuremath{\egweigsym(#1,#2)}}

% aresta qualquer gred estendido para inversao
\newcommand{\egesymi}{\ensuremath{\overline{\epsilon}}}

% aresta horizontal gred estendido para inversao
\newcommand{\egehi}[1]{\ensuremath{\egesymi_H^{#1}}}

% aresta vertical gred estendido para inversao
\newcommand{\egevi}[1]{\ensuremath{\egesymi_V^{#1}}}

% aresta diagonal gred estendido para inversao
\newcommand{\egedi}[1]{\ensuremath{\egesymi_D^{#1}}}

% aresta estendida gred estendido para inversao
\newcommand{\egexi}[2]{\ensuremath{\egesymi_{#1}^{#2}}}

% função peso weight gred estendido para inversao
\newcommand{\egweigsymi}{\ensuremath{\overline{\omega}}}

% peso de uma aresta gred estendido para inversao
\newcommand{\egweigei}[1]{\ensuremath{\egweigsymi(#1)}}

% peso de uma caminho gred estendido para inversao
\newcommand{\egweigpi}[2]{\ensuremath{\egweigsymi(#1,#2)}}

%função que associa uma aresta de um \gred\ estendido a uma \oped
\newcommand{\egeopedinvsym}[1]{\ensuremath{\widehat{\textrm{op}}}}

%função que troca os índices de uma oped em \overline{G} para a oped em G
\newcommand{\eginvert}[1]{\ensuremath{\textrm{add}_{#1}}}


% gap em um alinhamento
\newcommand{\aligngap}{\ensuremath{-}}

% gap em um alinhamento com inversões
\newcommand{\aligngapi}{\ensuremath{\_}}

% gap em um alinhamento com inversões
\newcommand{\aligngapd}{\ensuremath{-}}

% prefixo de s ou t contido até a coluna k de um alinhamento A
\newcommand{\alignprefixsym}{\ensuremath{\textrm{pref}}}
\newcommand{\alignprefix}[3]{\ensuremath{\alignprefixsym(#1, #2, #3)}}

% função score de um alinhamento
\newcommand{\alignscore}{\ensuremath{\varphi}}

%Conjunto dos alinhamentos de quaisquer s e t
\newcommand{\alignset}{\ensuremath{\Lambda}}

%Conjunto dos alinhamentos com inv de quaisquer s e t
\newcommand{\alignseti}{\ensuremath{\widehat{\Lambda}}}

%Conjunto dos alinhamentos com inv de quaisquer s e t
\newcommand{\alignsetd}{\ensuremath{\Lambda_D}}

%Conjunto dos alinhamentos de s e t
\newcommand{\alignsetst}[2]{\ensuremath{\alignset_{#1,#2}}}

%Conjunto dos alinhamentos de s
\newcommand{\alignsets}[1]{\ensuremath{\alignset_{#1}}}

%Função coluna de s[i]
\newcommand{\aligncolsym}{\ensuremath{\textrm{col}}}
\newcommand{\aligncol}[3]{\ensuremath{\aligncolsym(#1,#2,#3)}}

%Função que associa uma coluna de A a uma \oped
\newcommand{\alignopedsym}{\ensuremath{\textrm{op}}}
\newcommand{\alignoped}[2]{\ensuremath{\alignopedsym(#1,#2)}}

%Função que associa uma coluna de A a uma aresta
\newcommand{\alignedgesym}{\ensuremath{\textrm{edge}}}
\newcommand{\alignedge}[2]{\ensuremath{\alignedgesym(#1,$ $#2)}}

%Função que associa uma coluna de A_inv a uma aresta num gred estendido
\newcommand{\alignedgeinvsym}{\ensuremath{\textrm{edge}}}
\newcommand{\alignedgeinv}[2]{\ensuremath{\alignedgesym(#1, #2)}}

%Função que associa uma coluna de A a uma \oped
\newcommand{\alignpathsym}{\ensuremath{\textrm{path}}}
\newcommand{\alignpath}[1]{\ensuremath{\alignpathsym(#1)}}

%símbolo de um alinhamento 
\newcommand{\alignsym}{\ensuremath{A}}

%símbolo de um alinhamento com inversoes nao sobrepostas
\newcommand{\aligninvsym}{\ensuremath{A}}

%símbolo de um alinhamento com duplicacaoes
\newcommand{\aligndupsym}{\ensuremath{A}}
\newcommand{\aligndupdirectsym}{\ensuremath{+}}
\newcommand{\aligndupinicdupsym}{\ensuremath{!}}
\newcommand{\aligndupextdupsym}{\ensuremath{\#}}

%conjunto com os símbolos s1,s2,\ldots,sn e t1,t2,\ldots,tm
\newcommand{\aligndupsetgapdupsym}{\ensuremath{\Upsilon}}

%função que associa uma caminho num \gred estendido a uma \seq\ de opeds
\newcommand{\aligninvfunc}{\ensuremath{\textrm{transf}}}

%Função que associa uma coluna de um \aligninvsym a um símbolo
\newcommand{\alignsimbsym}{\ensuremath{\textrm{simb}}}
\newcommand{\alignsimb}[3]{\ensuremath{\alignsimbsym(#1, #2, #3)}}

%Função que associa uma coluna de um \aligninvsym a um símbolo
\newcommand{\aligndsimbsym}{\ensuremath{\textrm{simb}}}
\newcommand{\aligndsimb}[3]{\ensuremath{\aligndsimbsym(#1, #2, #3)}}

%função que associa uma coluna de um alinh com \invnsobs a uma\oped
\newcommand{\alignopedinvsym}{\ensuremath{\textrm{opi}}}
\newcommand{\alignopedinv}[2]{\alignopedinvsym(#1,#2)}

%função que retorna o final de um bloco em um alinh \invnsobs
\newcommand{\alingblockinvsym}{\ensuremath{\textrm{end}}}
\newcommand{\alingblockinv}[2]{\alingblockinvsym(#1,#2)}

%transformação de A pela função opi
\newcommand{\tranfbyopisym}{\ensuremath{\opedseqsym_{\alignopedinvsym}^{\aligninvsym}}}
\newcommand{\tranfoptimumbyopisym}{\ensuremath{\opedseqsym_{\alignopedinvsym}^{\aligninvoptimumsym}}}

\newcommand{\alignimaxind}{\ensuremath{\textrm{maxi}}}
\newcommand{\aligniminind}{\ensuremath{\textrm{mini}}}

%pontuação de um alinhamento com inv nao sobrepostas
\newcommand{\aligninvscoresym}{\ensuremath{\omega^{\aligninvsym}}}
\newcommand{\aligninvoptimumsym}{\ensuremath{\aligninvsym^*}}
\newcommand{\aligninvoptimumscoresym}{\ensuremath{\omega^{\aligninvoptimumsym}}}

%pontuação de um alinhamento com dups
\newcommand{\aligndupscoresym}{\ensuremath{\omega^{\aligndupsym}}}
\newcommand{\aligndupoptimumsym}{\ensuremath{\aligndupsym^*}}
\newcommand{\aligndupoptimumscoresym}{\ensuremath{\omega^{\aligndupoptimumsym}}}

\newcommand{\aligndupoptscore}[2]{\ensuremath{\omega_D(#1,#2)}}
\newcommand{\aligndupoptscorest}[6]{\ensuremath{\aligndupoptscore{#1[#3\Rng #4]}{#2[#5\Rng #6]}}}
\newcommand{\alignoptscore}[2]{\ensuremath{\omega^*(#1,#2)}}
\newcommand{\alignoptscorest}[6]{\ensuremath{\alignoptscore{#1[#3\Rng #4]}{#2[#5\Rng #6]}}}
\newcommand{\alignoptlocscore}[2]{\ensuremath{\omega_L(#1,#2)}}
\newcommand{\alignoptlocscorest}[6]{\ensuremath{\alignoptlocscore{#1[#3\Rng #4]}{#2[#5\Rng #6]}}}
\newcommand{\vomega}[2]{\ensuremath{\omega_v(#1[#2])}}
\newcommand{\homega}[2]{\ensuremath{\omega_h(#1[#2])}}
\newcommand{\domega}[4]{\ensuremath{\omega_d(#1[#3],#2[#4])}}
\newcommand{\vomegad}[2]{\ensuremath{\omega_v(#1[#2])}}
\newcommand{\homegad}[2]{\ensuremath{\omega_h(#1[#2])}}
\newcommand{\domegad}[4]{\ensuremath{\omega_d(#1[#3],#2[#4])}}
\newcommand{\xomega}[3]{\ensuremath{\omega_x(#1[#2 \Rng #3])}}
\newcommand{\uomega}[3]{\ensuremath{\omega_u(#1[#2 \Rng #3])}}
\newcommand{\romega}{\ensuremath{\omega_r}}

%conjunto com os símbolos s1,s2,\ldots,sn e t1,t2,\ldots,tm
\newcommand{\aligndupsetbase}[3]{\ensuremath{\Sigma_{base}^{#1,#2,#3}}}

%Função de exclusão de símbolos de uma \seq\
\newcommand{\excludefunc}{\ensuremath{\textrm{exclude}}}

%grafo das duplicações de um alinhamento com duplicações
\newcommand{\graphdup}[1]{\ensuremath{G_{#1}}}

%função com peso máximo de um intrep
\newcommand{\dupwsym}{\ensuremath{\textrm{dup}}}
\newcommand{\dupw}[3]{\ensuremath{\dupwsym(#1,#2,#3)}}

%função com peso máximo de um intrep em tandem
\newcommand{\dupwtsym}{\ensuremath{\textrm{dupt}}}
\newcommand{\dupwt}[5]{\ensuremath{\dupwtsym(#1,#2,#3,#4,#5)}}


%Matriz W
\newcommand{\matw}[3]{\ensuremath{W_{#1}^{#2,#3}}}

%função hdif, vdif e ddif
\newcommand{\diffunc}[5]{\ensuremath{{#1}((#2,#3),(#4,#5))}}
\newcommand{\difvec}[4]{\ensuremath{{#1}^{#2,#3,#4}}}

\newcommand{\hdifsym}[1]{\ensuremath{\textrm{hDif}_{#1}}}
\newcommand{\hdiffunc}[5]{\diffunc{\hdifsym{#1}}{#2}{#3}{#4}{#5}}
\newcommand{\hdifvec}[4]{\difvec{\hdifsym{#1}}{#2}{#3}{#4}}

\newcommand{\vdifsym}[1]{\ensuremath{\textrm{vDif}_{#1}}}
\newcommand{\vdiffunc}[5]{\diffunc{\vdifsym{#1}}{#2}{#3}{#4}{#5}}
\newcommand{\vdifvec}[4]{\difvec{\vdifsym{#1}}{#2}{#3}{#4}}

\newcommand{\ddifsym}[1]{\ensuremath{\textrm{dDif}_{#1}}}
\newcommand{\ddiffunc}[5]{\diffunc{\ddifsym{#1}}{#2}{#3}{#4}{#5}}
\newcommand{\ddifvec}[4]{\difvec{\ddifsym{#1}}{#2}{#3}{#4}}

%Árvore com os valores de pesos de caminhos ótimos
\newcommand{\arvb}[4]{B_{#1}^{#2,#3,#4}}

%Função Out para o alg n3
\newcommand{\outsym}[1]{\ensuremath{\textrm{out}}}
\newcommand{\outfunc}[5]{\ensuremath{\outsym{#1}((#2,#3),(#4,#5))}}
\newcommand{\outvec}[4]{\ensuremath{\outsym{#1}^{#2,(#3,#4)}}}
\newcommand{\outlist}[1]{\ensuremath{Out_{#1}}}
\newcommand{\cl}[1]{\ensuremath{CL_{#1}}}

%Função difOut para o alg n3
\newcommand{\difoutsym}[1]{\ensuremath{\Delta \textrm{out}_{#1}}}
\newcommand{\difoutfunc}[5]{\ensuremath{\difoutsym{#1}((#2,#3),(#4,#5))}}
\newcommand{\difoutvec}[1]{\ensuremath{\Delta OUT_{#1}}}

%Função psi para o alg n3
\newcommand{\psihsym}[1]{\ensuremath{\psi_{#1}}}
\newcommand{\psihfunc}[4]{\ensuremath{\psihsym{#1}(#2,#3,#4)}}

%borderline
% \newcommand{\blhsym}[1]{\ensuremath{bl_{#1}}}
% \newcommand{\blhfunc}[5]{\ensuremath{\blhsym{#1}(#2,(#3,#4),#5)}}
\newcommand{\blhvec}[4]{\ensuremath{BL_{#1}^{#2,#3,#4}}}
\newcommand{\blhdeltavec}[1]{\ensuremath{\Delta BL_{#1}}}



\newcommand{\inv}{in\-ver\-são}
\newcommand{\invs}{in\-ver\-sões}
\newcommand{\invnsob}{\inv\ não so\-bre\-pos\-ta}
\newcommand{\invnsobs}{\invs\ não so\-bre\-pos\-tas}
\newcommand{\oped}{o\-pe\-ra\-ção de e\-di\-ção}
\newcommand{\opeds}{o\-pe\-ra\-ções de e\-di\-ção}
\newcommand{\Oped}{O\-pe\-ra\-ção de e\-di\-ção}
\newcommand{\Opeds}{O\-pe\-ra\-ções de e\-di\-ção}
\newcommand{\seq}{se\-qüên\-cia}
\newcommand{\seqs}{se\-qüên\-cias}
\newcommand{\Seq}{Se\-qüên\-cia}
\newcommand{\Seqs}{Se\-qüên\-cias}
\newcommand{\bio}{bio\-ló\-gi\-co}
\newcommand{\bioa}{bio\-ló\-gi\-ca}
\newcommand{\bios}{bio\-ló\-gi\-cos}
\newcommand{\bioas}{bio\-ló\-gi\-cas}
\newcommand{\gred}{grafo de e\-di\-ção}
\newcommand{\greds}{grafos de e\-di\-ção}
\newcommand{\gredes}{grafo de e\-di\-ção estendido}
\newcommand{\gredess}{grafos de e\-di\-ção estendido}
\newcommand{\dup}{du\-pli\-ca\-ção}
\newcommand{\dups}{du\-pli\-ca\-ções}
\newcommand{\rep}{re\-pe\-ti\-ção}
\newcommand{\reps}{re\-pe\-ti\-ções}
\newcommand{\intrep}{intervalo de \rep}
\newcommand{\intreps}{intervalos de \rep}


\newcommand{\seqbaseLetter}{\ensuremath{x}}
\newcommand{\seqbase}[3]{\ensuremath{\seqbaseLetter(#1,#2,#3)}}
\newcommand{\seqbasei}[5]{\ensuremath{\seqbaseLetter_{#1[#3]}(#2[#4\Rng #5])}}
\newcommand{\dupi}[5]{\ensuremath{\omega_{#2|#1}(#3,#4,#5)}}
\newcommand{\wts}[2]{\ensuremath{W_{#2|#1}}}
\newcommand{\wdupi}[5]{\ensuremath{\wts{#1}{#2}[#3,#4,#5]}}
\newcommand{\bestScoreA}[3]{\ensuremath{\omega_{#1}^{A}(#2,#3)}}
\newcommand{\bestScoreB}[3]{\ensuremath{\omega_{#1}^{B}(#2,#3)}}
\newcommand{\bestScoreC}[3]{\ensuremath{\omega_{#1}^{C}(#2,#3)}}
\newcommand{\bestScoreD}[4]{\ensuremath{\omega_{#1|#2}^{D}(#3,#4)}}
\newcommand{\bestScoreE}[3]{\ensuremath{\omega_{#1}^{E}(#2,#3)}}
\newcommand{\bestScoreF}[5]{\ensuremath{\omega_{#1|#4}^{F}(#2,#3,#5)}}
\newcommand{\setA}[3]{\ensuremath{A_{#1}^{#2,#3}}}
\newcommand{\setB}[3]{\ensuremath{B_{#1}^{#2,#3}}}
\newcommand{\setC}[3]{\ensuremath{C_{#1}^{#2,#3}}}
\newcommand{\setD}[1]{\ensuremath{D_{#1}}}
\newcommand{\setE}[2]{\ensuremath{E^{#1,#2}}}

\newcommand{\wbestScore}[1]{\ensuremath{W_{#1}}}
\newcommand{\wbestScoreAjm}[1]{\ensuremath{\wbestScore{#1}^{A}}}
\newcommand{\wbestScoreAj}[4]{\ensuremath{\wbestScoreAjm{#1}[#2,#3,#4]}}
\newcommand{\wbestScoreBjm}[1]{\ensuremath{\wbestScore{#1}^{B}}}
\newcommand{\wbestScoreBj}[4]{\ensuremath{\wbestScoreBjm{#1}[#2,#3,#4]}}
\newcommand{\wbestScoreCjm}[1]{\ensuremath{\wbestScore{#1}^{C1}}}
\newcommand{\wbestScoreCj}[3]{\ensuremath{\wbestScoreCjm{#1}[#2,#3]}}
\newcommand{\wbestScoreCjjm}[1]{\ensuremath{\wbestScore{#1}^{C2}}}
\newcommand{\wbestScoreCjj}[3]{\ensuremath{\wbestScoreCjjm{#1}[#2,#3]}}
\newcommand{\wbestScoreDjm}[2]{\ensuremath{\wbestScore{#1|#2}^{D}}}
\newcommand{\wbestScoreDj}[5]{\ensuremath{\wbestScoreDjm{#1}{#2}[#3,#4,#5]}}
\newcommand{\wbestScoreEjm}[1]{\ensuremath{\wbestScore{#1}^{E}}}
\newcommand{\wbestScoreEj}[4]{\ensuremath{\wbestScoreEjm{#1}[#2,#3,#4]}}
\newcommand{\wbestScoreFjm}[2]{\ensuremath{\wbestScore{#1|#2}^{F}}}
\newcommand{\wbestScoreFj}[5]{\ensuremath{\wbestScoreFjm{#1}{#4}[#2,#3,#5]}}

\newcommand{\wbestScorem}[1]{\ensuremath{\widehat{#1}}}
\newcommand{\wbestScoreAm}[1]{\ensuremath{\wbestScorem{\wbestScoreAjm{#1}}}}
\newcommand{\wbestScoreA}[3]{\ensuremath{\wbestScoreAm{#1}[#2,#3]}}
\newcommand{\wbestScoreBm}[1]{\ensuremath{\wbestScorem{\wbestScoreBjm{#1}}}}
\newcommand{\wbestScoreB}[3]{\ensuremath{\wbestScoreBm{#1}[#2,#3]}}
\newcommand{\wbestScoreCm}[1]{\ensuremath{\wbestScorem{\wbestScore{#1}^{C}}}}
\newcommand{\wbestScoreC}[3]{\ensuremath{\wbestScoreCm{#1}[#2,#3]}}
\newcommand{\wbestScoreDm}[2]{\ensuremath{\wbestScorem{\wbestScoreDjm{#1}{#2}}}}
\newcommand{\wbestScoreD}[4]{\ensuremath{\wbestScoreDm{#1}{#2}[#3,#4]}}
\newcommand{\wbestScoreEm}[1]{\ensuremath{\wbestScorem{\wbestScoreEjm{#1}}}}
\newcommand{\wbestScoreE}[3]{\ensuremath{\wbestScoreEm{#1}[#2,#3]}}
\newcommand{\wbestScoreFm}[2]{\ensuremath{\wbestScorem{\wbestScoreFjm{#1}{#2}}}}
\newcommand{\wbestScoreF}[5]{\ensuremath{\wbestScoreFm{#1}{#4}[#2,#3,#5]}}

% \newcommand{\fmia}[7]{\ensuremath{\delta_{m1}(#1,#2,#3,#4,#5,#6,#7)}}
% \newcommand{\fmiia}[4]{\ensuremath{\omega_{#1}^{#4}(#2,#3)}}
% \newcommand{\fmii}[3]{\ensuremath{\omega_{#1}(#2,#3)}}
% \newcommand{\fmiiia}[4]{\ensuremath{\omega_{#1}^{#4}(#2,#3)}}
% \newcommand{\fmiii}[3]{\ensuremath{\omega_{#1}(#2,#3)}}
% \newcommand{\fmiv}[6]{\ensuremath{\omega_{#2|#1}^{#3}(#4,#5,#6)}}
% \newcommand{\fmiva}[6]{\ensuremath{\underline{\omega_{#2|#1}^{#3}}(#4,#5,#6)}}
% \newcommand{\fmivb}[6]{\ensuremath{\overline{\omega_{#2|#1}^{#3}}(#4,#5,#6)}}
% \newcommand{\maxnew}[3]{\ensuremath{\max\left\{#3\textrm{; }\forall #1 \tq #2\right\}}}
\newcommand{\maxnew}[3]{\ensuremath{\max_{\forall #1 \tq #2}\left(#3\right)}}
%#1 variables, #2 restrictions and #3 expression           
\newcommand{\mtm}{\ensuremath{M_t}}
\newcommand{\msm}{\ensuremath{M_s}}
\newcommand{\mt}[2]{\ensuremath{\mtm[#1,#2]}}
\newcommand{\ms}[2]{\ensuremath{\msm[#1,#2]}}

\newcommand{\mtmtandem}{\ensuremath{M_t}}
\newcommand{\msmtandem}{\ensuremath{M_s}}
\newcommand{\mttandem}[2]{\ensuremath{\mtmtandem[#1,#2]}}
\newcommand{\mstandem}[2]{\ensuremath{\msmtandem[#1,#2]}}

\newcommand{\Wt}{\ensuremath{MAXW_t}}
\newcommand{\Wtold}{\ensuremath{W_t^{old}}}
\newcommand{\Ws}{\ensuremath{MAXW_s}}
\newcommand{\Wsold}{\ensuremath{W_s^{old}}}
\newcommand{\wt}[2]{\ensuremath{\Wt[#1,#2]}}
\newcommand{\wtold}[2]{\ensuremath{\Wtold[#1,#2]}}
\newcommand{\ws}[2]{\ensuremath{\Ws[#1,#2]}}
\newcommand{\wsold}[2]{\ensuremath{\Wsold[#1,#2]}}

\newcommand{\WA}{\wbestScoreAm{t}}
\newcommand{\WAj}{\wbestScoreAjm{t}^{,j'}}
\newcommand{\wA}[2]{\ensuremath{\WA[#1,#2]}}
\newcommand{\wAj}[2]{\ensuremath{\WAj[#1,#2]}}

\newcommand{\WB}{\wbestScoreBm{t}}
\newcommand{\WBj}{\wbestScoreBjm{t}^{,j}}
\newcommand{\wB}[2]{\ensuremath{\WB[#1,#2]}}
\newcommand{\wBj}[2]{\ensuremath{\WBj[#1,#2]}}

\newcommand{\WC}{\wbestScoreCm{t}}
\newcommand{\WCj}{\wbestScoreCjm{t}}
\newcommand{\WCjj}{\wbestScoreCjjm{t}}
\newcommand{\wC}[2]{\ensuremath{\WC[#1,#2]}}
\newcommand{\wCj}[2]{\ensuremath{\WCj[#1,#2]}}
\newcommand{\wCjj}[2]{\ensuremath{\WCjj[#1,#2]}}

\newcommand{\WD}{\wbestScoreDm{t}{s}}
\newcommand{\WDj}{\wbestScoreDjm{t}{s}^{,j'}}
\newcommand{\wD}[2]{\ensuremath{\WD[#1,#2]}}
\newcommand{\wDj}[2]{\ensuremath{\WDj[#1,#2]}}

\newcommand{\WE}[1]{\wbestScoreEm{#1}}
\newcommand{\WEj}{\wbestScoreEjm{t}^{,j'}}
\newcommand{\wE}[2]{\ensuremath{\WE{t}[#1,#2]}}
\newcommand{\wEj}[2]{\ensuremath{\WEj[#1,#2]}}

% \newcommand{\WF}{\wbestScoreFm{t}{s}}
% \newcommand{\wF}[2]{\ensuremath{\WF[#1,#2]}}
\newcommand{\WFi}[3]{\wbestScoreFjm{#1}{#2}^{,#3}}
\newcommand{\wFi}[5]{\ensuremath{\WFi{#1}{#2}{#3}[#4,#5]}}


% 
% \newcount\hour
% \newcount\minute
% \hour=\time \divide \hour by 60 \minute=\time \loop \ifnum \minute
% > 59 \advance \minute by -60 \repeat
% \def\now{%
% \ifnum \hour<13 \ifnum \hour<1 12:\else\number\hour:\fi \ifnum
% \minute<10 0\fi
% \number\minute%
% %\ifnum \hour<12 \ AM \else \ PM \fi
% \else \advance \hour by -12 \number\hour:%
% \ifnum \minute<10 0\fi
% \number\minute%
% %\ PM%
% \fi%
% }
% \let\oldthepage=\thepage
% \renewcommand{\thepage}{\today{} \now \qquad (\oldthepage)}

\DeclareTextFontCommand{\textcourier}{\fontfamily{pcr}\selectfont}

\title{Alinhamento de seqüências com inversões ou duplicações}
\author{Augusto Fernandes Vellozo}

\begin{document}

% \maketitle

% \begin{comment} 
% \begin{titlepage}

\thispagestyle{empty}
\begin{center}
% \vspace{10pt}
\linespread{0.8}
\begin{LARGE}
Alinhamento de \seqs \\ com \\  rearranjos

\end{LARGE}

\vspace{30pt}

\begin{Large}
Augusto Fernandes Vellozo
\end{Large}

\vspace{50pt}
\linespread{0.9}

\begin{Large}

TESE APRESENTADA \\ AO \\ INSTITUTO DE MATEMÁTICA E ESTATÍSTICA \\ DA \\
UNIVERSIDADE DE SÃO PAULO \\ PARA \\ OBTENÇÃO DO TÍTULO DE DOUTOR\\ EM \\ CIÊNCIAS

\end{Large}


\vspace{50pt}

\linespread{1}
\begin{Large}

Área de Concentração: Ciência da Computação

Orientador: Prof. Dr. Alair Pereira do Lago

\end{Large}

\vspace{30pt}
\end{center}
 \begin{small}
Durante a elaboração deste trabalho o autor recebeu~auxílio~financeiro~da~CAPES
 \end{small}
\begin{center}
\vspace{20pt}

São Paulo, março de 2007.

\end{center}

% \end{titlepage}
\newpage
\thispagestyle{empty}
\mbox{}
\newpage
\vspace{5pt}
\begin{center}
\textbf{\LARGE Resumo}
\end{center}

Uma das tarefas mais básicas em bioinformática é a comparação de \seqs\ feita
por algoritmos de alinhamento, que modelam as alterações evolutivas nas \seqs\
\bioas\ através de mutações como inserção, remoção e substituições de símbolos.
Este trabalho trata de generalizações nos algoritmos de alinhamento que levam em
consideração outras mutações conhecidas como rearranjos, mais especificamente,
inversões, \dups\ em \emph{tandem} e \dups\ por transposição.

Alinhamento com inversões não tem um algoritmo polinomial conhecido e uma 
simplificação para o problema que considera somente \invnsobs\ foi proposta em 
1992 por Schöniger e Waterman~\cite{pmid1591531}. Em 2003, trabalhos 
independentes propuseram algoritmos com tempo\footnote{Neste caso, $n$ denota o 
tamanho máximo dentre as duas \seqs\ a serem alinhadas.} 
$O(n^4)$~\cite{lago03:wob03,gao03:_space_effic_algor_sequen_align_inver,MR2132586} 
para alinhar duas \seqs\ com \invnsobs. Desenvolvemos dois algoritmos que 
resolvem este mesmo problema: um em tempo $O(n^3 \log n)$~\cite{MR2173809} e 
outro em tempo $O(n^3)$~\cite{vellozo06:_align_with_non_overl_inver}, ambos 
em memória $O(n^2)$.
  
  Em 1997, Benson propôs um modelo de alinhamento que reconhecesse também as 
  \dups\ em \emph{tandem}. Ele propôs dois algoritmos exatos para alinhar duas 
  \seqs\ com \dups\ em \emph{tandem}: um em tempo $O(n^5)$ e memória $O(n^2)$, 
  e outro em tempo $O(n^4)$ e memória $O(n^3)$. Propomos um algoritmo para 
  alinhar duas \seqs\ com \dups\ em \emph{tandem} em tempo $O(n^3)$ e memória 
  $O(n^2)$. Propomos também um algoritmo para alinhar duas \seqs\ com 
  \emph{transposons} (um tipo mais geral que a \dup\ em \emph{tandem}), em 
  tempo $O(n^3)$ e memória $O(n^2)$.

\newpage
\mbox{}
\newpage

\vspace{5pt}
\begin{center}
\textbf{\LARGE Abstract}
\end{center}

Sequence comparison done by alignment algorithms is one of the most fundamental 
tasks in bioinformatics. The evolutive mutations considered in these alignments 
are insertions, deletions and substitutions of nucleotides. This work treats of 
generalizations introduced in alignment algorithms in such a way that other 
mutations known as rearrangements are also considered, more specifically, we 
consider inversions, duplications in tandem and duplications by transpositions.

  Alignment with inversions does not have a known polynomial algorithm and a 
  simplification to the problem that considers only non-over\-lapping 
  inversions were proposed by Schöniger and Waterman~\cite{pmid1591531} in 
  1992. In 2003, independent works proposed algorithms  with 
  $O(n^4)$~\cite{lago03:wob03,gao03:_space_effic_algor_sequen_align_inver,MR2132586} 
  time\footnote{In this case, $n$ denotes the maximal length of the two aligned 
  sequences.} to align two sequences with non-overlapping inversions. We 
  developed two algorithms to solve this problem: one in $O(n^3 \log 
  n)$~\cite{MR2173809} time and other in 
  $O(n^3)$~\cite{vellozo06:_align_with_non_overl_inver} time, both in $O(n^2)$ 
  memory.
  
%   Before 
%   our algorithms, the best algorithms to align two sequences with 
%   non-overlapping inversions executed in 
%   $O(n^4)$~\cite{lago03:wob03,gao03:_space_effic_algor_sequen_align_inver} 
%   time\footnote{In this case, $n$ denotes the maximal length of the two aligned 
%   sequences.}. 
  
%   Repeated sequences represent a large part of eukaryotic genomes. More than 
%   80\% of plant genome are supposed to be repeats. Repeats are associated with 
%   some diseases and may serve a multitude of functions in DNA regulation and 
%   evolution. We worked with two types of repeats: tandem repeats (micro and 
%   minisatellites) and transposons.
%   
%   The first known work of alignment with duplication was done by Benson in 
%   1997~\cite{267526}.
  
  In 1997, Benson proposed a model of alignment that also recognized tandem 
  duplication. He proposed two exact algorithms to align two sequences with 
  tandem duplication: one in $O(n^5)$ time and $O(n^2)$ memory, and other in 
  $O(n^4)$ time and $O(n^3)$ memory. We propose one algorithm to align two 
  sequences with tandem duplication in $O(n^3)$ time and $O(n^2)$ memory. We 
  also propose one algorithm to align two sequences with transposons (a type of 
  duplication more general than tandem duplication), in $O(n^3)$ time and 
  $O(n^2)$ memory.

\newpage

\tableofcontents

\listoffigures

\listofalgorithms

% \listtheorems{definicao}

% \clearpage
% \end{comment} 

\chapter{Introdução}
Atualmente, devido ao grande número de projetos de seqüenciamentos 
desenvolvidos e finalizados, temos uma enorme quantidade de dados moleculares 
disponíveis, principalmente de DNA, RNA e proteína. Processar estes dados para 
extrair informações relevantes é um grande desafio.

Uma das maneiras de manipular, estudar e estruturar estes dados moleculares é 
através do uso de \seqs\ de símbolos. No caso do DNA os símbolos são as letras 
que representam as bases de nucleotídeos (A, C, T e G), no caso das proteínas 
os símbolos são letras que representam os 20 aminoácidos elementares.

À medida que o número de novos genomas completos aumenta, a comparação entre 
seqüências longas de DNA de espécies próximas torna-se mais importante para 
nosso entendimento da estrutura da seqüência do DNA. Devido a isto, a análise 
genômica comparativa~\cite{pmid10438229}, apesar de ser um novo campo na 
bioinformática, está se desenvolvendo rapidamente. Em muitas espécies próximas, 
a ordem dos genes é preservada para intervalos curtos~\cite{pmid7583118}. 
Nesses casos, os genes são mais conservados do que as regiões intergênicas. 
Portanto, a ordem da seqüência de genes é muito útil para detectar 
reordenamentos cromossômicos como inversões. Estes tipos de comparações ganham 
maior significância à medida que mais segmentos de genomas ortólogos, 
fortemente relacionados pela evolução, são seqüenciados.

Desde a finalização do rascunho do genoma humano novos projetos de 
seqüenciamento têm sido desenvolvidos para comparação com o genoma humano. 
Muitos programas computacionais têm sido usados para esse propósito co\-mo 
VISTA~\cite{pmid11159318,pmid10984448}, GLASS~\cite{pmid10899144}, 
Mummer~\cite{pmid10325427}, PipMaker~\cite{pmid10779500}, e também BLAST 2 
Sequences~\cite{pmid10339815}.

Essas comparações genômicas muitas vezes dependem fortemente da comparação de 
trechos menores dos genomas. Em outros estudos em bioinformática, assim como 
nas comparações ge\-nô\-mi\-cas,  a comparação de \seqs\ biológicas é muito 
utilizada. Uma das maneiras de se executar estas comparações de \seqs\ 
biológicas é através do alinhamento de \seqs, os quais são definidos na 
seção~\ref{sec:alinhamentousual}. 

Na história da evolução vários eventos introduzem mudanças nas \seqs\ do DNA. 
Alguns eventos biológicos típicos são as \emph{substituições}, \emph{remoções} e
\emph{inserções} de nucleotídeos. 
Portanto, qualquer comparação de \seqs\ precisa levar em consideração a
possibilidade da ocorrência desses eventos, se é esperado identificar uma alta
similaridade entre duas \seqs. Procedimentos de alinhamento típicos tentam 
identificar que partes não mudam e onde se localizam esses eventos biológicos.
Após, apresentam um alinhamento ótimo de acordo com algum critério de
otimização e sistema de pontuação associado aos eventos. 

Alinhamentos podem ser associados a um conjunto de operações de edição que 
transformam uma \seq\ em outra. Normalmente as únicas operações de edição 
consideradas são a \emph{substituição} de um símbolo em outro, a 
\emph{inserção} de um símbolo e a \emph{remoção} de um símbolo. Se os custos 
são associados a cada operação, existe um procedimento de programação dinâmica 
clássico em $O(n^2)$\footnote{Nas análises das complexidades dos algoritmos, 
consideraremos neste texto que $n$ é o comprimento da maior \seq\ analisada.} 
que computa o conjunto mínimo de operações de edição com o custo total mínimo e 
apresenta o alinhamento associado, que tem boa qualidade e alta semelhança para 
custos realistas.

Além desses eventos que resultam em alterações em um único símbolo na \seq\ 
biológica, iremos considerar também, para a obtenção de alinhamentos, outros 
eventos, os rearranjos, que agem sobre um fragmento da \seq. Consideraremos 
também, além das inserções, remoções e substituições de um símbolo, os eventos 
de \inv\ e de \dup\ para a obtenção de um alinhamento ótimo de duas \seqs. Estes
não são os únicos tipos de rearranjos, mas são os mais importantes.


A seção~\ref{sec:mutation} descreve algumas mutações que alteram as \seqs\ 
\bioas\ e que pretendemos analisar nos alinhamentos. Esta seção contém muitos 
conceitos e definições que foram obtidos de~\cite{Griffiths}.

O capítulo~\ref{sec:BasicDefinitions} contém definições e algoritmos que serão 
utilizados neste texto. A seção~\ref{sec:palavras} fornece conceitos básicos e 
elementares em combinatória das palavras e apresenta notações que serão 
utilizadas neste texto. As seções~\ref{sec:monotonica} 
e~\ref{sec:totMonotonica} mostram alguns tipos de matrizes (matrizes 
monotônicas e matrizes totalmente monotônicas) que foram utilizadas em 
\cite{tesecarlos}, e que têm propriedades que auxiliam na solução do problema 
da obtenção dos elementos máximos de cada coluna de uma matriz. Trazem também 
algoritmos apresentados por Aggarwal et al.\ \cite{MR895444} que resolvem este 
problema para estes tipos de matrizes. Estes algoritmos são utilizados nos 
algoritmos propostos para a obtenção de alinhamentos com \invnsobs. Na seção 
\ref{sec:monge} é apresentado a matriz de monge, que é um tipo de matriz com 
muitas propriedades descritas em \cite{burkard96perspectives} e que serão 
utilizadas, novamente, nos algoritmos propostos para alinhamentos com 
\invnsobs. A seção~\ref{sec:operacoes} contém as definições das \opeds\ sobre 
\seqs. Estas \opeds\ serão utilizadas como uma representação dos eventos 
biológicos que alteram as \seqs\ biológicas e que pretendemos detectar nos 
alinhamentos de \seqs. Na seção~\ref{sec:editgraph} é apresentado o conceito de 
grafo de edição, no qual são baseados os algoritmos de alinhamentos propostos.

O capítulo~\ref{cap:alinhamento} é sobre alinhamentos usuais de duas \seqs, ou 
seja alinhamentos que não consideram \dups\ nem \invs. Na 
seção~\ref{sec:alinhamentousual}, descreveremos e definiremos os alinhamentos 
usuais de duas \seqs. Muitos conceitos desta seção foram obtidos 
de~\cite{Pevzner_book}~e~\cite{giegerich-pairwise}. Nas 
seções~\ref{sec:alignoped} e \ref{sec:aligngred}, descreveremos como os 
alinhamentos usuais se relacionam com \opeds\ e \greds, respectivamente. Na 
seção~\ref{sec:alignglobsemi} descreveremos e daremos algumas noções sobre 
alguns tipos de alinhamentos usuais (local, global e semiglobal).

O capítulo~\ref{cap:aligninversion} é sobre alinhamentos com inversões, ou seja 
alinhamentos que consideram também os eventos de \inv. A 
seção~\ref{sec:aligninversionintroduction} traz uma introdução e um histórico 
sobre alinhamentos com inversões e uma definição de alinhamentos com inversões 
sem a restrição da não sobreposição. Já a seção~\ref{sec:aligninvnsob} descreve 
e define um alinhamento com \invnsobs. As 
seções~\ref{sec:jeanette}~e~\ref{sec:aligninvarvb} são baseadas nos conceitos 
apresentados por Jeanette Schmidt \cite{MR1621993}. Estas seções mostram uma 
estrutura de dados com árvores binárias, que armazenam as pontuações dos 
alinhamentos dos prefixos de uma \seq\ contra todos os fatores de outra 
seqüência, e um algoritmo que constrói estas estruturas de dados. Estas 
estruturas serão utilizadas no algoritmo de alinhamento com \invnsobs\ da 
seção~\ref{sec:algn3logn}. A seção~\ref{sec:algn3logn} mostra um algoritmo que 
propomos em~\cite{MR2173809} para resolver o problema da obtenção da pontuação 
de um alinhamento ótimo com \invnsobs\ em tempo $O(n^3 \log n)$ e espaço 
$O(n^2)$. Esse mesmo problema é resolvido pelo algoritmo que propomos 
em~\cite{vellozo06:_align_with_non_overl_inver} e que apresentamos na 
seção~\ref{sec:algn3}. Este algoritmo, para os sistemas de pontuação comumente 
utilizados em alinhamentos, leva tempo $O(n^3)$ e utiliza espaço $O(n^2)$ para 
executar.

O capítulo~\ref{cap:aligndup} é sobre alinhamentos com \dups, ou seja 
alinhamentos que consideram os eventos de \dup. A seção~\ref{sec:aligndupintro} 
traz uma introdução sobre alinhamentos com \dups\ e uma definição de 
alinhamentos com \dups, sem a restrição das \dups\ precisarem ser encadeadas 
(\emph{tandem}). A seção~\ref{sec:aligndupalg} mostra as recorrências para 
construir as matrizes que serão utilizadas no algoritmo proposto, e apresentado 
nesta seção, para obter a pontuação de um alinhamento ótimo com \dups. O 
algoritmo que obtém a pontuação de um alinhamento ótimo com \dups\ apresentado 
nesta seção executa em tempo $O(n^3)$ e utiliza espaço $O(n^2)$. As 
seções~\ref{sec:alignduptintro}~e~\ref{sec:alignduptalg} são equivalentes às 
seções~\ref{sec:aligndupintro}~e~\ref{sec:aligndupalg}, porém são para 
alinhamentos com \dups\ em \emph{tandem}.

O capítulo~\ref{cap:conclusao} traz uma conclusão sobre os algoritmos 
apresentados neste texto e no capítulo~\ref{cap:todo} são apresentados alguns 
trabalhos e problemas com os quais há interesse em se trabalhar no futuro.

\section{Um pouco de biologia: mutações}
\label{sec:mutation}

Durante o decorrer do tempo algumas \seqs\ de DNA podem sofrer alterações. 
Estas alterações nas \seqs\ de DNA chamamos de \emph{mutações}. As mutações são um 
tipo de evento biológico que ocorre devido a ação de agentes mutagênicos, que 
podem ser físicos (por exemplo radiação ionizante e raios ultra-violeta), 
químicos (por exemplo substâncias cancerígenas) e biológicos (por exemplo vírus 
e bactérias). Também podem haver mutações por falhas ocasionais (ou pelo menos 
desconhecidas), por exemplo algumas mutações ocorridas no processo de divisão 
das células. Alguns agentes mutagênicos apesar do efeito nocivo às células 
humanas, são aproveitados pela ciência e algumas vezes utilizado na medicina 
para diagnósticos e tratamentos de doenças.

Muitas vezes as células que sofreram uma mutação no seu código genético não 
persistem e morrem (ou param de metabolizar) sem replicar a mutação. Porém, 
outras vezes as mutações na \seq\ de DNA de uma célula não interferem na sua 
sobrevivência ou até provocam a apresentação de novas características que 
melhoram a sua sobrevivência. Isto possibilita que esta mutação seja propagada 
através da divisão celular.

Vamos classificar as mutações em dois grupos distintos:
\begin{description}
\item[Mutações pontuais]: são mutações que alteram a \seq\ de DNA em poucas 
bases ou apenas uma base. Neste trabalho, vamos considerar para este grupo de 
mutações somente as mutações que alteram as \seqs\ em apenas uma base. As 
principais mutações deste grupo são:
\begin{description}
\item[substituição]: neste tipo de mutação um nucleotídeo é substituído por 
outro na \seq\ de DNA. Se a mudança envolve uma purina e uma pirimidina então 
este tipo de mutação é chamado de transversão, senão é chamado de transição;
\item[inserção]: neste tipo de mutação uma base de nucleotídeo é inserida na 
\seq\ de DNA;
\item[remoção]: neste tipo de mutação uma base de nucleotídeo é removida da 
\seq\ de DNA;
\end{description} 
\item[Mutações por rearranjo]: são mutações que alteram a \seq\ de DNA em 
várias bases. As principais mutações deste grupo são:
\begin{description}
\item[inversão]: neste tipo de mutação um fragmento da \seq\ de DNA é 
envolvido. Os nucleotídeos deste fragmento tem a sua ordem alterada para a 
reversa e são trocados por seus nucleotídeos complementares, ou seja, quando 
uma inversão ocorre, um fragmento da seqüência é transformado no seu 
complemento reverso. O nucleotídeo complementar da adenina (A) é a timina (T) e 
vice versa. O nucleotídeo complementar da guanina (G) é a citosina (C) e vice 
versa. Por exemplo, o complemento reverso do fragmento \emph{ACTG} é 
\emph{CAGT}. A figura~\ref{fig:inversion} mostra o que acontece numa inversão 
de uma seqüência.
\item[duplicação]: neste tipo de mutação um fragmento de DNA de uma \seq\ é 
copiado e inserido na própria \seq;
\item[excisão]: neste tipo de mutação um fragmento de DNA, o qual foi inserido 
na \seq\ de DNA anteriormente, é removido. Consideraremos neste trabalho que o 
fragmento inserido foi devido a uma mutação de duplicação.
\end{description} 
\end{description} 

\begin{figure}[htbp]
  \centering
\includegraphics[width=0.6\textwidth,height=0.6\textwidth]{inversion}
% \end{center}
 \caption{Exemplo de inversão numa seqüência de DNA}
 \label{fig:inversion}
\end{figure}

Em organismos multicelulares, as mutações presentes em células reprodutivas 
(gametas) de um indivíduo são propagadas para os descendentes deste indivíduo, 
podendo até gerar novas espécies. Em algumas plantas, as mutações sofridas no 
DNA de células somáticas (não reprodutivas) podem também ser transmitidas para 
seus dependentes.

As mutações em \seqs\ de DNA afetam não somente as \seqs\ de DNA, mas também
as de RNA e as de aminoácidos de uma proteína.

As mutações atuam de forma crucial na evolução das espécies. 

\subsection{Repetições}

Repetições são elementos preponderantes, especialmente em genomas de organismos 
eucariontes. Estima-se que mais de 80\% dos genomas de planta são compostos por 
repetições. Existem diversos tipos de repetições em um genoma, provavelmente 
nem todos já conhecidos. Entre os tipos mais conhecidos estão os satélites 
(micro ou mini conforme as características de comprimento e outras) que são 
repetições em \emph{tandem}, isto é, que aparecem uma atrás da outra ao longo 
do genoma. Outro tipo de repetição muito conhecido são os ditos elementos 
transponíveis, ou transposons. Os transposons foram descobertos por Barbara 
McClintock~\cite{Comfort_2001} nos anos 50 estudando o milho. Os elementos 
transponíveis podem ser definidos como seqüências de DNA moderadamente 
repetitivas que podem mover-se de um local a outro no genoma e, desta maneira, 
ter um profundo impacto na estrutura, regulação e função dos genes, bem como na 
organização dos cromossomos na espécie.

% Enfim, motivos 
% (\emph{motifs}) em seqüências potencialmente relacionados com sítios de 
% interação de complexos moleculares (proteínas e/ou RNAs) com o DNA são mais um 
% exemplo de repetições, intra e inter espécie que desempenha um papel importante 
% na regulação individual dos genes.
% 
% 
Ser capaz de identificar repetições de maneira sistemática, e portanto exata, 
dado uma certa definição de repetição, é um problema importante em 
bioinformá\-ti\-ca que ainda não foi resolvido de maneira satisfatória ou 
realmente eficaz, especialmente no caso de genomas de organismos eucariontes. A 
dificuldade já vem da grande variedade de tipos de repetições. Algumas 
repetições, como as compridas (onde cada cópia pode atingir centenas de bases), 
são particularmente difíceis de identificar, por causa do comprimento, e porque 
há pouca conservação de uma cópia para a outra. Obviamente, o tamanho habitual 
das \seqs\ onde as repetições devem ser identificadas, aumenta ainda mais o 
grau de complexidade do problema.

Algumas doenças humanas são associadas às repetições, tais como: retardação 
mental \emph{fragile-X}~\cite{pmid1710175}, doença de 
Huntington~\cite{pmid8458076}, distrofia 
miotô\-ni\-ca~\cite{Myotonic_Muscular_Dystrophy} e ataxia de 
Friedreich~\cite{Friedreich_Ataxia}. \emph{Tandem repeats} podem estar ligados 
a regras de regulação gênica~\cite{HHamada12011984, QLu05011993, pmid3111846}, 
ligação DNA-proteína~\cite{DNAProteinBinding, 
binding_proteins_mammalian_species} e evolução~\cite{pmid3146527}.

O número de cópias num \emph{tandem repeat} pode ser variável entre indivíduos 
diferentes (polimórfico). Locais polimórficos são úteis em várias tarefas de 
laboratório~\cite{pmid1740333, pmid2916582}. \emph{Tandem repeats} tem sido 
utilizados para sustentar algumas hipóteses da evolução 
humana~\cite{pmid8640220, Modern_Human_Origins} e da evolução de 
micro-satélites (\emph{tandem repeats} cujo tamanho é de apenas algumas 
unidades de nucleotídeos) em primatas~\cite{Messier1996}.


\chapter{Definições Gerais} 
\label{sec:BasicDefinitions} 

\section{Combinatória das palavras}
\label{sec:palavras}
Seja $\alfabeto$ um \emph{alfabeto}, um conjunto de \emph{letras}. Qualquer 
seqüência finita em $\alfabeto$ é também chamada uma \emph{palavra em 
$\alfabeto$} ou simplesmente uma \emph{palavra} se o alfabeto for claro. Sejam 
$\alfabeto^*$ o conjunto de todas as palavras em $\alfabeto$, incluindo a 
\emph{palavra vazia} denotada por $1$ e $\alfabeto^+$ o conjunto de todas as 
palavras em $\alfabeto$, excluindo a \emph{palavra vazia}. Nós identificamos 
palavras de comprimento $1$ às letras que elas contém. A concatenação $\cdot$ 
de palavras é uma operação associativa definida sobre $\alfabeto^*$ e será 
freqüentemente omitida. Seja $w=w[1]w[2]\ldots w[k]$ uma palavra. Denotamos por 
$|w|$ o \emph{comprimento} $k$ de $w$. Iremos também denotar a palavra $w$ por 
$w[1\Rng k]$. Para $1\leq i\leq j\leq k$, o fator $w[i]w[i+1]\cdots w[j]$ de 
$w$ é também representado por $w[i\Rng j]$. Denotaremos $w[i\Rng j]=1$ se 
$i>j$. Seja $x,y,z\in \alfabeto^*$. Denotaremos por $x\alfabeto^*$ o conjunto 
$\{xy \tq y \in \alfabeto^*\}$, denotaremos por $\alfabeto^*x$ o conjunto $\{yx 
\tq y \in \alfabeto^*\}$ e denotaremos por $\alfabeto^*x\alfabeto^*$ o conjunto 
$\{yxz \tq y,z \in \alfabeto^*\}$. Diremos que $x$ é um \emph{prefixo de $w$} 
se $w \in x\alfabeto^*$, diremos que $x$ é um \emph{sufixo de $w$} se $y \in 
\alfabeto^*x$ e diremos que $x$ é um \emph{fator de $w$} se $w \in 
\alfabeto^*x\alfabeto^*$.

Seja $\invertsym{ }$, também chamada de \emph{inversão}, uma operação qualquer 
em $\alfabeto^*$ que satisfaça as seguintes propriedades:

\begin{enumerate} 
\item $\invert{a} \in \alfabeto, \forall a \in \alfabeto$
\item $\invert{x \cdot y} = \invert {y} \cdot \invert x, \forall x,y \in \alfabeto^*$
\end{enumerate} 

Note que a operação de inversão em $\alfabeto^*$ é definida por seus valores nas letras 
de $\alfabeto$. Por exemplo, seja $\alfabeto=\{A,C,T,G\}$ e seja $s\in \alfabeto^*$ uma seqüência de 
DNA qualquer. Se a inversão é definida por $\invert{A}=A$, $\invert{T}=T$, 
$\invert{C}=C$ e $\invert{G}=G$, ela mapeia $s$ à sua \emph{seqüência reversa}. 
Por outro lado, se a inversão é definida por $\invert{A}=T$, $\invert{T}=A$, 
$\invert{C}=G$ e $\invert{G}=C$, ela mapeia $s$ à sua \emph{seqüência reversa 
complementar}. O último caso é o de interesse para seqüências de DNA em 
biologia molecular e é o que será considerado nos exemplos e testes deste texto.

\section{Matriz monotônica} \label{sec:monotonica}

Diremos que $M$ é uma \emph{matriz} $n \times m$ se cada par $(i,j)$, $0 \leq i 
\leq n-1$ e $0 \leq j \leq m-1$, que chamaremos de posição $(i,j)$, contém
um elemento. Dizemos que $M[i,j]$ é o \emph{elemento da matriz} $M$ que está na 
linha $i$ e na coluna $j$, ou seja, na posição $(i,j)$.

Seja $M$ uma matriz $n \times m$. Dizemos que um conjunto de posições da matriz
é uma \emph{região da matriz}.

\begin{definicao}[Região de $(i_1,j_1)$ a $(i_2,j_2)$] Dados $i_1,j_1,i_2$ e 
$j_2$, dizemos que o conjunto de posições $\{(i,j)\tq\ i_1 \leq i \leq i_2 
\textrm{ e } j_1 \leq j \leq j_2\}$, denotado por $[i_1\Rng i_2,j_1\Rng j_2]$, 
é a região de $(i_1,j_1)$ a $(i_2,j_2)$.
\end{definicao}

\begin{definicao}[Submatriz] Sejam $M$ uma matriz $n \times m$ e as \seqs\ 
ordenadas $X=(x_1, x_2, \ldots, x_{n'})$ e $Y=(y_1, y_2, \ldots, y_{m'})$ de 
índices das linhas e das colunas, respectivamente, de $M$. Seja $M'$ a matriz 
$n' \times m'$ definida por $M'[i,j]=M[x_{i+1},y_{j+1}]$, para toda posição 
$(i,j)$ tal que $0 \leq i < n'$ e $0 \leq j < m'$. Diremos que a matriz $M'$ é 
uma submatriz de $M$ restrita às linhas de $X$ e às colunas de $Y$.
\end{definicao}

Nesta seção, e na próxima, analisaremos e trabalharemos com matrizes que 
possuem algumas propriedades específicas, que possibilitam encontrar de forma 
mais eficaz os elementos que são os máximos de cada coluna destas matrizes, a 
ser visto no Algoritmo~\ref{alg:maxmonotonica} e no 
Algoritmo~\ref{alg:maxTotMonotonica}.

\begin{definicao}[Matriz comparável nas colunas] Dizemos que a matriz $M$ é uma 
matriz comparável nas colunas se para cada coluna de $M$, todos os seus 
elementos admitem uma ordem total, ou seja, dois elementos quaisquer de uma 
mesma coluna podem ser comparados.
\end{definicao}

Em outras palavras, em uma matriz comparável nas colunas, todos os elementos de 
uma mesma coluna aceitam as operações de $<$ e $=$ entre eles.

Nesta seção consideraremos que a matriz $M$ é uma matriz ${n \times m}$ 
comparável nas colunas.

Diremos que $V$ é um \emph{vetor} de comprimento $n$ se para cada índice $i$, 
$0 \leq i \leq n-1$, $V[i]$ é definido. Dizemos que $V[i]$ é o elemento do 
vetor $V$ que está na posição $i$.

\begin{definicao}[Vetor $I_M$ de máximos das colunas] Dada uma matriz $M$, 
definimos o vetor $I_M$ da seguinte forma: $I_M[j]$ é o menor índice $i$ tal 
que $M[i, j]$ é máximo na coluna $j$. Chamamos o vetor $I_M$ de vetor de 
máximos das colunas de $M$.
\end{definicao}

Por abuso de linguagem, diremos que o vetor $I_M$ contém os índices das 
linhas dos elementos má\-xi\-mos de cada coluna, muito embora possa haver outra 
linha na coluna $j$, além de $I_M[j]$, que contenha este mesmo elemento máximo.

Observe que para todo $i'$, tal que $0 \leq i' < I_M[j]$, temos que $M[i',j] < 
M[I_M[j],j]$ e para todo $i''$, tal que $I_M[j] < i'' < n$, temos que $M[i'',j] 
\leq M[I_M[j],j]$.

Por exemplo, para a matriz $M$ do exemplo~\ref{ex:matIj} o vetor $I_M$ é igual 
ao vetor $[4,2,1,4,5,3]$ e os elementos máximos de cada coluna estão destacados em 
negrito.

\begin{exemplo}[Matriz com os elementos máximos destacados]
\label{ex:matIj}
 \[M=\left[\begin{array}{cccccc} 
          	5&7&\mathbf{25}&37&7&2\\
			12&\mathbf{13}&9&28&6&2\\
			1&8&14&40&9&\mathbf{3}\\
			\mathbf{14}&5&12&\mathbf{43}&4&3\\
			13&10&25&43&\mathbf{10}&3\\ 
		\end{array}\right]\]
\end{exemplo}

\begin{definicao}[Matriz monotônica] A matriz $M$ é dita monotônica se $I_M$
está em ordem crescente.
\end{definicao}

Vale a pena ressaltar que $I_M$ não precisa estar em ordem estritamente 
crescente, mas apenas crescente, ou seja os valores de $I_M$ podem não ser 
distintos. De forma equivalente, podemos dizer que uma matriz $M$ é monotônica 
se $I_M[j_1] \leq I_M[j_2]$, para quaisquer $j_1$ e $j_2$ tais que $0 \leq j_1 
< j_2 \leq m-1$.

Por exemplo, para a matriz $M$ do exemplo~\ref{ex:matmonotonica} o vetor $I_M$ 
é igual ao vetor $[1,2,2,4,5,5]$ e portanto a matriz é monotônica. Já para a matriz 
$M$ do exemplo~\ref{ex:matIj} o vetor $I_M$ é igual a $[4,2,1,4,5,3]$ e 
portanto a matriz não é monotônica.

No exemplo~\ref{ex:matmonotonica}, os elementos máximos de cada coluna de $M$ 
estão destacados em negrito.

\begin{exemplo}[Matriz monotônica]
% Exemplo $1$ de matriz monotônica:
\label{ex:matmonotonica}
\[M=\left[\begin{array}{cccccc} \mathbf{14}&7&9&37&7&2\\
12&\mathbf{13}&\mathbf{25}&28&6&2\\ 1&8&14&40&9&2\\ 5&5&12&\mathbf{43}&4&2\\
13&10&25&43&\mathbf{10}&\mathbf{3}\\ \end{array}\right]\]
\end{exemplo}

É interessante reparar que para que uma matriz $M$ seja monotônica, não é 
necessário que os elementos de diferentes colunas sejam comparáveis entre si. 
Nem tampouco é necessário haver qualquer relação entre os elementos de 
diferentes colunas.

O exemplo~\ref{ex:matmonotoposdif} a seguir é mostrado para ilustrar esta 
independência entre os elementos de diferentes colunas. Neste exemplo 
utilizamos a ordem lexicográfica para comparar os elementos da coluna $3$. Já 
na coluna $4$, as comparações são feitas utilizando o comprimento da palavra.

Assim, no exemplo~\ref{ex:matmonotoposdif} o vetor $I_M$ é igual a 
$[1,2,2,4,5,5]$ e portanto $M$ é uma matriz monotônica.

Novamente, no exemplo~\ref{ex:matmonotoposdif} os valores destacados em negrito 
são os elementos máximos de cada coluna de $M$.

\begin{exemplo}[Matriz monotônica com tipos diferentes]
\label{ex:matmonotoposdif}
\[M=\left[\begin{array}{cccccc} \mathbf{14}&7&a&{\textcourier {casado}}&7&2\\
12&\mathbf{13}&\mathbf{e}&{\textcourier {viúvo}}&6&2\\ 1&8&c&{\textcourier 
{noivo}}&9&2\\
5&5&b&$\bfseries\textcourier {solteiro}$&4&2\\ 13&10&d&{\textcourier 
{namorado}}&\mathbf{10}&\mathbf{3}\\
\end{array}\right]\]
\end{exemplo}

\begin{definicao}[Elemento morto] Uma posição $(i,j)$ de uma matriz $M$ é dita 
morta se $I_M(j) \neq i$. Por abuso de linguagem, diremos que o elemento 
$M[i,j]$ é morto.
\end{definicao}

\begin{definicao}[Região morta] Dizemos que as regiões da matriz que só contêm 
posições mortas são regiões mortas.
\end{definicao}

\begin{proposicao}
\label{prop:regmortamono}
Seja $M$ uma matriz $n \times m$ monotônica. Se $I_M[j]=i$ então as regiões 
$[0\Rng i-1,j\Rng m-1]$ e $[i+1 \Rng n-1, 0 \Rng j]$ de $M$ são regiões mortas.
\end{proposicao}
\begin{prova}
Suponha que $I_M[j]=i$. Como $M$ é monotônica, temos que $I_M[j'] \leq i$ para 
qualquer $j'$ tal que $0 \leq j' < j$. Portanto as posições de $M$ cujas linhas 
têm índices maiores que $i$ e cujas colunas tem índices menores que $j$ são 
mortas e $[i+1 \Rng n-1, 0 \Rng j-1]$ é uma região morta de $M$. De forma 
análoga, as posições cujas linhas têm índices menores que $i$ e cujas colunas 
tem índices maiores que $j$ são mortas e $[0\Rng i-1,j+1\Rng m-1]$ é uma região 
morta de $M$. Como as posições da coluna com índice $j$, exceto a da linha com 
índice $i$, são mortas temos que $[0\Rng i-1,j\Rng m-1]$ e $[i+1 \Rng n-1, 0 
\Rng j]$ são regiões mortas de $M$. \cqd
\end{prova}

\begin{problema}[Máximo das colunas] \label{prob:maxcol} Dada uma matriz $M$,
queremos encontrar $I_M$.
\end{problema}

Se $M$ for uma matriz monotônica o problema~\ref{prob:maxcol} da obtenção do 
máximo das colunas de $M$ pode ser resolvido utilizando um algoritmo recursivo 
com a estratégia de divisão e conquista, como mostrado no 
Algoritmo~\ref{alg:maxmonotonica}~\cite{MR895444}.

\begin{algorithm}[htbp]
\begin{algo}{maxMonotonica}{M,i_1,i_2,j_1,j_2,I_M}
\label{alg:maxmonotonica}
\COM{Põe em $I_M$ os índices dos máximos da região $[i_1 \Rng i_2, j_1 \Rng j_2]$}
\IF{(i_1 \leq i_2) $ e $ (j_1 \leq j_2)}
\SET{j}{\lfloor (j_1+j_2)/2 \rfloor}
\COM{Coloca em $I_M[j]$ a linha do 1º máximo da coluna $j$}
\SET{I_M[j]}{i_1}
\DOFORI{i}{i_1+1}{i_2}
\IF{M[i,j]>M[I_M[j],j]} \label{alg:maxmonotonica:loop1}
\SET{I_M[j]}{i}
\FI 
\OD
\CALL{maxMonotonica}{M,i_1,I_M[j],j_1,j-1,I_M} \label{alg:maxmonotonica:sub1}
\CALL{maxMonotonica}{M,I_M[j],i_2,j+1,j_2,I_M} \label{alg:maxmonotonica:sub2}
\FI
\caption[maxMonotonica]{Coloca em $I_M(j)$ o índice da linha do máximo da coluna $j$}
\end{algo}
\end{algorithm}

Sejam $n=i_2-i_1+1$ e $m=j_2-j_1+1$. 
O tempo de execução do Algoritmo~\ref{alg:maxmonotonica} é dado pela seguinte 
recorrência:
\begin{itemize}
  \item $t(0,m)=t(n,0)=c $, com $c$ constante e
  \item $t(n,m)\leq n+\max_{1 \leq i \leq n}(t(i,\lfloor (m-1)/2 
\rfloor)+t(n-i+1,\lceil (m-1)/2 \rceil))$, para $n>0$ e $m>0$.
\end{itemize}

Resolvendo esta recorrência temos que $t(n,m)=O(n\log m)$. 

O Algoritmo~\ref{alg:maxmonotonica} aloca memória somente para a pilha da 
chamada recursiva, ou seja, ele aloca memória $O(\log n)$. Vale a pena 
ressaltar que além desta alocação de memória, o algoritmo necessita de acesso 
ao vetor de resposta $I_M$ e à matriz $M$.

Aggarwal et al.\ provaram em 1987 \cite{MR895444} que qualquer algoritmo que 
resolva o problema de encontrar os máximos das colunas em uma matriz 
monotônica, levando em consideração somente a propriedade da monotonicidade da 
matriz, necessita no pior caso de tempo $\Omega (n\log m)$.

O Algoritmo~\ref{alg:maxmonotonica} está correto pois, para a coluna $j=\lfloor 
(j_1+j_2)/2 \rfloor$ todos os seus elementos são verificados na 
linha~\ref{alg:maxmonotonica:loop1} e é colocado em $I_M[j]$ o índice $i$ do 
elemento máximo desta coluna $j$. Para as colunas $j' \neq j$ as chamadas 
recursivas das linhas~\ref{alg:maxmonotonica:sub1} e 
\ref{alg:maxmonotonica:sub2} encontram os seus respectivos elementos máximos e 
colocam os seus índices em $I_M[j']$. As chamadas recursivas das linhas 
~\ref{alg:maxmonotonica:sub1} e \ref{alg:maxmonotonica:sub2} não verificam os 
elementos das regiões $[0\Rng i-1,j\Rng m-1]$ e $[i+1\Rng n-1,0\Rng j]$ de $M$, 
as quais de acordo com a proposição~\ref{prop:regmortamono} são mortas e 
portanto não precisam ser verificadas.

A figura~\ref{fig:monotonica} ilustra o funcionamento do 
Algoritmo~\ref{alg:maxmonotonica}.

\begin{figure}[htbp] \centering 
\includegraphics[width=1\textwidth,height=0.5\textwidth]{monotonica}
% \end{center}
\caption[Ilustração da execução do Algoritmo~\ref{alg:maxmonotonica}]{Após 
encontrar cada $I_M[j]$ são identificadas duas regiões mortas destacadas na
figura e que não são inspecionadas pelo algoritmo.}
 \label{fig:monotonica}
\end{figure}

\section{Matriz totalmente monotônica}
\label{sec:totMonotonica}

Nesta seção consideraremos que a matriz $M$ é uma matriz ${n \times m}$ 
comparável nas colunas.

\begin{definicao}[Matriz totalmente monotônica] Dizemos que $M$ é u\-ma matriz 
totalmente monotônica se toda submatriz de $M$ é monotônica.
\end{definicao}

Lembrando que estamos considerando como submatriz de $M$ a restrição de $M$ aos 
seus elementos que pertencem a uma sub\seq\ de linhas e a uma sub\seq\ de 
colunas de $M$. Ressaltando que as linhas, assim como as colunas, não precisam 
ser consecutivas mas sim ordenadas. Para que toda submatriz de $M$ seja 
monotônica, basta verificar que toda submatriz $2 \times 2$ de $M$ seja 
monotônica, ou seja, para qualquer $i_1$, $i_2$ , $j_1$ e $j_2$ tal que $0 \leq 
i_1 < i_2 \leq n-1$ e $0 \leq j_1 < j_2 \leq m-1$, se $M[i_1, j_1] < M[i_2, j_1]$ 
então $M[i_1, j_2] < M[i_2, j_2]$.

O exemplo~\ref{ex:totmonoto} mostra uma matriz totalmente monotônica. Os 
valores destacados em negrito são os elementos $M[I_M[j], j]$.

\begin{exemplo}[Matriz totalmente monotônica]
\label{ex:totmonoto}
\[M=\left[\begin{array}{cccccc} 
\mathbf{15}&7&33&11&70&15\\
14&\mathbf{10}&\mathbf{51}&12&71&16\\ 
13&8&40&17&72&17\\ 
12&9&41&\mathbf{20}&79&23\\
11&6&13&5&\mathbf{98}&\mathbf{31}\\ 
\end{array}\right]\]
\end{exemplo}


\begin{proposicao}
Seja $M$ uma matriz ${n \times m}$ totalmente monotônica e sejam $i_1$ e $i_2$ 
tais que $0 \leq i_1 < i_2 < n$. Então: \begin{enumerate}[\tabenum a)]
\item $M[i_1, j] \geq M[i_2, j]$ implica que, para todo $j'$ tal que $0 \leq j' 
\leq j$, a posição $(i_2, j')$ é morta em $M$. \label{propReducaomaior}
\item $M[i_1, j] < M[i_2, j]$ implica que, para todo $j'$ tal que $j \leq j' < 
m$, a posição $(i_1, j')$ é morta em $M$.\label{propReducaomenor}
\end{enumerate}
\label{propReducao}
\end{proposicao}

\begin{prova} 
\begin{enumerate}[\tabenum a)]
\item \emph{Se $M[i_1, j] \geq M[i_2, j]$ então $\forall\ j'$ tal que $0 \leq 
j' \leq j$ a posição $(i_2, j')$ é morta.}
	
Se $j'=j$ então $I_M[j'] \neq i_2$, pois por hipótese $M[i_1, j] \geq M[i_2, 
j]$ e portanto a posição $(i_2, j')$ é morta. Para $0 \leq j' < j$ suponha, por 
absurdo, que a posição $(i_2, j')$ não é morta e portanto $I_M[j']=i_2$. Sendo 
assim, teríamos $M[i_1, j']<M[i_2, j']$ e a submatriz de $M$ restrita aos 
elementos das linhas $i_1$ e $i_2$ e das colunas $j'$ e $j$ não seria 
monotônica. Portanto $M$ não seria totalmente monotônica. Logo a suposição que 
$M[i_2, j']$ não é um elemento morto está incorreta.
	
\item \emph{Se $M[i_1, j] < M[i_2, j]$ então $\forall\ j'$ tal que $j \leq j' < 
m$ a posição $M[i_1, j']$ é morta.}

Se $j'=j$ então $I_M[j'] \neq i_1$ pois por hipótese $M[i_1, j] < M[i_2, j]$ e 
portanto a posição $(i_1, j')$ é morta. Para $j < j' < m$ suponha, por absurdo, 
que a posição $(i_1, j')$ não é morta e portanto $I_M[j']=i_1$. Sendo assim, 
teríamos $M[i_1, j'] \geq M[i_2, j']$ e a submatriz de $M$ restrita aos 
elementos das linhas $i_1$ e $i_2$ e das colunas $j'$ e $j$ não seria 
monotônica. Portanto $M$ não seria totalmente monotônica. Logo a suposição que 
$M[i_1, j']$ não é um elemento morto está incorreta. \cqd
\end{enumerate}
\end{prova}

A figura~\ref{fig:proptotmono} mostra as posições mortas para cada caso da 
Proposição~\ref{propReducao}.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.8\textwidth,height=0.5\textwidth]{proptotmonoa}
% \end{center}
\caption[Ilustração da Proposição~\ref{propReducao}]{a) Se $M[i_1, j] \geq 
M[i_2, j]$ então a posição $(i_2, j')$ é morta, $0 \leq j' \leq j$. b) Se 
$M[i_1, j] < M[i_2, j]$ então a posição $(i_1, j')$ é morta, $j \leq j' \leq 
m-1$.}
 \label{fig:proptotmono}
\end{figure}

Se todas as posições $(i,j)$ de uma linha $i$ são mortas, então dizemos que a 
linha $i$ é morta.

\begin{corolario}
Seja $M$ uma matriz ${n \times m}$ totalmente monotônica e sejam $i_1$ e $i_2$ 
tais que $0 \leq i_1 < i_2 \leq n-1$. Se $M[i_1, m-1] \geq M[i_2, m-1]$ então a linha 
$i_2$ é morta.
\label{coroReducaom} 
\end{corolario}

Seja $M$ uma matriz ${n \times m}$ totalmente monotônica e $n \geq m$. Como $n 
\geq m$ então existem pelo menos $n-m$ linhas em $M$ cujo índice não é um 
elemento do vetor $I_M$ de máximos de colunas de $M$, ou seja, existem pelo 
menos $n-m$ linhas mortas. O Algoritmo~\ref{alg:reducao} remove da matriz 
totalmente monotônica $M$ $n-m$ destas linhas mortas. Portanto, o 
Algoritmo~\ref{alg:reducao} devolve uma submatriz $C$ de $M$ restrita a $m$ 
linhas de $M$, tal que todas as linhas cujos índices estão em $I_M$ são linhas 
de $C$.

\begin{algorithm}[htbp]
\begin{algo}{reducao}{M}
\SET{C}{M}
\SET{k}{0}
\SET{m}{$nº de colunas de $ C} \label{reducao:setM}
\DOWHILE{$nº de linhas de $ C > m} \label{reducao:loop}
	\IF{C[k,k] \geq C[k+1,k]} \label{reducao:if1}
	\COM{$C[k+1,j]$ é um elemento morto  $\forall\ j \tq 0 \leq j \leq k$}
		\IF{k<m-1} \label{reducao:if2}
			\INCR{k} \label{reducao:incrk}
		\ELSE
			\ACT{$Remove linha $k + 1$ de $C} \label{reducao:removek1}	
		\FI
	\ELSE \label{reducao:else1}
		\COM{$C[k, k] < C[k+1, k]$ e portanto} 
		\COM{$C[k, j]$ é um elemento morto  $\forall\ j \tq k \leq j < m$}
		\ACT{$Remove linha $k$ de $C} \label{reducao:removek}
			\IF {k > 0}
				\DECR{k}\label{reducao:decrk}
			\FI
	\FI
\OD
\RETURN{C} \label{reducao:return}
\caption[reducao]{Retira $n-m$ linhas da matriz $M$ que não contêm máximos de
colunas}
\label{alg:reducao}
\end{algo}
\end{algorithm}

\begin{lema}
O Algoritmo~\ref {alg:reducao} está correto e executa em tempo $O(n)$.
\end{lema}
\begin{prova}

\begin{enumerate}[\tabenum 1)]
\item[ ]
 \item O Algoritmo~\ref {alg:reducao} está correto.

  O laço da linha~\ref{reducao:loop} mantém as seguintes invariantes:
\begin{enumerate}
  \item o conjunto de posições $\Upsilon=\{(i,j)\tq 0 \leq i \leq k\textrm{ e } 
  0 \leq j < i\}$ contém somente posições mortas de $M$ e
  \label{reducao:elmorto}
  \item qualquer linha cujo índice é um elemento de $I_M$ é uma linha de 
  $C$.\label{reducao:imeic}
\end{enumerate}

A figura~\ref{fig:reducaoinvariante1} mostra o conjunto de posições mortas 
$\Upsilon$ da invariante~\ref{reducao:elmorto}.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.8\textwidth,height=0.5\textwidth]{invariante1}
% \end{center}
\caption[Invariante~\ref{reducao:elmorto} do 
Algoritmo~\ref{alg:reducao}]{Conjunto de posições mortas $\Upsilon$ da 
invariante~\ref{reducao:elmorto} do Algoritmo~\ref{alg:reducao}.}
 \label{fig:reducaoinvariante1}
\end{figure}

No início do laço, ou seja na primeira execução da linha~\ref{reducao:loop}, a 
invariante~\ref{reducao:elmorto} é verdadeira, pois para $k=0$ o conjunto 
$\Upsilon$ é vazio. No início do laço a invariante~\ref{reducao:imeic} também é 
verdadeira pois $C=M$.

Só podem ser inseridos elementos no conjunto $\Upsilon$ quando o valor de $k$ é 
aumentado, ou quando muda a linha indexada por $k$. Isto ocorre somente nas 
linhas~\ref{reducao:incrk}~e~\ref{reducao:removek} do algoritmo. Na 
linha~\ref{reducao:incrk} do algoritmo o valor de $k$ é incrementado e as 
posições inseridas em $\Upsilon$ são garantidas serem mortas pela 
afirmação~\ref{propReducaomaior}) da Proposição~\ref{propReducao}. Na execução 
da linha~\ref{reducao:removek} do algoritmo, a linha de $C$ indexada por $k$ é 
trocada, porém a nova linha indexada é a linha zero de $C$ ou será alterada, na 
linha~\ref{reducao:decrk} do algoritmo, para a linha $k-1$, o que em nenhuma 
das duas hipóteses insere elementos novos em $\Upsilon$. Portanto a 
invariante~\ref{reducao:elmorto} é mantida verdadeira durante a execução do 
laço.

A invariante~\ref{reducao:imeic} é mantida verdadeira durante a execução do 
laço pois somente são retiradas linhas mortas de $C$. A linha $k+1$ retirada de 
$C$ na linha~\ref{reducao:removek1} do algoritmo é garantida ser morta pelo 
Corolário~\ref{coroReducaom}. A linha $k$ retirada de $C$ na 
linha~\ref{reducao:removek} do algoritmo é garantida ser morta pois, pela 
invariante~\ref{reducao:elmorto} as posições $(k,j)$ são mortas, para todo $j$ 
tal que $0 \leq j < k$, e as outras posições da linha $k$, ou seja as posições 
$(k,j)$ para todo $j$ tal que $k \leq j < m$, são garantidas serem mortas pela 
afirmação~\ref{propReducaomenor}) da Proposição~\ref{propReducao}.

O número de linhas de $C$ ou decresce ou fica igual. Ele só não decresce quando 
$k$ é incrementado, porém a linha~\ref{reducao:if2} do algoritmo garante que 
$k$ só é incrementado até o limite superior $m$. Logo, como no início da 
execução do algoritmo o número de linhas de $C$ é maior ou igual ao número de 
colunas, então o número de linhas de $C$ atingirá o valor de $m$ e a condição 
do laço na linha~\ref{reducao:loop} do algoritmo será insatisfeita e o 
algoritmo será encerrado com a matriz $C$ tendo $m$ linhas. Portanto o 
algoritmo sempre termina com $C$ tendo $m$ linhas.

Como as únicas alterações realizadas em $C$ são remoções de linhas, temos que a
matriz $C$ é uma submatriz de $M$ restrita a $m$ linhas de $M$.

Além disso, a invariante~\ref{reducao:imeic} garante que as linhas de $M$ cujos 
índices são elementos de $I_M$ são linhas de $C$.

Portanto o Algoritmo~\ref {alg:reducao} executa corretamente.

\item O Algoritmo~\ref {alg:reducao} executa em tempo $O(n)$.

O tempo de execução do algoritmo é obtido através do número de vezes $t$ que o 
laço~\ref{reducao:loop}\ é executado. Esse número $t$ é dado pela seguinte 
equação: \[t=a+b+c,\] onde $a$, $b$ e $c$ são o número de vezes que as 
linhas~\ref{reducao:incrk},~\ref{reducao:removek1}~e~\ref{reducao:removek}, 
respectivamente, são executadas\footnote{A matriz $C$ pode ser construída com 
referências às linhas de $M$ e portanto a operação de remoção de uma linha pode 
ser feita em tempo constante.}.

O número de linhas removidas é igual a $b+c$. Sabemos também que o número de 
linhas removidas é igual a $n-m$, portanto \[b+c=n-m.\]

Seja $k_f$ o valor de $k$ quando o algoritmo termina e $k_i$ o valor de $k$ 
quando o laço do algoritmo inicia. Temos que $k_f - k_i$ é igual ao número de 
vezes que $k$ é incrementado menos o número de vezes que $k$ é decrementado. 
$k$ é incrementado $a$ vezes e decrementado no máximo $c$ vezes. Portanto 
\[k_f-k_i\geq a-c.\]

Sabemos também que $k_f< m$ e que $k_i=0$. Portanto $k_f-k_i\leq m-1$ e $m-1
\geq  k_f-k_i\geq a-c$. Logo \[m-1 \geq a-c.\]

Utilizando estas equações temos que:
\begin{equation*}
\begin{split}
t&=a+\underbrace{b + c}_{=n-m}\\
&=a+n-m\\
&=a+\underbrace{b-b+c-c}_{=0}+n-m\\
&= \underbrace{ a - c}_{\leq m-1} + \underbrace{b + c}_{=n-m} + n-m -b\\
&\leq m-1+n-m+n-m-b\\
&\leq 2n-m-1\\
&=O(n)
\end{split}
\end{equation*}

Portanto o tempo de execução do Algoritmo~\ref {alg:reducao} é $O(n)$. \cqd
\end{enumerate}
\end{prova}

A matriz $C$ pode ser construída através de referências às linhas de $M$.
Portanto, a memória utilizada pelo Algoritmo~\ref {alg:reducao} é $O(n)$.

Se $M$ for uma matriz totalmente monotônica $n \times m$ o 
problema~\ref{prob:maxcol} da obtenção do máximo das colunas de $M$ pode ser 
resolvido utilizando o Algoritmo~\ref{alg:maxTotMonotonica}. O 
Algoritmo~\ref{alg:maxTotMonotonica} foi construído, essencialmente, utilizando 
a estratégia da divisão e conquista e os 
Algoritmos~\ref{alg:reducao}~e~\ref{alg:maxImpar}.

\begin{algorithm}[htbp]
\begin{algo}{maxTotMonotonica}{M,I_M,A}
\COM{$A$ é uma submatriz da matriz original $M$. Na 1a. chamada $A = M$.}
\COM{O algoritmo encontra as linhas dos máximos da matriz $A$}
\SET{C}{{REDUCAO}(A)} \label{maxTotMonotonica:reduce}
\SET{n}{$ nº de linhas de $C}
\IF {n=1}
	\COM{Para toda coluna $j$ de $C$ o máximo é a única linha de $C$}
	\SET{m}{$ nº de colunas de $C}
	\DOFORI{j}{0}{m-1} \label{maxTotMonotonica:loop}
		\SET{j*}{$índice em $M$ da coluna $j$ de $C}
		\SET{i*}{$índice em $M$ da linha de $C}
		\SET{I_M[j*]}{i*} \label{maxTotMonotonica:setIJ}
	\OD
\ELSE
	\COM{Cria uma matriz $C'$ com as colunas pares de $C$}
	\SET{C'}{$ colunas pares de $ C} \label{maxTotMonotonica:setA}
	\CALL{maxTotMonotonica}{M,I_M,C'} \label{maxTotMonotonica:recursao}
	\COM{Coloca em $I_M$ os máximos das colunas ímpares de $C$}
	\CALL{maxImpar}{M,I_M,C} \label{maxTotMonotonica:maxImpar}
\FI
\caption[maxTotMonotonica]{Coloca em $I_M(j)$ o índice da linha do máximo da coluna $j$}
\label{alg:maxTotMonotonica}
\end{algo}
\end{algorithm}

\begin{algorithm}[htbp]
\begin{algo}{maxImpar}{M,I_M,C}
\COM{$C$ é uma submatriz da matriz original $M$}
\COM{As linhas dos máximos das colunas pares de $C$ já estão em
$I_M$ }
\SET{n}{$ nº de linhas de $C}
\SET{m}{$ nº de colunas de $C}
\DOFORS{j}{1}{m-1}{2} \label{maxImpar:loop1}
	\SET{j_1*}{$índice em $M$ da coluna $j-1$ de $C}
	\SET{i_1}{$índice em $C$ da linha $I_M[j_1*]$ de $M}
	\IF {j<m-1}
		\SET{j_2*}{$índice em $M$ da coluna $j+1$ de $C}
		\SET{i_2}{$índice em $C$ da linha $I_M[j_2*]$ de $M}
	\ELSE
		\SET{i_2}{n-1}
	\FI
	\COM{Obtém linha $i_{max}$ que tem o máximo em $j$. ($i_1 \leq
	i_{max} \leq i_2$) }
	\SET{i_{max}}{i_1} \label{maxImpar:inicvintervalo}
	\DOFORI{i}{i_1+1}{i_2} \label{maxImpar:loop2}
		\IF {C[i,j]>C[i_{max},j]}
			\SET{i_{max}}{i}
		\FI
	\OD \label{maxImpar:fimvintervalo}
		\SET{j*}{$índice em $M$ da coluna $j$ de $C}
		\SET{i*}{$índice em $M$ da linha $i_{max}$ de $C}
		\SET{I_M[j*]}{i*} 
 \OD
\caption[maxImpar]{Coloca em $I_M$ os índices das linhas dos máximos das
colunas ímpares de uma matriz monotônica $C$}
\label{alg:maxImpar}
\end{algo}
\end{algorithm}

O Algoritmo~\ref{alg:maxImpar} é simples e a prova de sua corretude será
omitida. Mostramos a seguir somente uma breve descrição da sua execução assim
como uma breve análise do tempo da sua execução. 

Pela fato de $C$ ser uma matriz monotônica $n \times m$, o índice da linha do
máximo de uma coluna ímpar $j$ deve estar entre:
\begin{itemize}
  \item $I_C[j-1]$ e $I_C[j+1]$ se $j<m-1$ ou entre
  \item $I_C[j-1]$ e $n-1$ se $j=m-1$.
\end{itemize} 

Essencialmente, o algoritmo usa esta propriedade para encontrar o má\-xi\-mo da 
cada coluna ímpar da matriz $C$ da seguinte forma: para cada coluna encontra o 
intervalo de linhas onde deve estar o máximo da coluna e percorre este 
intervalo, entre as 
linhas~\ref{maxImpar:inicvintervalo}~e~\ref{maxImpar:fimvintervalo} do 
algoritmo, para obter o máximo.


Devido a esta restrição no intervalo de busca do máximo de cada coluna ímpar, o 
algoritmo executa a linha~\ref{maxImpar:loop2} no máximo $n-1$ vezes. Portanto, 
para $n \geq m$, o Algoritmo~\ref{alg:maxImpar} é executado em 
tempo\footnote{Se $m \geq n$ então o Algoritmo~\ref{alg:maxImpar} executa em 
tempo $O(m)$, ou seja, o Algoritmo~\ref{alg:maxImpar} executa em tempo 
$O(n+m)$.} $O(n)$. Vale a pena ressaltar que, tomando-se certos cuidados nas 
estruturas de dados utilizadas para representar uma submatriz de $M$, as 
operações de conversão de linhas e colunas de uma submatriz de $M$ para $M$, e 
vice-versa, nos Algoritmos~\ref{alg:maxTotMonotonica}~e~\ref{alg:maxImpar} 
podem ser executadas em tempo constante\footnote{Em nossa implementação 
representamos uma submatriz de $M$ através de uma lista ligada de linhas, sendo 
que cada linha tem uma referência a linha correspondente da matriz $M$. As 
colunas de um submatriz de $M$ foram restritas através de um número $k$, tal 
que uma coluna $j$ da submatriz é igual à coluna $j*2^k$ de $M$.}.

A seguir segue uma breve descrição do funcionamento do 
Algoritmo~\ref{alg:maxTotMonotonica}. Vamos considerar que a matriz 
$M$ $n \times m$ é a matriz original para a qual queremos resolver o 
problema~\ref{prob:maxcol} e que $n \geq m$.

Na linha~\ref{maxTotMonotonica:reduce}, o algoritmo obtém uma matriz $C$ 
retirando algumas linhas mortas da matriz $A$ (através do 
Algoritmo~\ref{alg:reducao}). Se o algoritmo estiver sendo executado pela 
chamada da linha~\ref{maxTotMonotonica:recursao} do próprio 
Algoritmo~\ref{alg:maxTotMonotonica}, ou seja, estiver sendo executado dentro 
da recursão, então a matriz $A$ é $n \times \lceil\frac{n}{2}\rceil $ e a 
matriz $C$ será $\lceil\frac{n}{2}\rceil \times \lceil\frac{n}{2}\rceil$.

Se a matriz $C$ tem uma única linha, então a linha que tem os máximos das 
colunas é esta única linha e o algoritmo coloca em $I_M$, nas posições das 
colunas de $C$, o índice desta linha. Vale a pena ressaltar que se o algoritmo 
estiver sendo executado por uma chamada recursiva, então há somente uma coluna 
em $C$ e portanto, somente uma posição em $I_M$ onde será colocado o índice da 
linha de $C$.

Se a matriz $C$ tem mais do que uma linha, então o 
Algoritmo~\ref{alg:maxTotMonotonica} obtém os valores dos máximos das colunas 
pares, fazendo uma chamada recursiva na linha~\ref{maxTotMonotonica:recursao} e 
utilizando a submatriz $C'$ de $C$ restrita às colunas pares. Para encontrar os 
máximos das colunas ímpares de $C$ o Algoritmo~\ref{alg:maxTotMonotonica} 
utiliza o Algoritmo~\ref{alg:maxImpar} na linha~\ref{maxTotMonotonica:maxImpar}.

A seguir mostramos a análise do tempo de execução do 
Algoritmo~\ref{alg:maxTotMonotonica}.

Seja $m$ o número de colunas de $A$ e $n$ o número de linhas de $A$. Como 
estamos considerando que o número de linhas de $M$ é maior que o número colunas 
de $M$ e na chamada externa do algoritmo $A=M$, então podemos considerar que $n 
\geq m$.

Vimos que a linha~\ref{maxTotMonotonica:reduce} é executada em tempo $O(n)$. A 
linha~\ref{maxTotMonotonica:loop} é executada no máximo $m$ vezes. Vimos também 
que a linha~\ref{maxTotMonotonica:maxImpar} é executada em tempo $O(m)$. Seja 
$t(n,m)$ o tempo de execução do Algoritmo~\ref{alg:maxTotMonotonica} então a 
linha~\ref{maxTotMonotonica:recursao} é executada em tempo $t(m,m/2)$.

Portanto o tempo de execução do Algoritmo~\ref{alg:maxTotMonotonica} é dado 
pela seguinte recorrência: \[t(n,m) \leq c_1 n + c_2 m + t(m,m/2), \] onde 
$c_1$ e $c_2$ são constantes positivas e $n \geq m$. Resolvendo esta 
recorrência obtemos que $t(n,m) = O(n)$.

Portanto o tempo de execução do Algoritmo~\ref{alg:maxTotMonotonica} é $O(n)$ e 
conseguimos resolver o Problema~\ref{prob:maxcol} em tempo $O(n)$ para matrizes 
totalmente monotônicas com $n \geq m$.

Segundo Aggarwal et al.\ \cite{MR895444} se $m>n$ então o 
Problema~\ref{prob:maxcol} pode ser resolvido em tempo $\Theta(n(1+\log(m/n))$. 
Neste texto utilizaremos matrizes totalmente monotônicas onde $n \geq m$.

Assim como a matriz $C$ pode ser construída com referências às linhas de $A$, a 
matriz $C'$ pode ser construída com referências às colunas de $C$. Seja 
$e(n,m)$ o espaço em memória utilizado pelo 
Algoritmo~\ref{alg:maxTotMonotonica}. Temos que \[e(n,m) \leq c_3n + c_4m + 
e(m,m/2),\] onde $c_3$ e $c_4$ são constantes positivas. Resolvendo esta 
recorrência obtemos que $e(n,m) = O(n)$.

Logo, dados a matriz $M$ e o vetor $I_M$, a memória consumida pelo 
Algoritmo~\ref {alg:maxTotMonotonica} é $O(n)$.

\section{Matriz de Monge} 
\label{sec:monge}

\begin{definicao}[Matriz de monge] Uma matriz $M$ ${n \times m}$ é dita uma 
matriz de monge se \[M[i_1,j_1]+M[i_2,j_2] \leq M[i_1,j_2]+M[i_2,j_1]\] para 
todo $i_1, i_2, j_1, j_2$ tais que $0 \leq i_1 < i_2 \leq n-1$ e $0 \leq j_1 < 
j_2 \leq m-1$.
\end{definicao}

Algumas vezes a desigualdade é verdadeira na direção inversa. Neste caso temos uma
matriz de monge inversa.

\begin{definicao}[Matriz de monge inversa] Uma matriz $M$ ${n \times m}$ é di\-ta 
uma matriz de monge inversa se $M[i_1,j_1]+M[i_2,j_2] \geq 
M[i_1,j_2]+M[i_2,j_1]$ para todo $i_1, i_2, j_1, j_2$ tais que $0 \leq i_1 < 
i_2 \leq n-1$ e $0 \leq j_1 < j_2 \leq m-1$.
\end{definicao}

Um caso particular, mas muito comum de matriz de monge, é a  matriz de monge 
triangular superior (inferior). Neste tipo de matriz, para toda posição 
$(i,j)$, tal que $i>j$ (ou $i<j$ se inferior), o elemento da posição $(i,j)$ é 
$M[i,j]=+\infty$.\footnote{Alguns autores preferem a seguinte definição para 
Matriz de monge triangular superior (inferior): uma matriz $M$ ${n \times m}$ é 
dita uma matriz de monge triangular superior (ou inferior) se 
$M[i_1,j_1]+M[i_2,j_2] \leq M[i_1,j_2]+M[i_2,j_1]$ para todo $i_1, i_2, j_1, 
j_2$ tais que $0 \leq i_1 < i_2 \leq j_1 < j_2 \leq m-1$ (ou $0 \leq j_1 < j_2 
\leq i_1 < i_2 \leq n-1$ se inferior).} De forma análoga, definimos a matriz de 
monge inversa triangular superior e matriz de monge inversa triangular 
inferior, usando $M[i,j]=-\infty$ nas posições desprezadas.

Uma propriedade muitas vezes útil para a verificação de que uma determinada 
matriz é de monge, é que para que uma matriz seja uma matriz de monge basta que 
a desigualdade seja satisfeita para as linhas e colunas adjacentes, ou seja, 
\[M[i,j]+M[i+1,j+1] \leq M[i,j+1]+M[i+1,j]\] para todo $i,j$ tal que $0 \leq i 
< n-1$ e $0 \leq j < m-1$. Propriedade análoga vale para matriz de monge 
inversa.

Outra propriedade muito importante é que toda matriz de monge (ou monge 
inversa) é uma matriz totalmente monotônica. Isto é útil, principalmente, nos 
casos em que se deseja determinar os máximos das colunas de uma matriz de monge 
(ou monge inversa).

Sejam $M$ e $N$ duas matrizes ${n \times m}$ de monge (ou monge inversa). Sejam 
$U$ um vetor de comprimento $n$ e $V$ um vetor de comprimento $m$. Seja $c$ uma 
constante tal que $c \geq 0$. Seja $M^T$ a matriz transposta de $M$. Podemos 
afirmar que as seguintes matrizes também são matrizes de monge (ou monge 
inversa):
\begin{itemize}
  \item $M^T$,
  \item $M+N$,
  \item $c M$,
  \item $A \tq A[i,j]=M[i,j]+U[i]+V[j]$.
\end{itemize}

\section{\Opeds}
\label{sec:operacoes}
Nesta seção consideraremos que $\alfabeto$ é um alfabeto qualquer e que $s=s[1\Rng 
n] \in \alfabeto^*$ para $n \geq 0$. Nos exemplos consideraremos que $\alfabeto 
=\{A,C,T,G\}$.

\begin{definicao}[\Oped] Uma \oped\ é qualquer função parcial cujo domínio e 
contra-domínio são $\alfabeto^*$.
\end{definicao}

Em outras palavras, uma função de edição é uma função que quando aplicada em 
uma \seq\ $s \in \alfabeto^*$ gera uma \seq\ $s' \in \alfabeto^*$. Vale a pena 
ressaltar que as \opeds\ sendo funções parciais podem não ser definidas para 
todos os elementos do seu domínio.

As \opeds\ permitem representar o resultado das al\-te\-ra\-ções sofridas nas 
\seqs\ biológicas diante de diferentes tipos de mutações.

A seguir, vamos relacionar para cada mutação, que desejamos analisar, uma 
\oped\ correspondente.
\begin{description}
  \item {Inserção}: Dados $i$ e $a$ tais que $0\leq i$ e $a \in \alfabeto$, 
  dizemos que a função parcial $\opedinssym{i}{a}: \alfabeto^* \rightarrow \alfabeto^*$ 
  definida por $\opedinssym{i}{a}(s)=s[1\Rng i]\ a\ s[i+1\Rng n]$, para $i \leq 
  n$, é uma \emph{\oped\ de inserção}, ou mais especificamente a \emph{\oped\ 
  de inserção de $a$ após a posição $i$}. Por exemplo, 
  $\opedinssym{5}{G}(AACGCCTTCG)=AACGC\mathbf{G}CTTCG$. Diremos que $i$ é o 
  índice desta \oped\ e $a$ é o símbolo envolvido nesta \oped. Dizemos que 
  $\opedinssym{i}{a}$ é uma \oped\ do tipo lacuna (ou \emph{gap}). Chamaremos 
  de \emph{classe de \opeds\ de inserção} o conjunto com todas as possíveis 
  \opeds\ de inserção. Vamos considerar que uma \oped\ de inserção corresponde 
  a uma mutação de inserção.
  
  \item {Remoção}: Dados $i$ e $a$ tais que $1\leq i$ e $a\in \alfabeto^*$, 
  dizemos que a função parcial $\opeddelsym{i}{a}: \alfabeto^* \rightarrow \alfabeto^*$ 
  definida por $\opeddelsym{i}{a}(s)=s[1\Rng i-1] s[i+1\Rng n]$, para $i \leq 
  n$ e $s[i]=a$, é uma \emph{\oped\ de remoção}, ou mais especificamente a 
  \emph{\oped\ de remoção da letra $a$ na posição $i$}. Por exemplo, 
  $\opeddelsym{10}{G}(AACGCCTTC\mathbf{G})=AACGCCTTC$. Diremos que $i$ é o 
  índice desta \oped\ e $a$ é o símbolo envolvido nesta \oped. Dizemos que 
  $\opeddelsym{i}{a}$ é uma \oped\ do tipo lacuna (ou \emph{gap}). Chamaremos 
  de \emph{classe de \opeds\ de remoção} o conjunto com todas as possíveis 
  \opeds\ de remoção. Vamos considerar que uma \oped\ de remoção corresponde a 
  uma mutação de remoção.
  
  \item {Substituição}: Dados $i$, $a$ e $b$ tais que $1\leq i$, $a \in 
  \alfabeto$ e $b \in \alfabeto$, dizemos que a função parcial $\opedsubsym{i}{a}{b}: 
  \alfabeto^* \rightarrow \alfabeto^*$ definida por 
  $\opedsubsym{i}{a}{b}(s)=s[1\Rng i-1] a s[i+1\Rng n]$, para $i \leq n$ e 
  $s[i]=b$, é uma \emph{\oped\ de substituição}, ou mais especificamente a 
  \emph{\oped\ de substituição da letra $b$ na posição $i$ por $a$}. Por 
  exemplo, $\opedsubsym{1}{G}{A}(\mathbf{A}ACGCCTTCG)=\mathbf{G}ACGCCTTCG$. 
  Diremos que $i$ é o índice desta \oped\ e $a$ e $b$ são os símbolos 
  envolvidos nesta \oped. Se $a=b$ então dizemos que $\opedsubsym{i}{a}{b}$ é 
  uma \oped\ do tipo casamento (ou \emph{match}). Se $a\neq b$ então dizemos 
  que $\opedsubsym{i}{a}{b}$ é uma \oped\ do tipo erro (ou \emph{mismatch}). 
  Chamaremos de \emph{classe de \opeds\ de substituição} o conjunto com todas 
  as possíveis \opeds\ de substituição. Vamos considerar que uma \oped\ de 
  substituição corresponde a uma mutação de substituição.
  
  \item {Inversão}: Dados $i$ e $i'$ tais que $1\leq i \leq i'+1$, dizemos que 
  a função parcial $\opedinvsym{i}{i'}: \alfabeto^* \rightarrow \alfabeto^*$ definida 
  por $\opedinvsym{i}{i'}(s)=s[1\Rng i-1] \invert{s[i\Rng i']}  s[i'+1\Rng n]$, 
  para $i' \leq n$, é uma \emph{\oped\ de inversão}, ou mais especificamente, a 
  \emph{\oped\ de inversão do trecho de $i$ a $i'$}. Por exemplo, 
  $\opedinvsym{4}{7}(AAC\mathbf{GCCT}TCG)=AAC\mathbf{AGGC}TCG$. Repare que 
  $\invert{GCCT}=AGGC$, pois consideramos que a operação de inversão mapeia um 
  trecho no seu reverso complementar. Diremos que $i$ e $i'$ são os índices 
  desta \oped. Diremos que os símbolos nas posições de $i$ a $i'$, ou seja, nas 
  posições do intervalo $[i,i']$, são os símbolos envolvidos nesta \oped\ e são
  substituídos pelo seu complementar reverso. Chamaremos de \emph{classe de \opeds\ de
  inversão} o conjunto com todas as 
  possíveis \opeds\ de inversão. Vamos considerar que uma \oped\ de inversão 
  corresponde a uma mutação de inversão.
  
  \item {Duplicação}: Dados $i_1$, $i_2$ e $i_3$ tais que $1\leq i_1 \leq i_2$ 
  e $0 \leq i_3$ dizemos que a função parcial $\opeddupsym{i_1}{i_2}{i_3}: \alfabeto^* 
  \rightarrow \alfabeto^*$ definida por $\opeddupsym{i_1}{i_2}{i_3}(s)=s[1\Rng 
  i_3]s[i_1\Rng i_2]s[i_3+1\Rng n]=s'$, $i_2 \leq n$ e $i_3 \leq n$, é uma 
  \emph{\oped\ de duplicação}, ou mais especificamente a \emph{\oped\ de 
  duplicação do trecho de $i_1$ a $i_2$ após a posição $i_3$}. Diremos que, 
  para esta \oped\ de duplicação a \seq\ $s[i_1\Rng i_2]$ é a \emph{\seq\ 
  original} e a \seq\ $s'[i_3+1\Rng i_3+i_2-i_1+1]$ é a \emph{cópia} ou 
  \emph{repetição}. Por exemplo, 
  $\opeddupsym{4}{7}{9}(AAC\mathbf{GCCT}TCG)=AACGCCTTC\mathbf{GCCT}G$. Diremos 
  que $i_1$, $i_2$ e $i_3$ são os índices desta \oped. Chamaremos de 
  \emph{classe de \opeds\ de duplicação} o conjunto com todas as possíveis 
  \opeds\ de duplicação. Vamos considerar que uma \oped\ de duplicação 
  corresponde a uma mutação de duplicação.
  
  \item {Excisão}: Dados $i_1$, $i_2$ e $i_3$ tais que $1\leq i_1 \leq i_2$ e 
  $0 \leq i_3$ dizemos que a função parcial $\opedexcsym{i_1}{i_2}{i_3}: \alfabeto^* 
  \rightarrow \alfabeto^*$ definida por $\opedexcsym{i_1}{i_2}{i_3}(s)=s[1\Rng 
  i_1-1]s[i_2+1\Rng n]=s'$ tal que $s'[i_3\Rng i_3+i_2-i_1]=s[i_1\Rng i_2]$, 
  para $i_2 \leq n$ e $i_3 \leq n-(i_2-i_1+1)$, é uma \emph{\oped\ de excisão}, 
  ou mais especificamente a \emph{\oped\ de excisão do trecho de $i_1$ a $i_2$ 
  existente na posição $i_3$}. Diremos que, para esta \oped\ de excisão a \seq\ 
  $s[i_1\Rng i_2]$ é a \emph{cópia} ou \emph{repetição} e a \seq\ $s'[i_3\Rng 
  i_3+i_2-i_1]$ é a \emph{\seq\ original}. Por exemplo, 
  $\opeddupsym{10}{13}{4}(AACGCCTTC\mathbf{GCCT}G)=AAC\mathbf{GCCT}TCG$. 
  Observe que no exemplo 
  $\opeddupsym{6}{9}{4}(AACGC\mathbf{GCCT}CTTCG)=AAC\mathbf{GCCT}TCG$ não 
  e\-xis\-te um fragmento em $s$, exceto a repetição, que seja igual à \seq\ 
  original. Diremos que $i_1$, $i_2$ e $i_3$ são os índices desta \oped. 
  Chamaremos de \emph{classe de \opeds\ de excisão} o conjunto com todas as 
  possíveis \opeds\ de excisão. Vamos considerar que uma \oped\ de excisão 
  corresponde a uma mutação de excisão.
\end{description}

Chamamos as \opeds\ definidas acima de \emph{\opeds\ elementares}.

Seja \opedsym\ uma \oped\ elementar. Se $\opedsym$ é uma \oped\ de inserção
ou de remoção ou de substituição então \opedsym\ é
uma \emph{\oped\ pontual}, senão \opedsym\ é uma \emph{\oped\ de rearranjo}.

Seja $\opedseqsym=(\opedsym_1,\opedsym_2,\ldots,\opedsym_k)$ tal que $k 
\geq 0$ e $\opedsym_i$ é uma \oped, para todo $i$ onde $1 \leq i \leq k$. 
Diremos que \opedseqsym\ é uma \emph{\seq\ de \opeds} de comprimento $k$. Se 
$k=0$ então $\opedseqsym$ é a \seq\ de \opeds\ vazia.

Assim, dado uma \seq\ de \opeds\ 
$\opedseqsym=(\opedsym_1,\opedsym_2,\ldots,\opedsym_k)$, dizemos que a função parcial 
$\opedcompsym{\opedseqsym}: \alfabeto^* \rightarrow \alfabeto^*$ definida por 
\begin{displaymath}\opedcompsym{\opedseqsym}(s)= 
\opedsym_k(\opedsym_{k-1}(\ldots \opedsym_2(\opedsym_1(s))\ldots))=(\opedsym_k 
\circ \opedsym_{k-1} \circ \ldots \circ \opedsym_2 \circ 
\opedsym_1)(s)\end{displaymath} é a \emph{\oped\ composta de \opedseqsym}.

Vale a pena ressaltar que, como uma \oped\ qualquer $\opedsym_i$
é uma função parcial, $\opedcompsym{\opedseqsym}$ é também uma função parcial.

\begin{observacao}\label{obs:opedsuf}
Seja $\opedseqsym$ uma \seq\ de \opeds\ elementares. Se 
$\opedcompsym{\opedseqsym}(s)=t$ então $\opedcompsym{\opedseqsym}(sx)=tx$, onde 
$x$ é uma palavra qualquer.
\end{observacao}

%TODO Mostrar esta obs para o Alair

Seja $\opedsym$ uma \oped\ e $\opedsym^{-1}:\alfabeto^* \rightarrow \alfabeto^*$ uma 
\oped\ tal que $\opedsym^{-1}(\opedsym(s))=s$ para qualquer $s$ onde 
$\opedsym(s)$ é definida e $\opedsym(\opedsym^{-1}(s))=s$ para qualquer $s$ 
onde $\opedsym^{-1}(s)$ é definida. Diremos que $\opedsym^{-1}$ é a 
\emph{\oped\ inversa de \opedsym} e que \opedsym\ é uma \emph{\oped\ 
inversível}. Podemos dizer que a \oped\ $\opedsym^{-1}$ desfaz a transformação 
de uma \oped\ $\opedsym$ e vice versa. 

Vale a pena ressaltar que nem todas as \opeds\ são inversíveis. Por exemplo, a 
\oped\ $\opedsym_i$ definida a seguir não é inversível: dado $i$ tal que $1\leq 
i$, definimos $\opedsym_i$ como a função parcial $\opedsym_i: \alfabeto^* \rightarrow 
\alfabeto^*$ tal que $\opedsym_i(s)=s[1\Rng i-1] s[i+1\Rng n]$, para $i \leq n$.

\begin{observacao}
Se uma \oped\ \opedsym\ é inversível então a \oped\ $\opedsym^{-1}$ também é 
inversível e $(\opedsym^{-1})^{-1}=\opedsym$.
\end{observacao}

\begin{observacao}
Sejam as \opeds\ $\opedsym_1,\opedsym_2,\ldots,\opedsym_k$ tal que, para algum 
$i$, $\opedsym_i^{-1}=\opedsym_{i+1}$, onde $1 \leq i < k$, e as \seqs\ de 
\opeds\ 
$\opedseqsym=(\opedsym_1,\ldots,\opedsym_{i},\opedsym_{i+1},\ldots,\opedsym_k)$ 
e 
$\opedseqsym'=(\opedsym_1,\ldots,\opedsym_{i-1},\opedsym_{i+2},\ldots,\opedsym_k)$. 
Temos que $\opedcompsym{\opedseqsym}(s)= \opedcompsym{\opedseqsym'}(s)$.
\end{observacao}

\begin{proposicao}
As \opeds\ elementares são inversíveis e suas inversas são também \opeds\ 
elementares e são listadas a seguir:
\begin{align*}
&{\opedinssym{i}{a}}:&(\opedinssym{i}{a})^{-1}&=\opeddelsym{i+1}{a}&&&\\
&{\opeddelsym{i}{a}}:&(\opeddelsym{i}{a})^{-1}&=\opedinssym{i-1}{a}&&&\\
&{\opedsubsym{i}{a}{b}}:&(\opedsubsym{i}{a}{b})^{-1}&=\opedsubsym{i}{b}{a}&&&\\
&{\opedinvsym{i}{i'}}:&(\opedinvsym{i}{i'})^{-1}&=\opedinvsym{i}{i'}&&&\\
&{\opeddupsym{i}{i_1}{i_2}}:& 
(\opeddupsym{i}{i_1}{i_2})^{-1}&=\opedexcsym{i_2+1}{i_2+1+i_1-i}{i}&&&\\
&{\opedexcsym{i}{i_1}{i_2}}:& 
(\opedexcsym{i}{i_1}{i_2})^{-1}&=\opeddupsym{i_2}{i_2+i_1-i}{i-1}.&&&
\end{align*}
\end{proposicao}
\begin{prova}
Observe que:
\begin{enumerate}
  \item $\opeddelsym{i+1}{a}(\opedinssym{i}{a}(s))=\opeddelsym{i+1}{a}(s[1\Rng 
  i]\ a\ s[i+1\Rng n])=s[1\Rng i]s[i+1\Rng n]=s$ e
  \item $\opedinssym{i}{a}(\opeddelsym{i+1}{a}(s))=\opedinssym{i}{a}(s[1\Rng i] 
  s[i+2\Rng n])=s[1\Rng i]\ a\ s[i+2\Rng n]=s$.
\end{enumerate}
  Portanto a inversa de $\opedinssym{i}{a}$ é $\opeddelsym{i+1}{a}$. De modo 
  similar pode-se provar que as inversas das outras \opeds\ elementares são as 
  listadas no enunciado da proposição. \cqd
\end{prova}

Seja $\opedseqsym=(\opedsym_1,\opedsym_2,\ldots,\opedsym_k)$ tal que 
$\opedsym_i$ é uma \oped\ inversível, para todo $i$ tal que $1 \leq i \leq k$. 
Temos que a \oped\ composta de \opedseqsym\ é inversível e sua inversa é dada 
por \begin{displaymath}(\opedcompsym{\opedseqsym})^{-1}= (\opedsym_1)^{-1} 
\circ (\opedsym_{2})^{-1} \circ \ldots \circ (\opedsym_{k-1})^{-1} \circ 
(\opedsym_k)^{-1}.\end{displaymath} Neste caso, dizemos que 
$\opedseqsym^{-1}=((\opedsym_k)^{-1},(\opedsym_{k-1})^{-1},\ldots,(\opedsym_1)^{-1})$ 
é a \seq\ inversa de \opedseqsym\ e 
$(\opedcompsym{\opedseqsym})^{-1}=\opedcompsym{\opedseqsym^{-1}}$.

\section{Grafo de edição}
\label{sec:editgraph}

Sejam $s$ e $t$ duas seqüências de comprimentos $n$ e $m$ respectivamente.

Seja $e=(u,v)$ uma aresta que liga o vértice $u$ ao vértice $v$ de um grafo 
qualquer. Dizemos que $\startedge{e}=u$ e $\finishedge{e}=v$.

\begin{definicao}[Grafo de edição de $s$ e $t$] O grafo de edição de $s$ e $t$ 
é o grafo orientado com pesos nas arestas $G=(V,E,\egweigsym)$, onde: 
\begin{enumerate}[\tabenum 1)]
\item $V=\{(i,j)| 0 \leq i \leq n, 0 \leq j \leq m\}$.
\item $E=E_H \cup E_D \cup E_V$, tal que:
\begin{itemize}
  \item $E_H=\{((i, j-1), (i, j))|0 \leq i \leq n, 0 < j \leq m\}$ é o conjunto 
  das arestas horizontais de $G$;
  \item $E_D=\{((i-1, j-1), (i, j))|0 < i \leq n, 0 < j \leq m\}$ é o conjunto 
  das arestas diagonais de $G$;
  \item $E_V=\{((i-1, j), (i, j))|0 < i \leq n, 0 \leq j \leq m\}$ é o conjunto 
  das arestas verticais de $G$.
\end{itemize}
  \item A função $\egweigsym: E \aplica \realset \cup\{-\infty\}$ associa a 
  cada aresta $e \in E$ o seu peso $\egweige{e}$.
\end{enumerate}
\end{definicao}

Seja $G$ um grafo de edição de $s$ e $t$.

As arestas $\egeh{(i,j)}=((i, j-1), (i, j))$, $\eged{(i,j)}=((i-1, j-1), 
(i, j))$ e $\egev{(i,j)}=((i-1, j), (i, j))$ de $G$ são as
arestas \emph{horizontal}, \emph{diagonal} e \emph{vertical}, respectivamente, 
\emph{de $G$ que chegam em $(i,j)$}.

A figura~\ref{fig:exemploeg} ilustra a forma de um grafo de edição com $n=3$ e 
$m=3$. Repare que neste exemplo, para não sobrecarregar demais a figura, não 
mostramos os valores de $\egweige{e}$ para qualquer aresta $e$ do grafo.

\begin{figure}
 \centering
\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{exemploeg}
% \end{center}
 \caption{Exemplo de grafo de edição}
 \label{fig:exemploeg}
\end{figure}

A cada aresta $\egesym$ de um \gred\ $G$ de $s$ e $t$ vamos associar uma \oped\
pontual da seguinte forma:
\begin{itemize}
  \item $\egesym=\eged{(i,j)}$ está associada a \oped\
  $\opedsubsym{j}{t[j]}{s[i]}$,
  \item $\egesym=\egeh{(i,j)}$ está associada a \oped\
  $\opedinssym{j-1}{t[j]}$,
  \item $\egesym=\egev{(i,j)}$ está associada a \oped\
  $\opeddelsym{j+1}{s[i]}$.
\end{itemize}

Com esta associação, podemos dizer que um caminho $P$ de $(0,0)$ a $(n,m)$ em 
$G$ está associado a uma \seq\ $\opedseqsym$ de \opeds\ pontuais, tal que 
$\opedcompsym{\opedseqsym}(s)=t$. Ou seja, qualquer caminho de $(0,0)$ a 
$(n,m)$ em $G$ corresponde a uma \seq\ de \opeds\ pontuais que transforma $s$ 
em $t$.

Na verdade, podemos afirmar que qualquer caminho de $(i_1.j_1)$ a $(i_2,j_2)$ 
em $G$ corresponde a uma \seq\ de \opeds\ que transforma $s[i_1+1 \Rng i_2]$ em 
$t[j_1+1 \Rng j_2]$, alterando-se apenas os índices da \oped\ associada a cada 
aresta \egesym\ da seguinte forma:
\begin{itemize}
  \item $\egesym=\eged{(i,j)}$ está associada a \oped\ 
  $\opedsubsym{j-j_1}{t[j]}{s[i]}$,
  \item $\egesym=\egeh{(i,j)}$ está associada a \oped\ 
  $\opedinssym{j-1-j_1}{t[j]}$,
  \item $\egesym=\egev{(i,j)}$ está associada a \oped\ 
  $\opeddelsym{j+1-j_1}{s[i]}$.
\end{itemize}

  
\begin{definicao}[Grafo de edição estendido] O grafo de e\-di\-ção estendido de 
$s$ e $t$ é o grafo orientado com pesos nas arestas $G=(V,E,\egweigsym)$, onde: 
\begin{enumerate}[\tabenum 1)]
\item $V=\{(i,j)| 0 \leq i \leq n, 0 \leq j \leq m\}$.
\item $E=E_H \cup E_D \cup E_V \cup E_X$, tal que:
\begin{itemize}
   \item $E_H=\{((i, j-1), (i, j))|0 \leq i \leq n, 0 < j \leq m\}$ é o 
   conjunto das arestas horizontais de $G$;
   \item $E_D=\{((i-1, j-1), (i, j))|0 < i \leq n, 0 < j \leq m\}$ é o conjunto 
   das arestas diagonais de $G$;
   \item $E_V=\{((i-1, j), (i, j))|0 < i \leq n, 0 \leq j \leq m\}$ é o 
   conjunto das arestas verticais de $G$;
   \item $E_X=\bigcup_{i=0}^{n}\bigcup_{j=0}^{m} E_X^{i,j}$ é o conjunto das 
   arestas estendidas de $G$, tal que:
   \begin{itemize}
     \item  $E_X^{i,j}=\{((i', j'), (i, j)) \tq 0 \leq i' \leq i \leq n, 0 \leq 
     j' \leq j \leq m \mbox{ e } (i',j') \neq (i,j)\}$ é o conjunto das arestas 
     estendidas que chegam no vértice $(i,j)$ de $G$ e
     \item $E_X \cap \{E_H \cup E_D \cup E_V\}=\emptyset$.
	\end{itemize}
\end{itemize}
     \item A função $\egweigsym: E \aplica \realset \cup\{-\infty\}$ associa a 
     cada aresta $\egesym \in E$ o seu peso $\egweige{\egesym}$.
\end{enumerate}

\end{definicao}

Seja $G$ um grafo de edição estendido de $s$ e $t$.

As arestas $\egeh{(i,j)}=((i, j-1), (i, j))$, $\eged{(i,j)}=((i-1, j-1), (i, 
j))$ e $\egev{(i,j)}=((i-1, j), (i, j))$ de $G$, tais que $\egeh{(i,j)} \in 
E_H$, $\eged{(i,j)} \in E_D$ e $\egev{(i,j)} \in E_V$, são as arestas 
\emph{horizontal}, \emph{diagonal} e \emph{vertical}, respectivamente, 
\emph{de $G$ que chegam em $(i,j)$} e serão chamadas de arestas simples.

As arestas $\egex{(i',j')}{(i,j)}=((i', j'), (i, j))$ de $G$ tais que 
$\egex{(i',j')}{(i,j)}\in E_X^{i,j}$ são as \emph{arestas estendidas de $G$ que 
chegam em $(i,j)$}.

A figura~\ref{fig:exemploegestendido} ilustra a forma de um grafo de edição 
estendido com $n=3$ e $m=3$, onde somente as arestas estendidas que chegam em 
$(1,2)$ são mostradas. Repare que neste exemplo, novamente para não 
sobrecarregar demais a figura, não mostramos as outras arestas estendidas além 
dos valores de $\egweige{e}$ para qualquer aresta $e$ do grafo.

\begin{figure}
 \centering
\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{exemploegestendido}
% \end{center}
 \caption{Exemplo de \gredes}
 \label{fig:exemploegestendido}
\end{figure}

Repare que podem existir até duas arestas que saem de $(i',j')$ e chegam em 
$(i,j)$. Por exemplo, na figura~\ref{fig:exemploegestendido} pode-se observar 
que  $\eged{(1,2)}$ e $\egex{(0,1)}{(1,2)}$ são duas arestas que saem de 
$(0,1)$ e chegam em $(1,2)$.

Seja $\widehat{G}$ um grafo de edição estendido de $s$ e $t$. Seja $G$ o grafo 
obtido de $\widehat{G}$ removendo-se as arestas estendidas. Temos que $G$ é um 
grafo de edição de $s$ e $t$.

Seja $G$ um grafo de edição de $s$ e $t$ ou um grafo de edição estendido de $s$
e $t$.

Sejam $u=(i,j)$ e $v=(i',j')$ dois vértices de $G$. Iremos considerar que um 
caminho $P$ de $u$ a $v$ é ótimo se ele tiver peso máximo entre todos os 
caminhos de $u$ a $v$. Dizemos que $\egweigp{u}{v}$ é o peso de um caminho 
ótimo de $u$ a $v$. Se não houver um caminho de $u$ a $v$ então 
$\egweigp{u}{v}=-\infty$.
  
Subentendendo-se uma disposição matricial natural dos vértices de $G$, dizemos 
que $G$ tem $n+1$ linhas e $m+1$ colunas. Mais ainda, dizemos que o vértice 
$v=(i,j)$ está na linha $\egrowv v=i$ e na coluna $\egcolv v=j$.

Todos os algoritmos que apresentaremos neste texto, que têm como objetivo a 
obtenção de um alinhamento ótimo, estão baseados em grafos de edição e grafos 
de edição estendidos. Em particular, os caminhos em um grafo de edição ou em um 
grafo de edição estendido serão mapeados para um alinhamento.

\chapter{Alinhamento}
\label{cap:alinhamento}
\section{Alinhamento usual}\label{sec:alinhamentousual}
Quando duas seqüências tem alto grau de semelhança é esperado que elas se 
diferenciem apenas em pequenos trechos. Normalmente as diferenças nestes 
trechos são con\seqs\ da ocorrência de alguns eventos \bios. Em geral, para a 
visualização destes eventos ocorridos, é feito um procedimento de alinhamento 
entre as duas seqüências. Procedimentos de alinhamento típicos tentam 
identificar que partes não mudam e, nas partes que mudam, quais os eventos 
biológicos que ocasionaram as mudanças.

O alinhamento de \seqs\ \bioas\ é uma das principais técnicas utilizadas por 
biólogos para comparar \seqs.

Neste capítulo vamos considerar que $\alfabeto$ é um alfabeto com um número 
constante de símbolos. Vamos considerar também que $\aligngap \notin \alfabeto$
e $\alfabetoaligngap = \alfabeto \cup \{\aligngap\}$. Chamaremos o símbolo 
$\aligngap$ de espaço (ou \emph{gap}).

\begin{definicao}[Alinhamento de $s$ e $t$] Sejam $s=\alfabeto^*$ e 
$t=\alfabeto^*$ duas \seqs\ de comprimentos $n$ e $m$, respectivamente. Um 
alinhamento de $s$ e $t$ é uma matriz $A_{2 \times r}$, tal que:
\begin{itemize}
  \item $r \geq m$, $r \geq n$, $r \leq m+n$,
  \item para todo $j$ tal que $0 \leq j \leq r-1$, se $A[0,j]=A[1,j]$ então 
  $A[0,j] \neq \aligngap$ e
  \item existem duas sub\seqs\ $S=(i_1, i_2, \ldots, i_n)$ e $T=(j_1, j_2, 
  \ldots, j_m)$ dos índices das colunas de $A$, tais que:
  \begin{itemize}
    \item $s=A[0,i_1]A[0,i_2]\ldots A[0,i_n]$,
    \item $t=A[1,j_1]A[1,j_2]\ldots A[1,j_m]$,
    \item $A[0,i]=\aligngap$ para toda coluna $i$ de $A$, tal que $i \notin S$, 
    e
    \item $A[1,j]=\aligngap$ para todo coluna $j$ de $A$, tal que $j \notin T$.
  \end{itemize} 
\end{itemize} 
\end{definicao}

Em outras palavras, um alinhamento de $s$ e $t$ é uma matriz $A$ com duas 
linhas de comprimento $r$ tal que, a primeira linha de $A$ é a \seq\ $s$ 
alterada com possíveis espaços inseridos entre os seus símbolos ou nas suas 
extremidades, e a segunda linha de $A$ é a \seq\ $t$ alterada com possíveis 
espaços inseridos entre os seus símbolos ou nas suas extremidades. Além disso, 
para que $A$ seja um alinhamento, assumimos que toda coluna de $A$ tem pelo 
menos um símbolo em $\alfabeto$. Dizemos que o comprimento do alinhamento $A$ é 
$r$.

O exemplo~\ref{ex:align} mostra um alinhamento das \seqs\\
$s=AGCGTATCCAGT$ e $t=AGTATCACGGAT$.

\begin{exemplo}[Alinhamento de duas \seqs]
\label{ex:align}
\[A=\left[\begin{array}{cccccccccccccc} A&G&C&G&T&\aligngap&A&T&C&C&A&G&\aligngap&T\\
A&G&T&A&T&C&A&\aligngap&C&G&\aligngap&G&A&T \end{array}\right]\]
\end{exemplo}

Neste capítulo consideraremos que $s$ e $t$ são duas \seqs\ em $\alfabeto^*$ e que
$A$ é um alinhamento de $s$ e $t$ de comprimentos $n$ e $m$, respectivamente.

De acordo com os espaços contidos em uma coluna $k$ de $A$, esta coluna $k$ 
pode ser classificada nos seguintes tipos:
\begin{description}
\item[\emph{Substituição}:] se existem $i$ e $j$ tais que $s[i]$ e $t[j]$ estão 
na coluna $k$ então esta é uma coluna de substituição. Neste caso, dizemos que 
$s[i]$ e $t[j]$ estão alinhados em $A$, ou mais especificamente, $s[i]$ e 
$t[j]$ estão alinhados na coluna $k$ de $A$. Se $s[i]=t[j]$ então dizemos que 
há um \emph{casamento} (ou \emph{match}) na coluna $k$ de $A$. Se $s[i]\neq 
t[j]$ então dizemos que há um \emph{erro} (ou \emph{mismatch}) na coluna $k$ de 
$A$.

\item[\emph{Inserção}:] se $A[0,k]= \aligngap$ e existe $j$ tal que $t[j]$ está 
na coluna $k$ então esta é uma coluna de inserção. Neste caso, dizemos que 
$t[j]$ está alinhado com um espaço em $A$, ou mais especificamente, $t[j]$ está 
alinhado com um espaço na coluna $k$ de $A$. Dizemos que há uma \emph{lacuna} 
(ou \emph{gap}) na coluna $k$ de $A$.

\item[\emph{Remoção}:] se $A[1,k]= \aligngap$ e existe $i$ tal que $s[i]$ está 
na coluna $k$ então esta é uma coluna de remoção. Neste caso, dizemos que 
$s[i]$ está alinhado com um espaço em $A$, ou mais especificamente, $s[i]$ está 
alinhado com um espaço na coluna $k$ de $A$. Dizemos que há uma \emph{lacuna} 
(ou \emph{gap}) na coluna $k$ de $A$.
\end{description}

Diremos que $\alignset$ é o conjunto de todos os possíveis alinhamentos de 
quaisquer duas \seqs. Dado $s$, diremos que $\alignsets{s}$ é o conjunto de 
todos os possíveis alinhamentos de $s$ e qualquer \seq\ ou de qualquer \seq\ e 
$s$. Dados $s$ e $t$, diremos que $\alignsetst{s}{t}$ é o conjunto de todos os 
possíveis alinhamentos de $s$ e $t$.

Diremos que $A[i,j \Rng j']$ é a palavra $A[i,j]A[i,j+1]\ldots A[i,j']$. Se $j' 
< j$ então $A[i,j \Rng j']$ é a palavra vazia. Por exemplo, no 
Exemplo~\ref{ex:align} a palavra $A[0,3 \Rng 7]$ é igual a $GT{\aligngap}AT$.

Seja a função parcial $\aligncolsym:\alfabeto^* \times \natset \times \alignset 
\rightarrow \natset$ definida por $\aligncol{s}{i}{A}=k$ tal que $i$ é um 
índice de $s$, $A \in \alignsets{s}$ e $k$ é o índice da coluna de $A$ tal que 
$A[l,k]=s[i]$ e existem $k-i+1$ espaços na palavra $A[l,0 \Rng k]$, onde $l=0$ 
se $A$ é um alinhamento de $s$ e $t$ ou $l=1$ se $A$ é um alinhamento de $t$ e 
$s$. Podemos dizer que se $\aligncol{s}{i}{A}=k$ então $s[i]$ está alinhado na 
coluna $k$ de $A$. Como o número de espaços numa palavra é maior ou igual a 
zero, temos que $k-i+1 \geq 0$, ou seja, $k \geq i-1$. Por exemplo, no 
Exemplo~\ref{ex:align}, $\aligncol{s}{5}{A}=4$.

Repare que, como $s[i]$ representa um símbolo, podemos ter outra posição 
$i'\neq i$ tal que $s[i']=s[i]$ e portanto $\aligncol{s}{i'}{A}=k' \neq k$. 
Logo o símbolo $s[i]=s[i']$ está alinhado na coluna $k'$ de $A$ também. Por 
exemplo, no Exemplo~\ref{ex:align}, $\aligncol{t}{10}{A}=11$ e $t[10]=G$ está 
alinhado nas coluna $1$, $9$ e $11$ de $A$.

Seja a função parcial $\alignprefixsym:\alfabeto^* \times \natset \times \alignset 
\rightarrow \alfabeto^*$ definida por $\alignprefix{s}{k}{A}=s[1 \Rng i]$ tal que 
$k$ é um índice de $A$, $A \in \alignsets{s}$ e $s[1 \Rng i]$ é o prefixo de $s$ 
tal que $\aligncol{s}{i'}{A} \leq k$ para todo $i'$ tal que $i' \leq i$ e 
$\aligncol{s}{i''}{A}> k$ para todo $i''$ tal que $i'' > i$. Ou seja, 
$\alignprefix{s}{k}{A}$ é o mais longo prefixo de $s$ cujos elementos estão 
alinhados até a coluna $k$ de $A$. Por exemplo, no Exemplo~\ref{ex:align} 
$\alignprefix{t}{11}{A}=t[1 \Rng 10]=AGTATCACGG$ e 
$\alignprefix{s}{5}{A}=s[1 \Rng 5]=AGCGT$.

\begin{observacao}\label{obs:prefix}
Se $\aligncol{s}{i}{A}=k$ então temos que $\alignprefix{s}{k}{A}=s[1\Rng i]$ e 
$\alignprefix{s}{k - 1}{A} = s[1 \Rng i - 1]$. Repare que se 
$\alignprefix{s}{k}{A}=s[1\Rng i]$ então não necessariamente 
$\aligncol{s}{i}{A}=k$, porém se $\alignprefix{s}{k}{A}=s[1\Rng i]$ e 
$\alignprefix{s}{k-1}{A}=s[1\Rng i-1]$ então $\aligncol{s}{i}{A}=k$. Se 
$\aligncol{s}{i}{A}=k$ e $s[i]$ é alinhado com \aligngap\ na coluna $k$ de $A$ 
então $\alignprefix{t}{k}{A}=\alignprefix{t}{k-1}{A}$.
\end{observacao}

Existem diferentes sistemas de pontuação para alinhamentos, ou maneiras de 
atribuir pontuação a um alinhamento. Um sistema de pontuação muito utilizado é 
aquele que, dada uma função $\alignscore: \{\alfabetoaligngap\} \times 
\{\alfabetoaligngap\} \rightarrow \mathbb{R}$, determina que a pontuação de 
cada coluna $k$ de $A$ é igual a $\alignscore(A[0,k],A[1,k])$ e a pontuação do 
alinhamento $A$ é igual à somatória da pontuação de cada coluna de $A$. 
Chamaremos este sistema de pontuação de sistema de pontuação com custo de 
\emph{gap} linear\label{gaplinear}. Existe um outro sistema de pontuação também muito utilizado 
que determina que a pontuação de uma coluna é igual a 
$\alignscore(A[0,k],A[1,k])+\rho$, onde $\rho$ é diferente de zero se 
$A[0,k]=\aligngap$ e $A[0,k-1]\neq \aligngap$, ou se $A[1,k]=\aligngap$ e 
$A[1,k-1]\neq \aligngap$. Normalmente $\rho$ é chamado de penalidade para 
abertura de lacuna, ou \emph{gap open penalty}. Chamaremos este sistema de 
pontuação de sistema de pontuação com \emph{gap} afim.

A questão de como definir similaridade ainda é controversa. Não existe uma 
única, precisa ou universalmente aceita noção de similaridade, assim como um 
sistema que define ou mede o grau, ou valor, de similaridade. Por exemplo, duas 
proteínas podem ser similares (ou seja, com alto grau de similaridade) com 
relação à sua estrutura, ou com relação à sua função ou com relação à sua \seq. 
Em geral, é a \seq\ que determina a estrutura e a estrutura determina a função. 
Assim, quando analisamos e atribuímos um grau de similaridade às \seqs, 
esperamos que este grau reflita, da mesma forma que nas \seqs, a similaridade 
nas estruturas e nas funções destas \seqs.

Em geral, um alinhamento de \seqs\ é utilizado para visualizar os fragmentos 
iguais e os fragmentos diferentes destas \seqs. No entanto, algumas vezes o 
alinhamento de \seqs\ é utilizado para medir apenas o grau de similaridade das 
\seqs, sem interessar onde estão e quais são as diferenças e as igualdades 
destas \seqs, ou seja, existem situações onde não há interesse em visualizar o 
alinhamento, mas sim em saber o quanto as \seqs\ são similares.

Assumiremos que o sistema de pontuação a ser utilizado em um alinhamento 
considera que a pontuação do alinhamento é diretamente proporcional às 
similaridades mostradas por este alinhamento, ou seja, um alinhamento procura 
medir o grau de similaridade das \seqs. Portanto, assumiremos que um 
\emph{alinhamento ótimo de $s$ e $t$} é aquele que possui pontuação máxima 
dentre todos os possíveis alinhamentos de $s$ e $t$. Desta forma, quanto maior 
a pontuação de um alinhamento ótimo de $s$ e $t$, maior é a similaridade destas 
\seqs. Vale a pena ressaltar que dois alinhamentos diferentes podem ter a mesma 
pontuação e assim podem existir mais de um alinhamento ótimo para um mesmo par 
de \seqs\ e um mesmo sistema de pontuação.

Muitas vezes, quando as \seqs\ têm grau de similaridade, ou pontuação de um 
alinhamento ótimo, acima de um certo limite mínimo estipulado, vamos dizer que 
as \seqs\ são similares.

\section{Alinhamentos e \opeds}
\label{sec:alignoped}

Seja $\opedsym^*$ o conjunto de todas as \opeds. Para cada coluna $k$ de um 
alinhamento qualquer $A$ de $s$ e $t$ vamos associar uma \oped\ pontual através 
da função parcial $\alignopedsym:\alignset \times \natset \rightarrow \opedsym^*$ 
definida por:
\begin{itemize}
\item $\alignoped{A}{k}=\opedsubsym{j}{t[j]}{s[i]}$ se a coluna $k$ de $A$ é do 
tipo substituição, onde $i$ e $j$ são tais que $\aligncol{s}{i}{A}=k$ e 
$\aligncol{t}{j}{A}=k$;
\item $\alignoped{A}{k}=\opedinssym{j-1}{t[j]}$ se a coluna $k$ de $A$ é do 
tipo inserção, onde $j$ é tal que $\aligncol{t}{j}{A}=k$;
\item $\alignoped{A}{k}=\opeddelsym{j+1}{s[i]}$ se a coluna $k$ de $A$ é do 
tipo remoção, onde $i$ e $j$ são tais que $\aligncol{s}{i}{A}=k$, $j \geq 0$ e 
$\alignprefix{t}{k}{A}=t[1 \Rng j]$.
\end{itemize}

Como um alinhamento é uma \seq\ de colunas e cada coluna está associada a uma 
\oped\ pontual, podemos associar um alinhamento a uma \seq\ de \opeds\ pontuais 
através da função parcial \alignopedsym.

\begin{proposicao}\label{prop:alignoped}
Seja $A$ um alinhamento de $s$ e $t$ de comprimento $r$. Temos que, para toda 
coluna $l$ de $A$, 
$\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})=\alignprefix{t}{l}{A}$, 
onde $\opedseqsym_l=(\opedsym_0,\opedsym_1, \ldots, \opedsym_{l})$ e 
$\opedsym_k=\alignoped{A}{k}$ para toda coluna $k$ de $A$ tal que $0 \leq k 
\leq l$.
\end{proposicao}

\begin{prova}
A prova é por indução em $l$.
\begin{enumerate}
\item Base da indução: 
$\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})=\alignprefix{t}{l}{A}$, 
para $l = 0$.
	      
De acordo com o tipo da coluna $l=0$ temos que:
\begin{enumerate}
\item Se $l$ é uma coluna do tipo substituição, então $A[0,0]=s[1]$, 
$A[1,0]=t[1]$ e $\opedsym_l=\opedsubsym{1}{t[1]}{s[1]}$. Como, 
$\alignprefix{s}{0}{A}=s[1]$ e $\alignprefix{t}{0}{A}=t[1]$ então
\begin{align*} 
\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})& 
=\opedcompsym{\opedseqsym_l}(s[1])\\
&=\opedsubsym{1}{t[1]}{s[1]}(s[1])\\
&=t[1]\\
&=\alignprefix{t}{l}{A}.
\end{align*}
\item Se $l$ é uma coluna do tipo inserção, então $A[1,0]=t[1]$ e 
$A[0,0]=\aligngap$. Portanto, $\aligncol{t}{1}{A}=0$, 
$\opedsym_l=\opedinssym{0}{t[1]}$, $\alignprefix{t}{l}{A}=t[1]$ e 
$\alignprefix{s}{l}{A}=s[1\Rng 0]$.
\begin{align*} 
\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})& 
=\opedcompsym{\opedseqsym_l}(s[1 \Rng 0])\\
&=\opedinssym{0}{t[1]}(s[1 \Rng 0])\\
&=t[1]\\
&=\alignprefix{t}{l}{A}.
\end{align*}
\item Se $l$ é uma coluna do tipo remoção, então $A[1,0]=\aligngap$ e 
$A[0,0]=s[1]$. Portanto, $\aligncol{s}{1}{A}=0$, $\alignprefix{t}{l}{A}=t[1 
\Rng 0]$, $\opedsym_l=\opeddelsym{1}{s[1]}$ e $\alignprefix{s}{l}{A}=s[1]$.
\begin{align*} 
\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})& 
=\opedcompsym{\opedseqsym_l}(s[i])\\
&=\opeddelsym{1}{s[1]}(s[1])\\
&=t[1 \Rng 0]\\
&=\alignprefix{t}{l}{A}.
\end{align*} 
\end{enumerate}
Portanto, para $l=0$ temos que 
$\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})=\alignprefix{t}{l}{A}$.
	       
\item Passo da indução: Dado que 
$\opedcompsym{\opedseqsym_{l-1}}(\alignprefix{s}{l-1}{A})=\alignprefix{t}{l-1}{A}$ 
então 
$\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})=\alignprefix{t}{l}{A}$, 
para qualquer $l$ tal que $0 \leq l \leq r-1$.
	      
De acordo com o tipo da coluna $l$ temos que:
\begin{enumerate}
\item Se $l$ é uma coluna do tipo substituição, então 
$\opedsym_l=\opedsubsym{j}{t[j]}{s[i]}$, onde $i$ e $j$ são índices tais que 
$\aligncol{s}{i}{A}=l$ e $\aligncol{t}{j}{A}=l$. Utilizando as 
observações~\ref{obs:opedsuf}~e~\ref{obs:prefix} temos que:
\begin{align*} 
\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})& 
=\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l-1}{A}s[i])\\
&=\opedsubsym{j}{t[j]}{s[i]}(\opedcompsym{\opedseqsym_{l-1}}(\alignprefix{s}{l-1}{A}s[i]))\\
&=\opedsubsym{j}{t[j]}{s[i]}(\opedcompsym{\opedseqsym_{l-1}}(\alignprefix{s}{l-1}{A})s[i])\\
&=\opedsubsym{j}{t[j]}{s[i]}(\alignprefix{t}{l-1}{A}s[i])\\
&=\alignprefix{t}{l-1}{A}t[j]\\
&=\alignprefix{t}{l}{A}.
\end{align*}
\item Se $l$ é uma coluna do tipo inserção, então 
$\opedsym_l=\opedinssym{j-1}{t[j]}$, onde $j$ é tal que $\aligncol{t}{j}{A}=l$. 
Utilizando as observações~\ref{obs:opedsuf}~e~\ref{obs:prefix} temos que:
\begin{align*} 
\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})& 
=\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l-1}{A})\\
&=\opedinssym{j-1}{t[j]}(\opedcompsym{\opedseqsym_{l-1}}(\alignprefix{s}{l-1}{A}))\\
&=\opedinssym{j-1}{t[j]}(\alignprefix{t}{l-1}{A})\\
&=\opedinssym{j-1}{t[j]}(t[1 \Rng j-1])\\
&=t[1 \Rng j]\\
&=\alignprefix{t}{l}{A}.
\end{align*}
\item Se $l$ é uma coluna do tipo remoção, então 
$\opedsym_l=\opeddelsym{j+1}{s[i]}$, onde $j$ é tal que 
$\alignprefix{t}{l}{A}=t[1 \Rng j]$ e $j \geq 0$, e $i$ é tal que 
$\aligncol{s}{i}{A}=l$. Utilizando as 
observações~\ref{obs:opedsuf}~e~\ref{obs:prefix} temos que:
\begin{align*} 
\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l}{A})& 
=\opedcompsym{\opedseqsym_l}(\alignprefix{s}{l-1}{A}s[i])\\
&=\opeddelsym{j+1}{s[i]}(\opedcompsym{\opedseqsym_{l-1}}(\alignprefix{s}{l-1}{A}s[i]))\\
&=\opeddelsym{j+1}{s[i]}(\opedcompsym{\opedseqsym_{l-1}}(\alignprefix{s}{l-1}{A})s[i])\\
&=\opeddelsym{j+1}{s[i]}(\alignprefix{t}{l-1}{A}s[i])\\
&=\opeddelsym{j+1}{s[i]}(t[1 \Rng j]s[i])\\
&=t[1 \Rng j]\\
&=\alignprefix{t}{l}{A}. \cqd
\end{align*} 
\end{enumerate}
\end{enumerate}

\end{prova}

\begin{corolario}\label{coro:alignoped}
Seja $A$ um alinhamento de $s$ e $t$ de comprimento $r$. Seja 
$\opedseqsym=(\opedsym_0,\opedsym_1, \ldots, \opedsym_{r-1})$ onde, para cada 
coluna $k$ de $A$, $\opedsym_k$ é a \oped\ associada a coluna $k$ através da 
função parcial \alignopedsym. Temos que $\opedcompsym{\opedseqsym}(s)=t$.
\end{corolario}

Repare que, dado uma \seq\ de \opeds\ pontuais 
$\opedseqsym=(\opedsym_0,\opedsym_1, \ldots, \opedsym_i, \ldots, \opedsym_j, 
\ldots,\opedsym_{r-1})$ tal que $\opedcompsym{\opedseqsym}(s)=t$, como no 
Corolário~\ref{coro:alignoped}, podemos obter 
$\opedseqsym'=(\opedsym_0,\opedsym_1, \ldots, \opedsym_{j}', \opedsym_{i+1}', 
\ldots, \opedsym_{j-1}', \opedsym_{i}', \ldots, \opedsym_{r-1})$, para $r \geq
2$ e quaisquer $i$ e $j$  tais que, $0 \leq i < j \leq r-1$, de tal forma que
$\opedcompsym{\opedseqsym}(s)=\opedcompsym{\opedseqsym'}(s)=t$ e as \opeds\ 
$\opedsym_{i}', \opedsym_{i+1}', \ldots, \opedsym_{j-1}'$ e $\opedsym_{j}'$ 
pertencem, respectivamente, à mesma classe das \opeds\ $\opedsym_i, 
\opedsym_{i+1}, \ldots, \opedsym_{j-1}$ e $\opedsym_j$, mas são diferentes 
destas em seus índices. Ou seja, as \opeds\ da \seq\ $\opedseqsym$ podem ter a 
ordem alterada juntamente com seus índices para obter uma outra \seq\ 
$\opedseqsym'$ tal que 
$\opedcompsym{\opedseqsym}(s)=\opedcompsym{\opedseqsym'}(s)=t$.

Em biologia é comum ao fazer uma análise evolutiva de duas \seqs, supor a 
existência de uma \seq\ ancestral destas duas \seqs e que após um processo de 
replicação gera duas \seqs\ iguais, as quais sofrem mutações com o decorrer do 
tempo e geram as duas \seqs\ que estão sendo analisadas. Portanto, é 
interessante, e muitas vezes desejado pelos biólogos, fazer uma análise 
evolutiva de duas \seqs\ para tentar descobrir esta \seq\ ancestral e conhecer 
as mutações que ocorreram com o decorrer do tempo.

Apesar de cada coluna de um alinhamento estar associada a uma \oped\ e cada 
\oped\ estar relacionada a uma mutação, não podemos dizer que um alinhamento 
por si só mostra a \seq\ de mutações que ocorreram em uma \seq\ ancestral que 
geraram as duas \seqs\ sendo alinhadas, pois como já vimos, dado um alinhamento 
de duas \seqs, a ordem das \opeds\ associadas a este alinhamento pode 
facilmente ser alterada. Portanto descobrir esta ordem dos eventos requer mais 
informações que as utilizadas num alinhamento. Além disso, um alinhamento não 
indica a \seq\ ancestral, e portanto ele não mostra precisamente qual foi a 
mutação que ocorreu, mesmo restringindo as possibilidades de mutações às 
mutações relacionadas às \opeds\ pontuais. Assim, um alinhamento de duas \seqs\ 
não tem como objetivo, mostrar que os eventos \bios\ ocorridos são precisamente 
os eventos mapeados pelas \opeds\ associadas a cada coluna deste alinhamento. 
Por exemplo, uma coluna do tipo inserção, de um alinhamento de $s$ e $t$, 
indica que pode ter ocorrido um evento de inserção em $s$ ou um evento de 
remoção em $t$, pois o alinhamento não mostra qual é a \seq\ ancestral de $s$ e 
$t$. As \opeds\ associadas as colunas indicam apenas que podemos alterar $s$ 
com estas \opeds\ para obter $t$. Quando associamos as \opeds\ às colunas de um 
alinhamento de $s$ e $t$, estabelecemos arbitrariamente que as \opeds\ são 
sempre sobre $s$, porém sem a intenção de indicar que $s$ é a \seq\ ancestral. 
Além disto, estabelecemos arbitrariamente que a ordem das \opeds\ são da 
esquerda para a direita nas colunas de um alinhamento.

Do ponto de vista evolutivo, um alinhamento de duas \seqs\ por si só não 
garante a ordem em que ocorreram as mutações, nem tampouco mostra qual é a 
\seq\ ancestral. Porém, é possível utilizar um alinhamento de duas \seqs\ para 
se inferir hipóteses para uma análise evolutiva.

\section{Alinhamentos e \greds}
\label{sec:aligngred}

\begin{proposicao}\label{prop:alignpath}
% Cada alinhamento $A$ de $s$ e $t$ está associado a um caminho de $(0,0)$ a
% $(n,m)$ no \gred\ de $s$ e $t$ e vice versa.

Seja $G$ um \gred\ de $s=s[1\Rng n]$ e $t=t[1\Rng m]$. Seja $E$ o conjunto de 
arestas de $G$. Sejam $\alignsetst{s}{t}$ o conjunto de todos os possíveis 
alinhamentos de $s$ e $t$ e $\egpathset{(0,0)}{(n,m)}$ o conjunto de todos os 
possíveis caminhos de $(0,0)$ a $(n,m)$ em $G$. Seja a função parcial 
$\alignedgesym:\alignsetst{s}{t} \times \natset \rightarrow E$ definida por:
\begin{itemize}
\item $\alignedge{A}{k}= \eged{(i,j)}$ se $k$ é uma coluna de $A$ e é do tipo 
substituição,
\item $\alignedge{A}{k}= \egeh{(i,j)}$ se $k$ é uma coluna de $A$ e é do tipo 
inserção,
\item $\alignedge{A}{k}= \egev{(i,j)}$ se $k$ é uma coluna de $A$ e é do tipo 
remoção,
\end{itemize}
onde $i$ e $j$ são tais que $0 \leq i \leq n$, $0 \leq j \leq m$, 
$\alignprefix{s}{k}{A}=s[1 \Rng i]$ e $\alignprefix{t}{k}{A}=t[1 \Rng j]$. Temos que:
\begin{enumerate}
  \item A \seq\ $P=(\alignedge{A}{0}, \alignedge{A}{1}, \ldots, 
  \alignedge{A}{r-1})$ é um caminho de $(0,0)$ a $(n,m)$ em $G$, onde $A$ é um 
  alinhamento de $s$ e $t$ de comprimento $r$.
  \item A função $\alignpathsym:\alignsetst{s}{t} \rightarrow 
  \egpathset{(0,0)}{(n,m)}$ definida por, $\alignpath{A}=(\alignedge{A}{0}$, 
  $\alignedge{A}{1},\ldots,\alignedge{A}{r-1})=P$, onde $A$ é um alinhamento de 
  comprimento $r$, é bijetora.
\end{enumerate}
\end{proposicao}
\begin{prova}
\begin{enumerate}
  \item $P$ é um caminho de $(0,0)$ a $(n,m)$ em $G$.
  
  Se $n=0$ e $m=0$ então $P$ é a \seq\ vazia e como $G$ só tem o vértice 
  $(0,0)$ então $P$ é um caminho de $(0,0)$ a $(n,m)$ em $G$.
  
  Vamos assumir que $n\neq 0$ ou $m\neq 0$.

  Para que $P$ seja um caminho de $(0,0)$ a $(n,m)$ em $G$, é necessário 
  provarmos que $\startedge{\alignedge{A}{0}}=(0,0)$, 
  $\finishedge{\alignedge{A}{r-1}}=(n,m)$ e que para todo $k$, $1 \leq k \leq 
  r-1$, $\finishedge{\alignedge{A}{k-1}}=\startedge{\alignedge{A}{k}}$.
  
  \begin{enumerate}
      \item $\startedge{\alignedge{A}{0}}=(0,0)$
      
      Se a coluna $0$ de $A$ é do tipo substituição então 
      $\alignprefix{s}{0}{A}=s[1]$ e $\alignprefix{t}{0}{A}=t[1]$ e portanto 
      $\alignedge{A}{0}= \eged{(1,1)}$ e $\startedge{\alignedge{A}{0}}=(0,0)$.
      
      Se a coluna $0$ de $A$ é do tipo inserção então 
      $\alignprefix{s}{0}{A}=s[1 \Rng 0]$ e $\alignprefix{t}{0}{A}=t[1]$ e 
      portanto $\alignedge{A}{0}= \egeh{(0,1)}$ e 
      $\startedge{\alignedge{A}{0}}=(0,0)$.
      
      Se a coluna $0$ de $A$ é do tipo remoção então 
      $\alignprefix{s}{0}{A}=s[1]$ e $\alignprefix{t}{0}{A}=t[1 \Rng 0]$ e 
      portanto $\alignedge{A}{0}= \egev{(1,0)}$ e 
      $\startedge{\alignedge{A}{0}}=(0,0)$.
  
      \item $\finishedge{\alignedge{A}{r-1}}=(n,m)$
      
      Para a coluna $r-1$ de $A$ temos que $\alignprefix{s}{r-1}{A}=s[1 \Rng 
      n]$ e $\alignprefix{t}{r-1}{A}=t[1 \Rng m]$, pois $A$ é um alinhamento de 
      $s$ e $t$ de comprimento $r$. A aresta $\alignedge{A}{r-1}$ pode ser 
      $\eged{(n,m)}$, $\egeh{(n,m)}$ ou $\egev{(n,m)}$, dependendo do tipo da 
      coluna $r-1$ de $A$. Portanto, para qualquer que seja o tipo da coluna 
      $r-1$ de $A$, $\finishedge{\alignedge{A}{r-1}}=(n,m)$.
      
      \item $\finishedge{\alignedge{A}{k-1}}=\startedge{\alignedge{A}{k}}$, 
      para todo $k$ tal que $1 \leq k \leq r-1$.
      
      Seja $\finishedge{\alignedge{A}{k-1}}=(i,j)$. Independente do tipo da 
      coluna $k-1$, como $\finishedge{\alignedge{A}{k-1}}=(i,j)$ então, pela 
      definição de \alignedgesym, $\alignprefix{s}{k-1}{A}=s[1 \Rng i]$ e 
      $\alignprefix{t}{k-1}{A}=t[1 \Rng j]$.
      
      Se a coluna $k$ de $A$ é do tipo substituição então 
      $\alignprefix{s}{k}{A}=s[1 \Rng i+1]$ e $\alignprefix{t}{k}{A}=t[1 \Rng 
      j+1]$ e portanto $\alignedge{A}{k}= \eged{(i+1,j+1)}$ e 
      $\startedge{\alignedge{A}{k}}=(i,j)=\finishedge{\alignedge{A}{k-1}}$.
      
      Se a coluna $k$ de $A$ é do tipo inserção então 
      $\alignprefix{s}{k}{A}=s[1 \Rng i]$ e $\alignprefix{t}{k}{A}=t[1 \Rng 
      j+1]$ e portanto $\alignedge{A}{k}= \egeh{(i,j+1)}$ e 
      $\startedge{\alignedge{A}{k}}=(i,j)=\finishedge{\alignedge{A}{k-1}}$.
      
      Se a coluna $k$ de $A$ é do tipo remoção então $\alignprefix{s}{k}{A}=s[1 
      \Rng i+1]$ e $\alignprefix{t}{k}{A}=t[1 \Rng j]$ e portanto 
      $\alignedge{A}{k}= \egev{(i+1,j)}$ e 
      $\startedge{\alignedge{A}{k}}=(i,j)=\finishedge{\alignedge{A}{k-1}}$.
  \end{enumerate}
  
  Portanto $P$ é um passeio de $(0,0)$ a $(n,m)$ em $G$. Como um grafo de 
  edição é um grafo acíclico, não há vértices repetidos e a primeira afirmação 
  da proposição está demonstrada.
  
  \item $\alignpathsym$ é uma função bijetora.
  
    Para que $\alignpathsym$ seja bijetora é necessário que $\alignpathsym$ 
    seja uma função definida para todos os elementos do seu domínio e que seu 
    contra-domínio seja igual ao seu domínio, ou seja, para todo alinhamento 
    $A$ existe um único $P$ tal que $\alignpath{A}=P$ assim como para todo 
    caminho $P$ existe um único $A$ tal que $\alignpath{A}=P$.
  
    Se $n=0$ e $m=0$ então $A$ é o alinhamento sem colunas e $\alignpath{A}= P$ 
    é um caminho sem arestas. Temos também que $\alignsetst{s}{t}=A$ e 
    $\egpathset{(0,0)}{(n,m)}=P$. Portanto $\alignpathsym$ é uma função 
    bijetora.
    
    Vamos assumir que $n\neq 0$ ou $m\neq 0$.
  
	\begin{enumerate}
       \item Para todo alinhamento $A$ existe um único $P$ tal que 
       $\alignpath{A}=P$.
   
          Como $\alignedgesym$ é uma função parcial definida para toda coluna 
          de qualquer alinhamento $A$ e como $\alignedgesym$ é 
          unívoca\footnote{Uma função $f$ é unívoca se quando $f(x) = y$ e 
          $f(x) = z$ então $y = z$, para todo $x$.}, então $\alignpathsym$ é 
          também uma função definida para qualquer $A$ e existe um único $P$ 
          tal que $\alignpath{A}=P$.
          
       \item Para todo caminho $P$ existe um único $A$ tal que 
       $\alignpath{A}=P$.
       
       Para provar esta afirmação precisamos provar que não existem dois 
       alinhamentos $A$ e $A'$ distintos em \alignsetst{s}{t} tais que 
       $\alignpath{A}=\alignpath{A'}=P$ e que para todo caminho $P$ em 
       $\egpathset{(0,0)}{(n,m)}$ existe um alinhamento $A$ tal que 
       $\alignpath{A}=P$.
       
       \begin{enumerate}
          \item Não existem dois alinhamentos $A$ e $A'$ distintos tais que \\
          $\alignpath{A}=\alignpath{A'}=P$.
          
          Suponha por absurdo, que existam os alinhamento $A$ e $A'$ distintos 
          tais que $\alignpath{A}=\alignpath{A'}=P$. Seja $k$ o menor índice 
          tal que a coluna $k$ de $A$ é diferente da coluna $k$ de $A'$. Como 
          $\alignprefix{s}{k-1}{A}=\alignprefix{s}{k-1}{A'}$ e 
          $\alignprefix{t}{k-1}{A}=\alignprefix{t}{k-1}{A'}$ então as colunas 
          $k$ de $A$ e $A'$ são de tipos diferentes. Logo $\alignedge{A}{k} 
          \neq \alignedge{A'}{k}$ e portanto $\alignpath{A}\neq 
          \alignpath{A'}$, o que é uma contradição com a hipótese que 
          $\alignpath{A}=\alignpath{A'}=P$.
          
          \item Para todo caminho $P$ em $\egpathset{(0,0)}{(n,m)}$ existe um 
          alinhamento $A$ tal que $\alignpath{A}=P$.
          
          Seja $P=(\egesym_0, \egesym_1, \ldots, \egesym_{r-1})$ um caminho de 
          $(0,0)$ a $(n,m)$ em $G$. Seja a função $f:E \rightarrow 
          \alfabetoaligngap \times \alfabetoaligngap$ definida por:
          \begin{itemize}
              \item $f(\eged{(i,j)})=(s[i],t[j])$,
              \item $f(\egeh{(i,j)})=(\aligngap,t[j])$,
              \item $f(\egev{(i,j)})=(s[i],\aligngap)$.
          \end{itemize} 
              Seja a matriz $A$ $(2 \times r)$ definida da seguinte forma: 
              $(A[0,k]$, $A[1,k])=f(\egesym_k)$, para todo $k$ tal que $0 \leq 
              k \leq r-1$. Se $A$ é um alinhamento então $\alignpath{A}=P$, 
              pois $f$ associa uma aresta de um \gred\ a uma coluna de um 
              alinhamento, analogamente como $\alignedgesym$ associa uma coluna 
              de um alinhamento a uma aresta de um \gred.
              
              Para que $A$ seja um alinhamento é necessário que:
          \begin{enumerate}
             \item $r \geq m$ e $r \geq n$.
             
             Seja $a_k=\egrowv{\finishedge{\egesym_k}}$ o índice da linha de 
             $\finishedge{\egesym_k}$ e $b_k=\egcolv{\finishedge{\egesym_k}}$ o 
             índice da coluna de $\finishedge{\egesym_k}$, para qualquer aresta 
             $\egesym_k$ do caminho $P$. Sabemos que, para todo $k$ tal que $1 
             \leq k \leq r-1$, $a_k-a_{k-1} = 1$ somente se $\egesym_k$ é uma 
             aresta diagonal ou vertical, e $b_k-b_{k-1} = 1$ somente se 
             $\egesym_k$ é uma aresta diagonal ou horizontal. Como 
             $a_{r-1}-a_0=n$ então há exatamente $n$ arestas diagonais ou 
             verticais em $P$ e como $b_{r-1}-b_0=m$ então há exatamente $m$ 
             arestas diagonais ou horizontais em $P$. Portanto o número $r$ de 
             arestas no caminho $P$ é tal que $r \geq n$ e $r \geq m$.
                
             \item Para toda coluna $j$ da matriz $A$ se $A[0,j]=A[1,j]$ então 
             $A[0,j] \neq \aligngap$.
             
             Isto é verdade pois $(\aligngap, \aligngap)$ não é elemento da 
             imagem de $f$ e a matriz $A$ é construída de tal forma que toda 
             coluna de $A$ é um elemento da imagem de $f$.
             
             \item Existem duas sub\seqs\ $S=(i_1, i_2, \ldots, i_n)$ e 
             $T=(j_1, j_2, \ldots, j_m)$ dos índices das colunas de $A$, tais 
             que:\label{prop:alignpath:itemST}
             \begin{itemize}
                \item $s=A[0,i_1]A[0,i_2]\ldots A[0,i_n]$,
                \item $t=A[1,j_1]A[1,j_2]\ldots A[1,j_m]$,
                \item $A[0,i]=\aligngap$ para toda coluna $i$ de $A$, tal que 
                $i \notin S$, e
                \item $A[1,j]=\aligngap$ para todo coluna $j$ de $A$, tal que 
                $j \notin T$.
             \end{itemize} 
             
             Vamos demonstrar a seguir que existem \seqs\ $S$ e $T$ que 
             satisfazem estas restrições.
             
             Como o número de arestas diagonais e verticais de $P$ é igual a 
             $n$ e o número de arestas diagonais e horizontais de $P$ é igual a 
             $m$, definiremos as \seqs\ $S$ e $T$ da seguinte forma: sejam 
             $S=(i_1, i_2, \ldots, i_{n})$ e $T=(j_1, j_2, \ldots, j_{m})$ tais 
             que, para cada coluna $k$ de $A$, se $\egesym_k$ é uma aresta 
             diagonal ou vertical então $k \in S$ e se $\egesym_k$ é uma aresta 
             diagonal ou horizontal então $k \in T$.
             
             Como $P$ é um caminho de $(0,0)$ a $(n,m)$ em $G$ então 
             $\egrowv{\finishedge{\egesym_{i_1}}}=1$, 
             $\egrowv{\finishedge{\egesym_{i_n}}}=n$ e 
             $\egrowv{\finishedge{\egesym_{i_l}}}-\egrowv{\finishedge{\egesym_{i_{l-1}}}}=1$, 
             para todo $l$ tal que $2 \leq l \leq n$, ou seja, 
             $(\egrowv{\finishedge{\egesym_{i_1}}},\egrowv{\finishedge{\egesym_{i_2}}}, 
             \ldots, \egrowv{\finishedge{\egesym_{i_n}}})=(1,2,\ldots,n)$. Como 
             $\egesym_{i_l}$ é uma aresta diagonal ou vertical então 
             $A[0,i_l]=s[\egrowv{\finishedge{\egesym_{i_l}}}]$, para todo $l$ 
             tal que $1 \leq l \leq n$. Portanto $A[0,i_1]A[0,i_2]\ldots 
             A[0,i_n]=s[\egrowv{\finishedge{\egesym_{i_1}}}]$ $
             s[\egrowv{\finishedge{\egesym_{i_2}}}]$ $\ldots $ $
             s[\egrowv{\finishedge{\egesym_{i_n}}}] =$ $s[1]s[2]\ldots
             s[n]=s$. De modo análogo temos que $A[1,j_1]$ $A[1,j_2]$ $\ldots $
             $ A[1,j_n]=t[\egcolv{\finishedge{\egesym_{j_1}}}]$ $
             t[\egcolv{\finishedge{\egesym_{j_2}}}]$ $\ldots $ $
             t[\egcolv{\finishedge{\egesym_{j_n}}}]$ $=$ $t[1]t[2]\ldots t[n]=t$.
             
             Seja $i$ uma coluna de $A$, tal que $i \notin S$. Logo $\egesym_i$ 
             é uma aresta horizontal e portanto $A[0,i]=\aligngap$.
             
             Seja $j$ uma coluna de $A$, tal que $j \notin T$. Logo $\egesym_j$ 
             é uma aresta vertical e portanto $A[i,j]=\aligngap$.
             
             Portanto $S$ e $T$, como definidos no início da demonstração, 
             satisfazem as restrições do item~\ref{prop:alignpath:itemST}.
          \end{enumerate} 
             Logo $A$ é um alinhamento tal que $\alignpath{A}=P$. Assim, existe 
             um alinhamento $A$ para qualquer $P$ tal que $\alignpath{A}=P$.
       \end{enumerate}
             Assim, para todo caminho $P \in \egpathset{(0,0)}{(n,m)}$ existe 
             um único alinhamento $A$ tal que $\alignpath{A}=P$.
    \end{enumerate}
             Portanto $\alignpathsym$ é uma função bijetora e a segunda 
             afirmação da proposição está demonstrada. \cqd
\end{enumerate}
             
\end{prova}

Portanto, podemos associar cada alinhamento $A$ de $s$ e $t$ a um caminho $P$ 
de $(0,0)$ a $(n,m)$ no grafo de edição de $s$ e $t$ e vice-versa. 

A Figura~\ref{fig:exemploegcaminho} destaca um caminho de $(0,0)$ a $(3,3)$ num 
grafo de edição de 4 linhas e 4 colunas. O caminho representa o seguinte 
alinhamento de $s=s[1 \Rng 3]$ e $t=t[1 \Rng 3]$:

\[A=\left[\begin{array}{cccc} \aligngap&s[1]&s[2]&s[3]\\
t[1]&\aligngap &t[2]&t[3] \end{array}\right]\]

\begin{figure}[htbp] \centering 
\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{exemploegcaminho}
% \end{center}
\caption[Ilustração de um caminho num \gred]{Arestas tracejadas indicam um caminho 
de $(0,0)$ a $(3,3)$ num grafo de edição de 4 linhas e 4 colunas.}
 \label{fig:exemploegcaminho}
\end{figure}

% Sejam $A$ um alinhamento de $s$ e $t$ e $P$ o caminho correspondente no \gred\ 
% de $s$ e $t$. Assim como associamos uma pontuação $x$ a uma coluna $k$ de $A$, 
% podemos associar um peso $x$ a aresta do caminho $P$ associada, através da 
% função $\alignedgesym$, a coluna $k$ de $A$. Desta forma o peso de $P$ é a 
% pontuação de $A$.
% 
Se o sistema de pontuação de um alinhamento de $s$ e $t$ é tal que, não 
considera como estão alinhadas as colunas anteriores ou posteriores para 
atribuir a pontuação de cada coluna do alinhamento, então podemos atribuir um 
peso a cada aresta de um \gred\ $G=(V,E,\egweigsym)$ de $s$ e $t$ de tal forma que, o peso de 
qualquer caminho $P$ de $(0,0)$ a $(n,m)$ em $G$ será o peso do alinhamento 
correspondente a $P$. Por exemplo, isto é válido quando utilizamos o sistema de 
pontuação com custo de \emph{gap} linear e atribuímos um peso a cada aresta da seguinte forma:
\begin{itemize}
  \item se a aresta é $\eged{(i,j)}$ então 
  $\egweige{\eged{(i,j)}}=\alignscore(s[i],t[j])$;
  \item se a aresta é $\egeh{(i,j)}$ então 
  $\egweige{\egeh{(i,j)}}=\alignscore(\aligngap,t[j])$;
  \item se a aresta é $\egev{(i,j)}$ então 
  $\egweige{\egev{(i,j)}}=\alignscore(s[i],\aligngap)$.
\end{itemize}

Podemos também associar o peso de uma aresta a pontuação de uma \oped\ da
seguinte forma: o peso da aresta $e_V^{i,j}$ corresponde à pontuação 
associada à \oped\ de remoção da letra $s[i]$ após o alinhamento de $s[1\Rng 
i-1]$ e $t[1\Rng j]$; o peso da aresta $e_H^{i,j}$ corresponde à pontuação 
associada à \oped\ de inserção da letra $t[j]$ após o alinhamento de $s[1\Rng 
i]$ e $t[1\Rng j-1]$ e; o peso da aresta $e_D^{i,j}$ corresponde à pontuação 
associada à \oped\ de substituição da letra $s[i]$ pela letra $t[j]$ após o 
alinhamento de $s[1\Rng i-1]$ e $t[1\Rng j-1]$. Esta associação permite a
utilização do sistema de pontuação com custo de \emph{gap} linear,
além de outras possibilidades, e permite que o peso de qualquer caminho $P$ de 
$(0,0)$ a $(n,m)$ num \gred\ seja o peso do alinhamento correspondente a $P$.

Portanto, para determinados sistemas de pontuação, podemos afirmar que 
encontrar um alinhamento ótimo de $s$ e $t$ é o mesmo que encontrar um caminho 
ótimo de $(0,0)$ a $(n,m)$ no grafo de edição de $s$ e $t$. 

Vale a pena ressaltar que essa associação de pontuação de um alinhamento ao 
peso do caminho correspondente no \gred, não é válida para o sistema de 
pontuação que utiliza penalidade para abertura de gaps (\emph{gap open 
penalty}) descrito anteriormente, ou seja, o sistema de pontuação com 
\emph{gap} afim. No entanto, freqüentemente neste texto, vamos assumir a 
utilização do sistema de pontuação com custo de \emph{gap} linear e portanto 
poderemos nos referir a um alinhamento de $s$ e $t$ como um caminho no \gred\ 
de $s$ e $t$ e vice-versa.

\section{Alinhamento global, semiglobal e local}
\label{sec:alignglobsemi}

Nesta seção vamos considerar que o sistema de pontuação utilizado é o sistema 
de pontuação com custo de \emph{gap} linear e que as \seqs\ $s$ e $t$ utilizadas nos 
alinhamentos são de comprimento $n$ e $m$, respectivamente.

Muitas vezes um alinhamento de $s$ e $t$ é chamado de alinhamento global de $s$
e $t$.

O conhecido artigo de Needleman e Wunsch~\cite{pmid5420325} é geralmente 
considerado a primeira contribuição importante em procedimentos computacionais 
para a comparação de \seqs. O algoritmo proposto por eles neste artigo, apesar 
de não ter sido feita uma análise de tempo no artigo, é considerado cúbico 
($O(n^2m)$ ou $O(nm^2)$) e, apesar da recorrência que vamos ver a seguir 
possibilitar um algoritmo com tempo de execução quadrático ($O(nm)$), 
normalmente o nome "Algoritmo de Needleman e Wunsch" é utilizado no algoritmo 
de programação dinâmica para alinhamentos globais~\cite{meidanissetubalbook}.

Seja $M$ a matriz $n+1 \times m+1$ tal que $M[i,j]$ contém a 
pontuação de um alinhamento global ótimo de $s[1 \Rng i]$ e $t[1 \Rng j]$. Uma maneira
de construir a matriz $M$ é através da seguinte recorrência:
\begin{align*}
&M[0,0]&&=0&&\\
&M[i,0]&&=M[i-1,0]+\alignscore(s[i],\aligngap)&&,0<i\leq n\\
&M[0,j]&&=M[0,j-1]+\alignscore(\aligngap,t[j])&&,0<j\leq m\\
&M[i,j]&&=\max\left(\begin{array}{l} M[i-1,j]+\alignscore(s[i],\aligngap),\\
M[i,j-1]+\alignscore(\aligngap,t[j]),\\
M[i-1,j-1]+\alignscore(s[i],t[j]) \end{array}\right)&&,\begin{array}{l}0<i\leq
n \textrm{ e }\\  0<j\leq m \end{array}
\end{align*}

Portanto $M[n,m]$ é a pontuação de um alinhamento ótimo de $s$ e $t$. 

A obtenção do alinhamento ótimo de $s[1\Rng n]$ e $t[1\Rng m]$ é feita
traçando-se o caminho reverso no \gred\ $G=(V,E,\egweigsym)$ de $s$ e $t$, ou seja,
analisando-se todas as arestas que chegam em $(n,m)$ e obtendo-se a aresta 
$((i_1,j_1),(n,m))$ tal que $M[n,m]=M[i_1,j_1]+\egweige{((i_1,j_1),(n,m))}$, 
depois analisa-se todas as arestas que chegam em $(i_1,j_1)$ e obtém-se a 
aresta $((i_2,j_2),$ $(i_1,j_1))$ tal que 
$M[i_1,j_1]=M[i_2,j_2]+\egweige{((i_2,j_2),(i_1,j_1))}$, e assim por diante até 
chegar-se em $(0,0)$. Portanto, dado que o número de 
arestas que chegam em qualquer vértice é constante, podemos obter o alinhamento
ótimo, com um pós-processamento, em tempo $O(n+m)$. Repare que deste
modo precisamos manter a matriz $M$ para obter o alinhamento ótimo e portanto o 
espaço requerido é $O(nm)$. Existe um método desenvolvido por 
Hirschberg~\cite{360861} que utiliza espaço linear para obter o LCS de duas
\seqs\ e que é comumente adaptado para obter o alinhamento ótimo sem a
necessidade de espaço quadrático.

É comum que fragmentos de duas \seqs\ de DNA tenham alto grau de similaridade, 
enquanto que outros fragmentos destas \seqs\ tenham grau de similaridade baixo. 
Por isto, muitas vezes é interessante descobrir quais são os fragmentos que 
possuem alto grau de similaridade entre duas \seqs. Isto leva a necessidade da
obtenção de um alinhamento local ótimo de $s$ e $t$.

Um alinhamento local de $s$ e $t$ é um alinhamento global de qualquer
fragmento de $s$ e qualquer fragmento de $t$. Um alinhamento local ótimo é um
alinhamento local com pontuação máxima dentre todos os possíveis alinhamentos
locais de $s$ e $t$.

Como já dissemos, um alinhamento global de $s$ e $t$ é um caminho de $(0,0)$ a 
$(n,m)$ no \gred\ $G$ de $s$ e $t$. Já um alinhamento local de $s$ e 
$t$ é um caminho de qualquer vértice $(i_1, j_1)$ a qualquer vértice $(i_2, 
j_2)$ de $G$. O problema de encontrar um alinhamento local ótimo de $s$ e $t$ é 
o problema de encontrar o caminho de maior peso dentre todos os possíveis 
caminhos no \gred\ de $s$ e $t$.

Repare que, se todas as arestas do \gred\ de $s$ e $t$ têm peso não negativo 
então o caminho de $(0,0)$ a $(n,m)$ é um alinhamento local ótimo. Portanto, 
neste caso, encontrar um alinhamento local ótimo é o mesmo que encontrar um 
alinhamento global ótimo. Para que haja uma diferença ente os dois tipos de 
alinhamentos, vamos assumir que algumas arestas do \gred\ têm peso negativo. 
Freqüentemente, é considerado que as arestas associadas a \emph{gaps} e 
\emph{mismatches} têm peso negativo.

Smith e Waterman~\cite{pmid7265238} desenvolveram um algoritmo que obtém um 
alinhamento local ótimo que executa em tempo $O(nm)$ e utiliza a seguinte 
recorrência:
\begin{align*}
&M[0,0]&&=0&&\\
&M[i,0]&&=\max\left(\begin{array}{l} 0,\\
M[i-1,0]+\alignscore(s[i],\aligngap) \end{array}\right)&&,0<i\leq n\\
&M[0,j]&&=\max\left(\begin{array}{l} 0,\\
M[0,j-1]+\alignscore(\aligngap,t[j]) \end{array}\right)&&,0<i\leq n\\
&M[i,j]&&=\max\left(\begin{array}{l} 0,\\
M[i-1,j]+\alignscore(s[i],\aligngap),\\
M[i,j-1]+\alignscore(\aligngap,t[j]),\\
M[i-1,j-1]+\alignscore(s[i],t[j]) \end{array}\right)&&,\begin{array}{l} 0<i\leq
n \textrm{ e }\\ 0<j\leq m \end{array}
\end{align*}

Neste caso, o valor de $M[i,j]$ é a maior pontuação de um alinhamento ótimo de 
qualquer sufixo de $s[1 \Rng i]$ e qualquer sufixo de $t[1 \Rng j]$. A pontuação de um 
alinhamento local ótimo é o maior valor $M[i,j]$ entre todas as posições 
$(i,j)$ de $M$.

Repare que a única diferença para a recorrência do algoritmo que obtém um 
alinhamento global ótimo é que foi incluída a possibilidade de todo elemento 
$M[i,j]$ ser no mínimo zero.

Seja $G$ o \gred\ de $s$ e $t$. Ao invés de um alinhamento ótimo de $s$ e $t$ 
(alinhamento global ótimo) ou um alinhamento ótimo de qualquer fragmento de $s$ 
e qualquer fragmento de $t$ (alinhamento local ótimo), um alinhamento 
semiglobal ótimo é um alinhamento com maior pontuação dentre os seguintes 
alinhamentos ótimos:
\begin{enumerate}
  \item Um alinhamento ótimo de $s$ e qualquer fator de $t$, ou seja, um 
  caminho ótimo entre $(0,j)$ e $(n,j')$, $0 \leq j \leq j' \leq m$. Neste 
  caso, dizemos que qualquer prefixo de $t$ e qualquer sufixo de $t$ podem ser
  retirados para obter um alinhamento semiglobal ótimo.
  \item Um alinhamento ótimo entre $t$ e qualquer fator de $s$, ou seja, um 
  caminho ótimo de $(i,0)$ e $(i',m)$, $0 \leq i \leq i' \leq n$. Neste 
  caso, dizemos que qualquer prefixo de $s$ e qualquer sufixo de $s$ podem ser retirados para 
  obter um alinhamento semiglobal ótimo.
  \item Um alinhamento ótimo de qualquer prefixo de $s$ e qualquer sufixo de 
  $t$, ou seja, um caminho ótimo entre $(0,j)$ e $(i,m)$, $0 \leq j \leq m$ e 
  $0 \leq i \leq n$. Neste caso, dizemos que qualquer prefixo de $t$ e qualquer sufixo de 
  $s$ podem ser retirados para obter um alinhamento semiglobal ótimo.
  \item Um alinhamento ótimo de qualquer sufixo de $s$ e qualquer prefixo de 
  $t$, ou seja, um caminho ótimo entre $(i,0)$ e $(n,j)$, $0 \leq j \leq m$ e 
  $0 \leq i \leq n$. Neste caso, dizemos que qualquer prefixo de $s$ e qualquer sufixo de 
  $t$ podem ser retirados para obter um alinhamento semiglobal ótimo.
\end{enumerate}

Nos alinhamentos semiglobais sufixos e/ou prefixos das \seqs\ podem ser 
retirados para obter um alinhamento semiglobal ótimo. Podemos também restringir 
as opções para a escolha de um alinhamento semiglobal ótimo, a somente um ou 
alguns alinhamentos dentre os 4 descritos acima e portanto, definir diferentes 
tipos de alinhamentos semiglobais ótimos. Por exemplo, podemos definir o 
alinhamento semiglobal ótimo de $s$ e $t$ como o alinhamento com maior 
pontuação entre o alinhamento ótimo de $s$ e qualquer fator de $t$ e o 
alinhamento ótimo de $t$ e qualquer fator de $s$. Neste exemplo, o alinhamento 
semiglobal ótimo é o caminho com maior peso dentre todos os caminhos que inicia 
em qualquer vértice da primeira linha e termina em qualquer vértice da última 
linha, ou inicia em qualquer vértice da primeira coluna e termina em qualquer 
vértice da última coluna do \gred\ de $s$ e $t$.

De acordo com a possibilidade de retirada dos prefixos, a matriz $M$ pode ser 
construída com a seguinte recorrência:
\begin{align*}
&M[0,0]&&=0&&\\
&M[i,0]&&=\max\left(\begin{array}{l} forgive_{s,t}(s,i),\\
M[i-1,0]+\alignscore(s[i],\aligngap) \end{array}\right)&&,0<i\leq n\\
&M[0,j]&&=\max\left(\begin{array}{l} forgive_{s,t}(t,j),\\
M[0,j-1]+\alignscore(\aligngap,t[j]) \end{array}\right)&&,0<i\leq n\\
&M[i,j]&&=\max\left(\begin{array}{l} M[i-1,j]+\alignscore(s[i],\aligngap),\\
M[i,j-1]+\alignscore(\aligngap,t[j]),\\
M[i-1,j-1]+\alignscore(s[i],t[j]) \end{array}\right)&&,\begin{array}{l} 0<i\leq
n \textrm{ e }\\ 0<j\leq m, \end{array}
\end{align*}
onde a função $forgive_{s,t}:\{s,t\} \times \natset \rightarrow \{0,-\infty\}$ 
é tal que $forgive_{s,t}(w,i)=0$ se o prefixo $w[1 \Rng i]$ pode ser 
retirado de $w$ para obter um alinhamento semiglobal ótimo, e 
$forgive_{s,t}(s,i)=-\infty$ caso contrário.

O elemento $M[i,j]$, com a pontuação do alinhamento semiglobal ótimo, será o maior
elemento na região $\Upsilon$ de posições de $M$, onde $\Upsilon$ é tal que:
\begin{itemize}
  \item $(i,m) \in \Upsilon$ se o sufixo $s[i+1 \Rng n]$ pode ser retirado.
  \item $(n,j) \in \Upsilon$ se o sufixo $t[j+1 \Rng m]$ pode ser retirado.
\end{itemize}

Resumindo, dado o \gred\ $G$ de $s$ e $t$, um alinhamento global ótimo de $s$ e 
$t$ é um caminho ótimo de $(0,0)$ a $(n,m)$ em $G$; um alinhamento local ótimo 
é um caminho ótimo dentre todos os possíveis caminhos em $G$ e; um 
alinhamento semiglobal ótimo é um caminho ótimo que sai da primeira linha ou da 
primeira coluna de $G$ e chega na última linha ou na última coluna de $G$.

Repare que todo alinhamento semiglobal ótimo pode ser um alinhamento local ótimo, 
e que todo alinhamento global ótimo pode ser um alinhamento semiglobal ótimo.

\chapter{Alinhamento com inversões}
\label{cap:aligninversion}
\section{Introdução}
\label{sec:aligninversionintroduction}

Neste capítulo, consideraremos
que $s$ e $t$ são duas \seqs\ de comprimentos $n$ e $m$, respectivamente.

Alguns eventos biológicos típicos que são considerados normalmente nos 
procedimentos de alinhamentos atuais de \seqs\ de DNA são: substituição, 
remoção e inserção de nucleotídeos. Um outro evento biológico que ocorre, mas 
que normalmente não é considerado nos alinhamentos usuais, é a inversão, a qual 
iremos considerar sob algumas restrições nos algoritmos de alinhamentos deste
capítulo.

\begin{definicao}[Alinhamento com \invs\ de $s$ e $t$] Um alinhamento com 
\invs\ de $s$ e $t$ é uma matriz \aligninvsym\ de 3 linhas e $r$ colunas, tal 
que:
\begin{itemize}
  \item $\max(n,m) \leq r \leq m+n$;
  \item para toda coluna $k$ de $\aligninvsym$ temos que $\aligninvsym[0,k]\in 
  [1,n] \cup \{\aligngapi\}$, $\aligninvsym[1,k]\in [1,m] \cup \{\aligngapi\}$, 
  $\aligninvsym[2,k]\in \{+,-\}$ e se $\aligninvsym[0,k]=\aligninvsym[1,k]$ 
  então $\aligninvsym[0,k] \neq \aligngapi$;
%   \item para todo $i$ tal que $0 \leq i \leq n$, existe um único $k$ tal que 
%   $\aligninvsym[0,k]=i$, e para todo $j$ tal que $0 \leq j \leq m$, existe um 
%   único $k'$ tal que $\aligninvsym[1,k']=j$;
  \item existe uma sub\seq\ $T=(k_1, k_2, \ldots, k_m)$ da \seq\ de índices das 
  colunas de $\aligninvsym$, tal que $(\aligninvsym[1,k_1], 
  \aligninvsym[1,k_2], \ldots, \aligninvsym[1,k_m])=(1,2,\ldots,m)$ e
  $\aligninvsym[1,k]=\aligngapi$, para todo 
  $k$, tal que $k \notin T$;
  \item existe uma e somente uma coluna
  $k$ de $\aligninvsym$ tal que $\aligninvsym[0,k]=i$, para cada $i$ tal que, $1
  \leq i \leq n$.
%   \item existem uma sub\seq\ $S=(k_1, k_2, \ldots, k_n)$ da \seq\ de índices 
%   das colunas de $\aligninvsym$ e uma \seq\ de \opeds\ de \inv\ 
%   $\opedseqsym=(\opedsym_1, \opedsym_2, \ldots, \opedsym_l)$ tais que:
%   \begin{itemize}
%       \item $\opedcompsym{\opedseqsym}(S)=(k_1', k_2', \ldots, k_n')$, 
%       $(\aligninvsym[0,k_1'], \aligninvsym[0,k_2'], \ldots, 
%       \aligninvsym[0,k_n'])=(1,2,\ldots,n)$ e para todo $k$, tal que $k \notin 
%       S$, $\aligninvsym[0,k]=\aligngapi$;
%       \item $\opedsym_k$ é uma \oped\ de \inv\ para toda $\opedsym_k$ tal que 
%       $\opedsym_k \in \opedseqsym$;
%       \item para todo $x$ e $x'$ tal que $1 \leq x < x' \leq l$ temos que 
%       $\opedsym_{x}=\opedinvsym{i_1}{i_2}$, 
%       $\opedsym_{x'}=\opedinvsym{i_3}{i_4}$ e $1 \leq i_1 \leq i_2 < i_3 \leq 
%       i_4 \leq n$
%   \end{itemize}      
\end{itemize}
\end{definicao}

O exemplo~\ref{ex:aligninv} mostra um alinhamento com \invs\ de duas \seqs\ de
comprimento 10.

\begin{exemplo}[Alinhamento com inversões]
\label{ex:aligninv}
\[\aligninvsym=\left[\begin{array}{cccccccccccc} 1&\aligngapi&2&6&5&\aligngapi&9&3&7&8&4&10\\
1&2&3&\aligngapi&4&5&6&7&8&9&\aligngapi&10\\
+&+&+&-&-&-&-&-&+&+&+&+ \end{array}\right]\]
\end{exemplo}


% Num alinhamento com \invs\ de $s$ e $t$ \aligninvsym, o símbolo correspondente 
% a $\aligninvsym[0,k]$ é o símbolo $s[\aligninvsym[0,k]]$ se $\aligninvsym[0,k] 
% \neq \aligngapi$, ou é o símbolo $\aligngapi$ caso contrário. De forma análoga, 
% o símbolo correspondente a $\aligninvsym[1,k]$ é o símbolo 
% $t[\aligninvsym[1,k]]$ se $\aligninvsym[1,k] \neq \aligngapi$, ou é o símbolo 
% $\aligngapi$ caso contrário. Se $\aligninvsym[2,k]=+$ então o símbolo 
% correspondente a $\aligninvsym[0,k]$ está alinhado com o símbolo correspondente 
% a $\aligninvsym[1,k]$ na coluna $k$ de \aligninvsym. Se $\aligninvsym[2,k]=-$ 
% então o símbolo inverso do símbolo correspondente a $\aligninvsym[0,k]$ está 
% alinhado com o símbolo correspondente a $\aligninvsym[1,k]$ na coluna $k$ de 
% \aligninvsym.
% 
Se $\aligninvsym[0,k] = \aligngapi$ então associamos à coluna $k$ uma \oped\ de 
inserção. Se $\aligninvsym[1,k] = \aligngapi$ então associamos à coluna $k$ uma 
\oped\ de remoção. Se $\aligninvsym[0,k] \neq \aligngapi$ e $\aligninvsym[1,k] 
\neq \aligngapi$ então associamos à coluna $k$ uma \oped\ de substituição.

\begin{definicao}[Transformação com \invs\ de $s$ e $t$] Dadas duas \seqs\ $s$ e 
$t$, dizemos que uma transformação com \invs\ de $s$ e $t$ é qualquer \seq\ de 
\opeds\ $\opedseqsym=(\opedsym_0, \opedsym_1, \ldots, \opedsym_r)$ tal que 
$\opedcompsym{\opedseqsym}(s)=t$ e $\opedsym_k$ é uma \oped\ de inserção, 
remoção, substituição ou \inv, para todo $k$ tal que $0 \leq k \leq r$.
\end{definicao}

Em geral os sistemas de pontuação para alinhamentos consideram que a pontuação 
do alinhamento é a soma das pontuações das \opeds\ da transformação associada, 
através de algum critério, ao alinhamento.

Porém, dado um alinhamento com \invs\ de $s$ e $t$, obter uma transformação com 
\invs\ de $s$ e $t$ pode não ser uma tarefa simples, pois as \opeds\ de \inv\ 
não estão explícitas no alinhamento. Como veremos, para 
alinhamentos com \invnsobs\ a identificação das \opeds\ de \inv\ é mais fácil.

Contudo, dada uma transformação com \invs\ \opedseqsym\ de $s$ e $t$, 
facilmente associamos um alinhamento com \invs\ de $s$ e $t$ à \opedseqsym. 
Portanto, muitas vezes é de interesse obter a transformação com \invs\ de $s$ e 
$t$ e a partir desta, obter o alinhamento com \invs\ associado e sua pontuação.

% Dada uma transformação com \invs\ \opedseqsym\ de $s$ e $t$, construímos um 
% alinhamento \aligninvsym\ com \invs\ de $s$ e $t$ associado a \opedseqsym\ da 
% seguinte forma:
% \begin{enumerate}
%   \item Criamos uma matriz $\aligninvsym$ de 3 linhas e $n$ colunas.
%   \item Preenchemos a linha zero de \aligninvsym\ com os números
%   $1,2,\ldots,n$.
%   \item Preenchemos a linha um de \aligninvsym\ com os símbolos
%   $s[1],s[2],\ldots,s[n]$.
%   \item Colocamos em todas as posições da linha dois de \aligninvsym\ o símbolo
%   $+$.
%   \item Para cada \oped\ $\opedsym$ tal que, $\opedsym \in \opedseqsym$, 
%   fazemos:
%   \begin{itemize}
%       \item se $\opedsym=\opedsubsym{i}{a}{b}$ então $\aligninvsym[1,i']=a$,
%       onde $i'$ é a coluna de \aligninvsym\ tal que, existem $i$ símbolos
%       diferentes de \aligngapi\ em $A[1,0 \Rng i']$,
%       \item se $\opedsym=\opeddelsym{i}{a}$ então
%       $\aligninvsym[1,i']=\aligngapi$, onde $i'$ é a coluna de \aligninvsym\ tal que, existem $i$ símbolos
%       diferentes de \aligngapi\ em $A[1,0 \Rng i']$,
%       \item se $\opedsym=\opedinssym{i}{a}$ então inserimos a coluna xxxx
%       $\aligninvsym[1,i']=\aligngapi$, onde $i'$ é a coluna de \aligninvsym\ tal que, existem $i$ símbolos
%       diferentes de \aligngapi\ em $A[1,0 \Rng i']$,
%   \end{itemize}
% \end{enumerate}

Dadas duas \seqs\ $s$ e $t$ e pontuações fixas para cada \oped\ associada a uma 
mutação, o problema de \emph{obter uma transformação ótima com \invs\ de $s$ e 
$t$} é um problema de otimização que procura uma transformação com \invs\ de 
$s$ e $t$ tal que a soma das pontuações das \opeds\ desta transformação é a 
máxima possível. Algumas vezes, pode ser desejável apenas a obtenção da soma 
das pontuações das \opeds\ da transformação ótima com \invs\ de $s$ e $t$, ou 
seja, a pontuação da transformação ótima com \invs\ de $s$ e $t$.

Vale a pena ressaltar que existem também outras possibilidades de eventos 
relacionados a inversão, como por exemplo:
\begin{itemize}
  \item a \emph{reversão-por-$2$}, que reverte a ordem de \emph{dois símbolos 
  consecutivos};
  \item a \emph{reversão}, que reverte a ordem de \emph{qualquer segmento} de 
  símbolos ao invés de um segmento de comprimento $2$;
\end{itemize}

Em 1975, Wagner~\cite{Wagner75} estudou o problema de obter um alinhamento
ótimo com reversões-por-$2$ e provou que ele admite uma solução polinomial se o 
custo de uma reversão-por-$2$ é nulo. Por outro lado, ele também provou que a 
obtenção de uma solução ótima é \emph{NP-difícil}, se cada operação tem um 
custo positivo constante.

Como pode ser visto em~\cite{1100950}, o problema de decisão associado ao 
problema de obter uma transformação ótima com \invs\ para um alfabeto ilimitado 
é NP-difícil

Dada a dificuldade de se resolver o problema de obter um alinhamento ótimo com
\invs\ de forma eficiente, três estratégias principais têm sido consideradas:

\begin{enumerate}
\item inversões sem sobreposições; 
\item ordenação de permutações sem sinal por reversões e; 
\item ordenação de permutações com sinal por reversões. 
\end{enumerate}	 

A segunda estratégia (ordenação de permutações sem sinal por reversões), 
aplica-se bem a \emph{seqüências de genes} e na comparação de genomas de 
mitocôndrias. Ela não se aplica a \seqs\ de nucleotídeos nem a \seqs\ de 
aminoácidos porque \emph{repetições} de símbolos \emph{não são} permitidas. 
Além disso, \emph{nenhuma inserção} e \emph{nenhuma remoção} são consideradas e 
a única operação permitida é a reversão, em que a \emph{reversão} é definida 
para transformar uma seqüência tal como ${1,2,3,4,5}$ em ${1,\,4,3,2,\,5}$. O 
problema, também chamado de \emph{ordenação de permutações sem sinal por 
reversões}, calcula a distância de edição de duas permutações considerando a 
operação de reversão. Neste caso, os dados são duas permutações de 
${1,2,3,\ldots,n}$, onde $n$ é o número de genes. Kececioglu e 
Sankoff~\cite{MR95j:68125} propuseram um algoritmo de $2$-aproximação em 1995 e 
Christie~\cite{MR1642934} propôs um algoritmo de aproximação de razão $3/2$ em 
1998. De fato, Caprara~\cite{MR2000a:68046} provou em 1999 que esse problema na 
verdade é NP-difícil.

A terceira estratégia é o problema chamado \emph{ordenação de permutações com 
sinal por reversões}. Este é o mesmo problema de ordenação de permutações sem 
sinal por reversões até o ponto em que os sinais também são atribuídos a um 
gene e uma reversão também troca seu sinal. Por exemplo, uma reversão poderia 
transformar ${1,2,3,4,5}$ em ${1,-4,-3,-2,5}$. Este sinal é normalmente 
associado à direção do gene (a qual filamento de DNA ele pertence). Hannenhalli 
e Pevzner~\cite{225112} propuseram o primeiro algoritmo polinomial para o 
problema em 1995 e iniciaram uma seqüência de artigos baseados nessa 
estratégia. O algoritmo de Hannenhalli e Pevzner era $O(n^4)$ e foi melhorado 
para $O(n^2)$ por Kaplan, Shamir e Tarjan~\cite{MR97k:92016,MR2001c:92008} em 
1997. Em 2004 Tannier e Sagot~\cite{tannier04:_sortin_by_rever_in_subquad_time} 
propuseram um algoritmo subquadrático para este problema. Em 2001, Bader, 
Moret, e Yan~\cite{MR2003i:68102} propuseram um algoritmo que calcula a 
distância de edição em $O(n)$ (a \seq\ de reversões ainda requer $O(n^2)$). 
Estes métodos têm sido aplicados a estudos de reconstrução filogenética.

Em 2000, El-Mabrouk~\cite{MR1789777,MR2002g:92019} estudou a inclusão de duas 
operações: inserções e remoções de segmentos genéticos. Ela obteve resultados 
parciais e propôs uma solução polinomial exata para um caso e uma heurística 
polinomial com um testador polinomial para otimalidade no outro caso. Símbolos 
repetidos ainda não foram permitidos. Em 2002, El-Mabrouk~\cite{MR1955942} 
também obteve alguns resultados parciais ao considerar reversões e duplicações.

A terceira estratégia é principalmente usada no estudo de \invs\ de \seqs\ de 
genes. Novos resultados comparativos feitos por Sherer et 
al.~\cite{pmid16254605} nas \seqs\ de DNA do homem e do chimpanzé, mostram 
também a importância do estudo da \inv\ ao nível da \seq\ de DNA, onde esses 
métodos não podem ser aplicados. Por exemplo, Sherer et al.\ reportaram 83 
\seqs\ reversas que estão contidas dentro de genes.

Em 1992, Schöniger e Waterman \cite{pmid1591531} introduziram uma hipótese 
simplificadora: todas as regiões envolvendo \invs\ não se sobrepõem, ou seja, a 
primeira estratégia. Esta simplificação é realista para comparação de \seqs\ de 
DNA relativamente próximas. Isto levou ao problema do \emph{alinhamento com 
\invnsobs}, que será definido mais adiante. Eles apresentaram uma solução que 
leva tempo $O(n^6)$ para esse problema. Também introduziram uma heurística que 
reduz a complexidade para algo entre $O(n^2)$ e $O(n^4)$, dependendo dos dados 
de entrada. Essa heurística usa o algoritmo desenvolvido por Waterman e Eggert 
\cite{pmid2448477} que informa os $k$ melhores alinhamentos locais não 
mutuamente intersectantes.

Em 2003, trabalhos independentes~\cite{lago03:wob03,gao03:_space_effic_algor_sequen_align_inver} 
apresentaram algoritmos exatos que resolvem o problema do alinhamento com 
\invnsobs\ em tempo $O(n^4)$ e memória $O(n^2)$.

Em 2005, do Lago et al.\cite{MR2132586} propuseram um outro algoritmo que é uma 
implementação dinâmica esparsa que reduz o uso de recursos se $o(n^2)$ 
atribuições são dadas. Isto é freqüentemente esperado se a cardinalidade do 
alfabeto for grande, como por exemplo quando as letras são fragmentos de DNA de 
comprimento fixo.

Propomos dois algoritmos exatos que resolvem o problema do alinhamento com 
\invnsobs\ em tempo $O(n^3 \log n)$~\cite{MR2173809} e 
$O(n^3)$~\cite{vellozo06:_align_with_non_overl_inver}. O algoritmo $O(n^3 \log 
n)$ permite maior flexibilidade no sistema de pontuação, mas os sistemas de 
pontuação usuais, com pesos inteiros e constantes, se usados no algoritmo 
$O(n^3)$ resultam numa complexidade cúbica no tempo de execução.

 % nas atribuições de pontuações das operações, já que o 
% algoritmo $O(n^3)$ tem esta complexidade garantida quando as pontuações das 
% \opeds\ são constantes inteiras ou obedecem a certas restrições.

\section{Alinhamento com \invnsobs}
\label{sec:aligninvnsob}

% Dados $i'$, $s$, $i$, $t$ e $j$ tais que $1\leq i'$, $s \in \alfabeto^*$, $t 
% \in \alfabeto^*$, $1 \leq i \leq |s|$ e $1 \leq j \leq |t|$ dizemos que a 
% função $\opedsustbsym{i'}{s}{i}{t}{j}: \alfabeto^* \rightarrow \alfabeto^*$ 
% definida por $\opedsustbsym{i'}{s}{i}{t}{j}(x) = 
% \opedsubsym{i'}{t[j]}{s[i]}(x)$, para $i' \leq |x|$ e $x[i']=s[i]$, é uma 
% \emph{\oped\ de substituição} baseado em $s$ e $t$. Dizemos que o índice $i$ de
% $s$ e o índice $j$ de $t$ estão envolvidos nesta \oped.
%   

Nesta seção, algumas vezes aplicaremos a \oped\ de \inv\ sobre o alfabeto 
$\natset \cup \{\aligngapi\}$. Consideraremos que se $a$ é um símbolo tal que, 
$a \in \natset \cup \{\aligngapi\}$, então $\invert{a}=a$.

\begin{definicao}[Alinhamento com \invnsobs\ de $s$ e $t$] Um alinhamento com 
\invnsobs\ de $s$ e $t$ é uma matriz \aligninvsym\ de 3 linhas e $r$ colunas, 
tal que:
\begin{itemize}
  \item $\max(n,m) \leq r \leq m+n$;
  \item para toda coluna $k$ de $\aligninvsym$ temos que $\aligninvsym[0,k]\in 
  [1,n] \cup \{\aligngapi\}$, $\aligninvsym[1,k]\in [1,m] \cup \{\aligngapi\}$, 
  $\aligninvsym[2,k]\in \{+,-,*\}$ e se $\aligninvsym[0,k]=\aligninvsym[1,k]$ 
  então $\aligninvsym[0,k] \neq \aligngapi$;
%   \item para todo $i$ tal que $0 \leq i \leq n$, existe um único $k$ tal que 
%   $\aligninvsym[0,k]=i$, e para todo $j$ tal que $0 \leq j \leq m$, existe um 
%   único $k'$ tal que $\aligninvsym[1,k']=j$;
  \item existe uma sub\seq\ $T=(k_1, k_2, \ldots, k_m)$ da \seq\ de índices das 
  colunas de $\aligninvsym$, tal que $(\aligninvsym[1,k_1], 
  \aligninvsym[1,k_2], \ldots, \aligninvsym[1,k_m])=(1,2,\ldots,m)$ e 
  $\aligninvsym[1,k]=\aligngapi$, para todo $k$, tal que $k \notin T$;
  \item existe uma \seq\ de \opeds\ de \inv\ $\opedseqsym$ tal que:
  \begin{itemize}
     \item para cada \oped\ de \inv\ $\opedsym=\opedinvsym{i_1}{i_2}$ em 
     $\opedseqsym$ temos que $\aligninvsym[2,i_1]=*$ e $\aligninvsym[2,i]= -$, 
     para todo $i$ tal que $i_1 < i \leq i_2$, e
     \item para cada coluna $k$ de $\aligninvsym$, tal que $\aligninvsym[2,k] 
     \in \{-,*\}$, existe uma e somente uma \oped\ 
     $\opedsym=\opedinvsym{i_1}{i_2}$ em $\opedseqsym$ tal que $i_1\leq k \leq 
     i_2$;
  \end{itemize}
     \item existe uma sub\seq\ $S=(k_1, k_2, \ldots, k_n)$ da \seq\ de índices 
     de $s'=\opedcompsym{\opedseqsym}(\aligninvsym[0,0\Rng r-1])$ tal que 
     $(s'[k_1], s'[k_2], \ldots, s'[k_n])=(1,2,\ldots,n)$ e $s'[k]=\aligngapi$, 
     para todo $k$, tal que $k \notin S$.
%   \item existem uma sub\seq\ $S=(k_1, k_2, \ldots, k_n)$ da \seq\ de índices 
%   das colunas de $\aligninvsym$ e uma \seq\ de \opeds\ de \inv\ 
%   $\opedseqsym=(\opedsym_1, \opedsym_2, \ldots, \opedsym_l)$ tais que:
%   \begin{itemize}
%       \item $\opedcompsym{\opedseqsym}(S)=(k_1', k_2', \ldots, k_n')$, 
%       $(\aligninvsym[0,k_1'], \aligninvsym[0,k_2'], \ldots, 
%       \aligninvsym[0,k_n'])=(1,2,\ldots,n)$ e para todo $k$, tal que $k \notin 
%       S$, $\aligninvsym[0,k]=\aligngapi$;
%       \item $\opedsym_k$ é uma \oped\ de \inv\ para toda $\opedsym_k$ tal que 
%       $\opedsym_k \in \opedseqsym$;
%       \item para todo $x$ e $x'$ tal que $1 \leq x < x' \leq l$ temos que 
%       $\opedsym_{x}=\opedinvsym{i_1}{i_2}$, 
%       $\opedsym_{x'}=\opedinvsym{i_3}{i_4}$ e $1 \leq i_1 \leq i_2 < i_3 \leq 
%       i_4 \leq n$
%   \end{itemize}      
\end{itemize}
\end{definicao}

Diremos que o comprimento de um alinhamento com \invnsobs\ é a quantidade de
colunas deste alinhamento.

O exemplo~\ref{ex:aligninsob} mostra um alinhamento com \invnsobs\ de 
comprimento 12 de duas \seqs\ de comprimento 10 cada uma.

\begin{exemplo}[Alinhamento com \invnsobs]
\label{ex:aligninsob}
\[\aligninvsym=\left[\begin{array}{cccccccccccc} 1&\aligngapi&2&6&5&4&3&\aligngapi&9&8&7&10\\
1&2&3&\aligngapi&4&5&6&7&8&9&\aligngapi&10\\
+&+&+&*&-&-&-&-&*&-&-&+ \end{array}\right]\]
\end{exemplo}

Dado um alinhamento \aligninvsym\ com \invnsobs\ de $s$ e $t$, diremos que as 
colunas que estão no intervalo $[k_1,k_2]$ são um trecho de inversão de 
$\aligninvsym$ se $\aligninvsym[2,k_1]=*$, $\aligninvsym[2,k_2]=-$ e não existe 
uma coluna $k_2+1$ tal que $\aligninvsym[2,k_2+1]=-$.

Seja $\alignseti$ o conjunto de todos os possíveis alinhamentos com \invnsobs\ 
de duas \seqs. 

\begin{definicao}[Função parcial $\alignsimbsym$]
Seja a função parcial $\alignsimbsym: \alignseti \times \{0,1\} 
\times \natset \rightarrow \alfabeto \cup \{\aligngapi\}$ definida por:
\begin{itemize}
  \item $\alignsimb{\aligninvsym}{0}{k}=s[\aligninvsym[0,k]]$ se 
  $\aligninvsym[0,k] \neq \aligngapi$, $\aligninvsym[2,k]=+$ e $k$ é o índice 
  de uma coluna de \aligninvsym, onde \aligninvsym\ é um alinhamento com 
  \invnsobs\ de $s$ e $t$;
  \item $\alignsimb{\aligninvsym}{1}{k}=t[\aligninvsym[1,k]]$ se 
  $\aligninvsym[1,k] \neq \aligngapi$ e $k$ é o índice de uma coluna de 
  \aligninvsym, onde \aligninvsym\ é um alinhamento com \invnsobs\ de $s$ e $t$;
  \item $\alignsimb{\aligninvsym}{0}{k}=\invert{s[\aligninvsym[0,k]]}$ se 
  $\aligninvsym[0,k] \neq \aligngapi$, $\aligninvsym[2,k] \in \{-,*\}$ e $k$ é 
  o índice de uma coluna de \aligninvsym, onde \aligninvsym\ é um alinhamento 
  com \invnsobs\ de $s$ e $t$;
  \item $\alignsimb{\aligninvsym}{0}{k}=\aligngapi$ se $\aligninvsym[0,k] = 
  \aligngapi$ e $k$ é o índice de uma coluna de \aligninvsym;
  \item $\alignsimb{\aligninvsym}{1}{k}=\aligngapi$ se $\aligninvsym[1,k] = 
  \aligngapi$ e $k$ é o índice de uma coluna de \aligninvsym.
\end{itemize} 
\end{definicao}

Seja $\opedpontset$ o conjunto com todas as possíveis \opeds\ pontuais. Seja 
$\opedpontset^*$ o conjunto com todas as possíveis \seqs\ de \opeds\ pontuais.
Seja $\opedinvset$ o conjunto com todas as possíveis \opeds\ de \inv. 

O operador $\opedconcat$ será utilizado para indicar a concatenação de \seqs\ de 
\opeds. Por exemplo, $(\opedinssym{j-1}{t[j]})\opedconcat 
(\opedinvsym{j}{j+1},\opedsubsym{j}{t[j]}{\overline{s[i]}},\opeddelsym{j+1}{\overline{s[i+1]}}) 
= (\opedinssym{j-1}{t[j]}, 
\opedinvsym{j}{j+1},\opedsubsym{j}{t[j]}{\overline{s[i]}},\opeddelsym{j+1}{\overline{s[i+1]}})$

Seja $\opedset_1=\{(\opedsym_1)\} \cup \{(\opedsym_2) \opedconcat 
\opedsym_3\}$, onde $\opedsym_1 \in \opedpontset$, $\opedsym_2 \in \opedinvset$ 
e $\opedsym_3 \in \opedpontset^*$, ou seja, $\opedsym_1$ é uma \oped\ pontual, 
$\opedsym_2$ é uma \oped\ de \inv\ e $\opedsym_3$ é uma \seq\ de \opeds\ 
pontuais. Se \opedseqsym\ é um elemento de $\opedset_1$ então \opedseqsym\ ou é 
uma \seq\ composta por uma \oped\ pontual, ou é uma \seq\ composta por uma 
\oped\ de inversão concatenada com uma \seq\ de \opeds\ pontuais. Por exemplo, 
$(\opedinssym{j-1}{t[j]}) \in \opedset_1$ e 
$(\opedinvsym{j}{j+1},\opedsubsym{j}{t[j]}{\overline{s[i]}},\opeddelsym{j+1}{\overline{s[i+1]}}) 
= (\opedinvsym{j}{j+1})\opedconcat(\opedsubsym{j}{t[j]}{\overline{s[i]}}, 
\opeddelsym{j+1}{\overline{s[i+1]}}) \in \opedset_1$.

\begin{definicao}[Função parcial \alignimaxind] Seja a função parcial 
$\alignimaxind: \alignseti \times \{0,1\} \times \natset \times \natset 
\rightarrow \natset$ definida por $\alignimaxind(\aligninvsym,x,i, i')=k$, onde 
$k$ é o valor do maior elemento diferente de \aligngapi\ dentre os elementos de 
$\aligninvsym[x,i\Rng i']$, ou é zero se não existirem elementos diferentes de 
\aligngapi\ em $\aligninvsym[x,i\Rng i']$, para $x \in \{0,1\}$.
\end{definicao}

\begin{definicao}[Função parcial \aligniminind] Seja a função parcial 
$\aligniminind: \alignseti \times \{0,1\} \times \natset \times \natset 
\rightarrow \natset$ definida por $\aligniminind(\aligninvsym,x,i, i')=k$, onde 
$k$ é o valor do menor elemento diferente de \aligngapi\ dentre os elementos de 
$\aligninvsym[x,i\Rng i']$, ou é zero se não existirem elementos diferentes de 
\aligngapi\ em $\aligninvsym[x,i\Rng i']$, para $x \in \{0,1\}$.
\end{definicao}

Repare que zero não é um índice 
das \seqs\ $s$ e $t$, pois o índice do primeiro elemento de qualquer uma destas
\seqs\ é 1 (um). 

\begin{definicao}[Função parcial \alingblockinvsym]
Seja a função parcial $\alingblockinvsym: \alignseti \times \natset \rightarrow 
\natset$ definida por $\alingblockinv{\aligninvsym}{k}=k'$ se 
$\aligninvsym[2,k]=*$, onde $k'$ é uma coluna de \aligninvsym\ tal que, para 
todo $l$ tal que $k+1 \leq l \leq k'$, temos que $\aligninvsym[2,l]=-$ e não 
existe uma coluna $k'+1$ em $\aligninvsym$ tal que $\aligninvsym[2,k'+1]= -$. 
\end{definicao}

Por exemplo, se $\aligninvsym[2,0..m]= (+,*,-,-,-,+)$ então 
\alingblockinv{\aligninvsym}{k} só é definida para $k=1$ e 
$\alingblockinv{\aligninvsym}{1}=4$. Em outras palavras, 
$\alingblockinv{\aligninvsym}{k}$ é a coluna de $\aligninvsym$ onde termina um 
trecho de inversão iniciado na coluna $k$ de $\aligninvsym$.

A seguir vamos definir uma função parcial que associa uma coluna de um 
alinhamento com \invnsobs, a uma \seq\ de \opeds\ contendo uma ou duas \opeds. 
Esta função parcial será utilizada para estabelecermos um sistema de pontuação 
para um alinhamento com \invnsobs.

\begin{definicao}[Função parcial $\alignopedinvsym$]
Seja a função parcial $\alignopedinvsym: \alignseti \times \natset \rightarrow 
\opedset_1$ tal que $\alignopedinv{\aligninvsym}{k}=\opedseqsym$ se $k$ é o índice 
de uma coluna de \aligninvsym, onde \aligninvsym\ é um alinhamento com 
\invnsobs\ de $s$ e $t$ e \opedseqsym\ é uma \seq\ de \opeds\ tal que:
\begin{itemize}
  \item $\opedseqsym=(\opedinssym{j-1}{t[j]})$ se $\aligninvsym[0,k] = \aligngapi$ 
  e $\aligninvsym[2,k]\neq *$, onde $j=\aligninvsym[1,k]$,
  \item $\opedseqsym=(\opedsubsym{j}{t[j]}{a})$ se $\aligninvsym[0,k] \neq 
  \aligngapi$, $\aligninvsym[1,k] \neq \aligngapi$ e $\aligninvsym[2,k]\neq *$, 
  onde $a=\alignsimb{\aligninvsym}{0}{k}$ e $j=\aligninvsym[1,k]$,
  \item $\opedseqsym=(\opeddelsym{j+1}{a})$ se $\aligninvsym[1,k] = \aligngapi$ e 
  $\aligninvsym[2,k]\neq *$, onde $a=\alignsimb{\aligninvsym}{0}{k}$ e 
  $j=\alignimaxind(\aligninvsym,1,0, k-1)$,
  \item $\opedseqsym=(\opedinvsym{j}{j+i'-i}, \opedinssym{j-1}{t[j]})$ se 
  $\aligninvsym[0,k] = \aligngapi$\ \  e $\aligninvsym[2,k]= *$, onde 
  $j=\aligninvsym[1,k]$, $i=\aligniminind(\aligninvsym,0,k, k')$, 
  $i'=\alignimaxind(\aligninvsym,0,k, k')$ e $k'=\alingblockinv{\aligninvsym}{k}$,
  \item $\opedseqsym=(\opedinvsym{j}{j+i'-i}, \opedsubsym{j}{t[j]}{a})$ se 
  $\aligninvsym[0,k] \neq \aligngapi$, $\aligninvsym[1,k] \neq \aligngapi$  e 
  $\aligninvsym[2,k]= *$, onde $a=\alignsimb{\aligninvsym}{0}{k}$, 
  $j=\aligninvsym[1,k]$, $i=\aligniminind(\aligninvsym,0,k, k')$, 
  $i'=\alignimaxind(\aligninvsym,0,k, k')$ e $k'=\alingblockinv{\aligninvsym}{k}$,
  \item $\opedseqsym=(\opedinvsym{j}{j+i'-i}, \opeddelsym{j+1}{a})$ se 
  $\aligninvsym[1,k] = \aligngapi$\ \ e $\aligninvsym[2,k]= *$, onde 
  $a=\alignsimb{\aligninvsym}{0}{k}$, $j=\alignimaxind(\aligninvsym,1,0, k-1)$, 
  $i=\aligniminind(\aligninvsym,0,k, k')$, $i'=\alignimaxind(\aligninvsym,0,k, k')$ e 
  $k'=\alingblockinv{\aligninvsym}{k}$.
\end{itemize} 
\end{definicao}

Repare que a cada coluna associamos uma \seq\ de \opeds\ com uma ou duas 
\opeds, sendo que a \seq\ é composta por duas \opeds, somente quando a coluna 
representar o início de um trecho invertido ($\aligninvsym[2,k]= *$). Neste 
caso, a primeira \oped\ da \seq\ de \opeds\ associada a coluna é sempre uma 
inversão.

% Portanto, se $\aligninvsym[0,k] = \aligngapi$ então associamos à coluna $k$ de 
% \aligninvsym\ uma \seq\ de \opeds\ com uma \oped\ de inserção; se
% $\aligninvsym[1,k] = \aligngapi$
% então associamos à coluna $k$ de \aligninvsym\ uma \seq\ de \opeds\ com uma \oped\ de remoção; se 
% $\aligninvsym[0,k] \neq \aligngapi$ e $\aligninvsym[1,k] \neq \aligngapi$ então 
% associamos à coluna $k$  de \aligninvsym\ uma \seq\ de \opeds\ com uma \oped\ de substituição. Se 
% $\aligninvsym[2,k]=*$ (o que representa o início de uma inversão) então, antes  
% dessa \oped\ pontual é inserido, associamos também à coluna $k$ de \aligninvsym\ uma 
% \oped\ de \inv.
% 
Pode-se verificar que, dado um alinhamento com \invnsobs\ \aligninvsym\ de $s$ 
e $t$ de comprimento $r$, temos que $\opedcompsym{\opedseqsym}(s)=t$, onde 
$\opedseqsym=\alignopedinv{\aligninvsym}{0} \opedconcat 
\alignopedinv{\aligninvsym}{1}\opedconcat \ldots \opedconcat 
\alignopedinv{\aligninvsym}{r-1}$.

Sejam $\opedseqsym$ uma \seq\ de \opeds\ pontuais ou de inversão e $s'$ uma 
\seq\ sobre a qual $\opedcompsym{\opedseqsym}$ é definida tal que, a cada 
símbolo de $s'$ está associada a sua posição em $s'$, e se um símbolo $a$ que 
está associado a posição $i$ de $s'$ é substituído por um símbolo $b$ numa 
\oped\ de substituição ou pelo seu complementar $\invert{a}$ numa \oped\ de 
inversão, então associamos a este símbolo $b$ ou $\invert{a}$ a mesma posição 
$i$ de $a$. Dizemos que uma posição de $s$ é envolvida em uma \oped\ de 
inversão \opedsym\ de $\opedseqsym$, se  existe uma \oped\ de inversão 
\opedsym\ em $\opedseqsym$ tal que, ao aplicarmos $\opedcompsym{\opedseqsym}$ 
sobre $s'$ então \opedsym\ envolve um símbolo associado a $i$. Dizemos que 
\opedseqsym\ não tem \invs\ sobrepostas se ao aplicarmos 
$\opedcompsym{\opedseqsym}$ sobre $s'$, qualquer posição $i$ de $s'$ é 
envolvida por no máximo uma única \oped\ de inversão \opedsym\ em 
$\opedseqsym$.

\begin{definicao}[Transformação com \invnsobs\ de $s$ e $t$] Dadas duas \seqs\ 
$s$ e $t$, dizemos que uma transformação com \invnsobs\ de $s$ e $t$ é uma 
\seq\ de \opeds\ sem \invs\ sobrepostas $\opedseqsym=(\opedsym_0, \opedsym_1, 
\ldots, \opedsym_r)$ tal que $\opedcompsym{\opedseqsym}(s)=t$ e $\opedsym_k$ é 
uma \oped\ de inserção, remoção, substituição ou \inv, para todo $k$ tal que $0 
\leq k \leq r$.
\end{definicao}

Dado um alinhamento com \invnsobs\ \aligninvsym\ de $s$ e $t$, obter uma 
transformação com \invnsobs\ de $s$ e $t$, é uma tarefa simples, pois tanto as 
\opeds\ pontuais quanto as \opeds\ de \inv\ necessárias para esta transformação 
estão explícitas no alinhamento. Em particular, a \seq\ de \opeds\ 
$\tranfbyopisym=\alignopedinv{\aligninvsym}{0}\opedconcat 
\alignopedinv{\aligninvsym}{1} \opedconcat \ldots \opedconcat 
\alignopedinv{\aligninvsym}{r-1}$, é uma transformação com \invnsobs\ de $s$ e 
$t$, onde $r$ é o comprimento de \aligninvsym. Temos também que, dada uma 
transformação com \invnsobs\ \opedseqsym\ de $s$ e $t$, podemos associar um 
alinhamento com \invnsobs\ de $s$ e $t$ à \opedseqsym.
% Vale a pena ressaltar 
% que, podem existir mais de uma transformação com \invnsobs\ de $s$ e $t$, que 
% pode ser obtida com as \opeds\ associadas a cada coluna de um alinhamento com 
% \invnsobs\ de $s$ e $t$.

Dado um alinhamento com \invnsobs\ \aligninvsym\ de $s$ e $t$ de comprimento 
$r$, diremos que a \seq\ 
$\tranfbyopisym=\alignopedinv{\aligninvsym}{0}\opedconcat 
\alignopedinv{\aligninvsym}{1} \opedconcat \ldots \opedconcat 
\alignopedinv{\aligninvsym}{r-1}$ é a \emph{transformação com \invnsobs\ de $s$ 
e $t$ associada a \aligninvsym\ pela função parcial \alignopedinvsym}.
% Denotaremos por \tranfbyopisym\ a transformação com \invnsobs\ de $s$ e $t$ 
% associada a \aligninvsym\ pela função parcial \alignopedinvsym.q

% Se a transformação com \invnsobs\ \opedseqsym\ está associada 
% a um alinhamento com \invnsobs\ \aligninvsym\ pela função parcial
% \alignopedinvsym então não existe outro alinhamento com \invnsobs\
% \aligninvsym'\ que pode ser associado a \opedseqsym\ pela função parcial
% \alignopedinvsym. Apesar da \oped\ $\opedinssym{j-1}{t[j]}$ poder estar
% associada a duas colunas 

Seja $\opedset$ o conjunto com todas as \opeds\ e $\opedset^*$ o conjunto com 
todas as \seqs\ de \opeds. 

\begin{definicao}[Função \opedweigsym]
Seja a função $\opedweigsym: \opedset \cup 
\opedset^* \rightarrow \realset$ tal que:
\begin{itemize}
  \item $\opedweigsym(\opedsym)=$ pontuação da \oped\ \opedsym, se \opedsym\ é 
  uma \oped.
  \item $\opedweigsym(\opedseqsym)=\sum_{\opedsym \in \opedseqsym} 
  \opedweigsym(\opedsym)$, se \opedseqsym\ é uma \seq\ de \opeds.
\end{itemize}
\end{definicao}

Ou seja, dado uma \oped\ \opedsym\ diremos que $\opedweigsym(\opedsym)$ é a
pontuação da \oped\ \opedsym\ e, dado uma \seq\ de \opeds\ \opedseqsym, diremos
que $\opedweigsym(\opedseqsym)$ é a pontuação da \seq\ de \opeds\ \opedseqsym.

\begin{definicao}[Pontuação de alinhamento com \invnsobs] 
Consideraremos que a \emph{pontuação de um alinhamento com \invnsobs\ 
\aligninvsym\ de $s$ e $t$} é igual a pontuação da transformação com \invnsobs\ 
de $s$ e $t$ associada a \aligninvsym\ pela função parcial \alignopedinvsym.
\end{definicao}

Ou seja, vamos considerar que a pontuação de um alinhamento com \invnsobs\ 
\aligninvsym\ de $s$ e $t$ é a soma das pontuações das \opeds\ associadas a 
\aligninvsym\ através da função parcial \alignopedinvsym.

Denotaremos por \aligninvscoresym\ a pontuação de um alinhamento com \invnsobs\ 
\aligninvsym\ de $s$ e $t$. Logo, consideraremos que 
$\aligninvscoresym=\opedweigsym(\tranfbyopisym)$.

Um alinhamento ótimo \aligninvoptimumsym\ com \invnsobs\ de $s$ e $t$ é um 
alinhamento que tem pontuação máxima dentre todos os possíveis alinhamentos com 
\invnsobs\ de $s$ e $t$. Diremos que 
$\aligninvoptimumscoresym=\opedweigsym(\tranfoptimumbyopisym)$ é a pontuação de 
um alinhamento ótimo com \invnsobs\ de $s$ e $t$.
% Com isto, definimos a transformação ótima com 
% \invnsobs\ de $s$ e $t$, como uma transformação com \invnsobs\ de $s$ e $t$ de 
% pontuação máxima, dentre as possíveis transformações com \invnsobs\ de $s$ e 
% $t$ que estão associadas a algum alinhamento com \invnsobs\ de $s$ e $t$ pela 
% função parcial \alignopedinvsym.

Seja \opedseqsym\ uma transformação com \invnsobs\ de $s$ e $t$. Pode-se 
verificar que podemos alterar a ordem de quaisquer \opeds\ que estão em 
\opedseqsym\ e, de acordo com a nova ordem das \opeds, fazer algumas alterações 
nos índices e nos símbolos das \opeds\ de \opedseqsym\ para obter uma nova 
\seq\ de \opeds\ \opedseqsym' tal que, \opedseqsym' também é uma transformação 
com \invnsobs\ de $s$ e $t$. Ou seja, as \opeds\ de \opedseqsym\ podem ser 
colocadas em qualquer ordem, alterando-se apenas os índices e símbolos das 
\opeds, para obter uma outra transformação com \invnsobs\ de $s$ e $t$.

Suponha um sistema de pontuação tal que, $-g <0$ é a pontuação das \opeds\ de 
inserção e remoção (\emph{gaps}), $-r <0$ é a pontuação das \opeds\ de 
substituição de símbolos diferentes (\emph{mismatches}), zero é a pontuação da 
\oped\ de substituição de um símbolo por ele mesmo (\emph{match}) e 
$\opedweiginv < 0$ é a pontuação de uma \oped\ de \inv. Seja \opedseqsym\ uma 
transformação com \invnsobs\ de $s$ e $t$ de pontuação máxima, ou seja, não 
existe outra transformação $\opedseqsym_1$ com \invnsobs\ de $s$ e $t$ tal que 
$\opedweigsym(\opedseqsym_1)>\opedweigsym(\opedseqsym)$. Utilizando esse 
sistema de pontuação, temos que 
$\opedweigsym(\tranfoptimumbyopisym)=\opedweigsym(\opedseqsym)$, ou seja, a 
transformação com \invnsobs\ de $s$ e $t$ $\tranfoptimumbyopisym$ é uma 
transformação de pontuação máxima dentre todas as possíveis transformações com 
\invnsobs\ de $s$ e $t$.

\begin{definicao}[Função parcial \eginvert{j'}]
Seja a função parcial $\eginvert{j'}:\opedset \cup \opedset^* \rightarrow 
\opedset$, onde $j' \in \intset$, definida por:
\begin{itemize}
  \item $\eginvert{j'}(\opedsubsym{j}{a}{b})=\opedsubsym{j'+j}{a}{b}$, se $j'+j 
  \geq 1$,
  \item $\eginvert{j'}(\opedinssym{j-1}{a})=\opedinssym{j'+j-1}{a}$, se $j'+j-1 
  \geq 1$,
  \item $\eginvert{j'}(\opeddelsym{j+1}{a})=\opeddelsym{j'+j+1}{a}$, se $j'+j+1 
  \geq 1$,
  \item $\eginvert{j'}(\opedinvsym{i}{i'})=\opedinvsym{j'+i}{j'+i'}$, se $j'+i 
  \geq 1$,
  \item 
  $\eginvert{j'}(\opeddupsym{i_1}{i_2}{i_3})=\opeddupsym{j'+i_1}{j'+i_2}{j'+i_3}$, 
  se $j'+i_1 \geq 1$ e $j'+i_3 \geq 0$,
  \item 
  $\eginvert{j'}(\opedexcsym{i_1}{i_2}{i_3})=\opedexcsym{j'+i_1}{j'+i_2}{j'+i_3}$, 
  se $j'+i_1 \geq 1$ e $j'+i_3 \geq 0$,
  \item $\eginvert{j'}(\opedseqsym)=\opedseqsym'$, onde 
  $\opedseqsym=(\opedsym_0, \opedsym_1, \ldots, \opedsym_r)$ é uma \seq\ de 
  \opeds\ e $\opedseqsym'=(\eginvert{j'}(\opedsym_0), 
  \eginvert{j'}(\opedsym_1), \ldots, \eginvert{j'}(\opedsym_r))$, se 
  $\eginvert{j'}$ é definida para cada \oped\ de \opedseqsym.
\end{itemize}
\end{definicao}

Ou seja, a função parcial $\eginvert{j'}$ acrescenta o valor $j'$  aos índices 
de uma ou mais \opeds.

% Seja $k$ uma coluna de um alinhamento ótimo com \invnsobs\ \aligninvsym\ de $s$ 
% e $t$ tal que $\aligninvsym[2,k]=*$. Sejam 
% $k'=\alingblockinv{\aligninvsym}{k}$, $i'=\aligniminind(\aligninvsym,0,k, k')$, 
% $i=\alignimaxind(\aligninvsym,0,k, k')$, $j'=\aligniminind(\aligninvsym,1,k, k')$, 
% $j=\alignimaxind(\aligninvsym,1,k, k')$ e  
% $\opedseqsym=(\eginvert{-j'}(\alignopedinv{\aligninvsym}{k}), (\eginvert{-j'}(\alignopedinv{\aligninvsym}{k+1}), 
% \ldots$,$ (\eginvert{-j'}(\alignopedinv{\aligninvsym}{k'}))$. Temos que
% \opedseqsym\ é a transformação com pontuação máxima dentre as  
% transformações com \invnsobs\ de $s[i' \Rng i]$ e $t[j' \Rng j]$.

A seguir vamos associar a cada aresta de um \gred\ estendido $G$ de $s$ e $t$, 
uma \oped\ de tal forma que um caminho de $(0,0)$ a $(n,m)$ em $G$ está 
associado a uma transformação \tranfbyopisym\ com \invnsobs\ de $s$ e $t$. 
Estabelecemos um sistema de pontuação para as arestas de $G$ de tal forma que, 
a pontuação de um caminho ótimo de $(0,0)$ a $(n,m)$ em $G$ é a pontuação de um 
alinhamento ótimo com \invnsobs\ de $s$ e $t$, ou seja, 
$\egweigp{(0,0)}{(n,m)}=\aligninvoptimumscoresym$.

\begin{definicao}[Função \egeopedinvsym{G}] Seja $G=(V,E,\egweigsym)$ um \gred\ 
estendido de $s$ e $t$. Dado um critério para escolher um alinhamento ótimo 
dentre todos os alinhamentos ótimos de quaisquer duas \seqs, podemos associar a 
cada aresta de $G$ uma \oped\ através da função $\egeopedinvsym{G}:E 
\rightarrow \opedset_1$ definida por:
\begin{itemize}
\item $\egeopedinvsym{G}(\eged{(i,j)})=(\opedsubsym{j}{t[j]}{s[i]})$,
\item $\egeopedinvsym{G}(\egeh{(i,j)})=(\opedinssym{j-1}{t[j]})$,
\item $\egeopedinvsym{G}(\egev{(i,j)})=(\opeddelsym{j+1}{s[i]})$ e
\item $\egeopedinvsym{G}(\egex{(i',j')}{(i,j)})= (\opedinvsym{j'+1}{j'+i-i'}) 
\opedconcat (\eginvert{j'}(\alignoped{A}{0})$, $ 
\eginvert{j'}(\alignoped{A}{1})$, $\ldots$, $ 
\eginvert{j'}$ $(\alignoped{A}{r-1}))$, onde $r$ é o comprimento do alinhamento 
ótimo $A$ de $\invert{s[i'+1 \Rng i]}$ e $t[j'+1 \Rng j]$ escolhido dentre os 
alinhamentos ótimos de $\invert{s[i'+1 \Rng i]}$ e $t[j'+1 \Rng j]$ sob o 
critério dado.
\end{itemize}
\end{definicao}

Repare que a função $\egeopedinvsym{G}$ não é injetora. Contudo, se as arestas 
$\egesym$ e $\egesym'$ são tais que $\egesym \neq \egesym'$ e 
$\egeopedinvsym{G}(\egesym)=\egeopedinvsym{G}(\egesym')$, então $\egesym$ e 
$\egesym'$ são arestas simples da mesma classe (diagonal, horizontal ou 
vertical) e chegam em vértices de uma mesma coluna de $G$. Por exemplo, para as 
arestas $\egesym=\egeh{(i,j)}$ e $\egesym'=\egeh{(i',j)}$ temos que 
$\egeopedinvsym{G}(\egesym)=\egeopedinvsym{G}(\egesym')=(\opedinssym{j-1}{t[j]})$.

A \seq\ $(\eginvert{j'}(\alignoped{A}{0}), \eginvert{j'}(\alignoped{A}{1}), 
\ldots, \eginvert{j'}(\alignoped{A}{r-1}))$, descrita acima, é a \seq\ de 
\opeds\ associadas a um alinhamento ótimo de $\invert{s[i+1 \Rng i']}$ e $t[j+1 
\Rng j']$ com apenas seus índices alterados pela função parcial $\eginvert{j'}$.

Dizemos que $\egepathset{(0,0)}{(n,m)}$ é o conjunto de todos os possíveis 
caminhos de $(0,0)$ a $(n,m)$ num \gred\ estendido de $s$ e $t$.

Seja $\opedset_1^*$ o conjunto com todas as possíveis concatenações de \seqs\ 
de elementos que pertencem ao conjunto $\opedset_1$. Por exemplo, se 
$\opedseqsym_1 \in \opedset_1$, $\opedseqsym_2 \in \opedset_1$ e $\opedseqsym_3 
\in \opedset_1$ então $\opedseqsym_1 \opedconcat \opedseqsym_2 \opedconcat 
\opedseqsym_3  \in \opedset_1^*$.

\begin{definicao}[Função $\aligninvfunc$] Seja a função 
$\aligninvfunc:\egepathset{(0,0)}{(n,m)} \rightarrow \opedset_1^*$ definida por 
$\aligninvfunc(P)=\egeopedinvsym{G}(\egesym_0) \opedconcat 
\egeopedinvsym{G}(\egesym_1)\opedconcat \ldots\opedconcat 
\egeopedinvsym{G}(\egesym_r)$, onde $P=(\egesym_0, \egesym_1, \ldots, 
\egesym_r)$ é um caminho de $(0,0)$ a $(n,m)$ em $G$.
\end{definicao}

Pode-se verificar que $\aligninvfunc(P)$, onde $P$ é um caminho de $(0,0)$ a 
$(n,m)$ em um \gred\ estendido de $s$ e $t$, é uma transformação com \invnsobs\ 
de $s$ e $t$.

Seja o \gred\ estendido $G=(V,E,\egweigsymi)$ de $s$ e $t$, onde a função 
$\egweigsymi:E \rightarrow \realset$ é definida por:
\begin{itemize}
  \item 
  $\egweigsymi(\eged{(i,j)})=\opedweigsym(\egeopedinvsym{G}(\eged{(i,j)}))$,
  \item 
  $\egweigsymi(\egeh{(i,j)})=\opedweigsym(\egeopedinvsym{G}(\egeh{(i,j)}))$,
  \item 
  $\egweigsymi(\egev{(i,j)})=\opedweigsym(\egeopedinvsym{G}(\egev{(i,j)}))$ e
  \item 
  $\egweigsymi(\egex{(i',j')}{(i,j)})=\opedweigsym(\egeopedinvsym{G}(\egex{(i',j')}{(i,j)}))$.
\end{itemize} 

Utilizando uma função equivalente a $\egweigsymi$ para atribuir pesos às 
arestas de um \gred\ estendido $G$ qualquer, temos que, a pontuação de um 
caminho ótimo $P$ de $(0,0)$ a $(n,m)$ em $G$ é igual à pontuação da 
transformação com \invnsobs\ $\aligninvfunc(P)$ de $s$ e $t$. Além disto temos 
que, a pontuação de um caminho ótimo de $(0,0)$ a $(n,m)$ em $G$ é igual à 
pontuação de um alinhamento ótimo com \invnsobs\ de $s$ e $t$. Ou seja, 
$$\egweigsymi(P)=\opedweigsym(\aligninvfunc(P))=\aligninvoptimumscoresym= 
\opedweigsym(\tranfoptimumbyopisym),$$ onde $P$ é um caminho ótimo de $(0,0)$ a 
$(n,m)$ em $G$.

% Associamos a cada coluna de um alinhamento com \invnsobs\ \aligninvsym\ de $s$ e
% $t$ uma aresta num \gred\ estendido $G$ de $s$ e $t$ através
% da função parcial $\alignedgeinvsym: \alignseti \times \natset \rightarrow E$,
% onde $E$ é o conjunto das possíveis arestas de um \gred\ estendido. A função
% parcial $\alignedgeinvsym$ é 

Em suma, se consideramos que a pontuação de um alinhamento com \invnsobs\ 
\aligninvsym\ de $s$ e $t$ é a pontuação da transformação com \invnsobs\ de $s$ 
e $t$ associada a \aligninvsym\ pela função parcial \alignopedinvsym, e a 
função de peso das arestas de um \gred\ estendido de $s$ e $t$ é uma função 
equivalente a $\egweigsymi$, então o peso de um caminho ótimo de $(0,0)$ a 
$(n,m)$ em $G$ é igual à pontuação de um alinhamento ótimo com \invnsobs\ de 
$s$ e $t$.

Portanto, podemos encontrar a pontuação de um alinhamento ótimo com \invnsobs\ 
de $s$ e $t$, encontrando o peso de um caminho ótimo de $(0,0)$ a $(n,m)$ num 
\gred\ estendido de $s$ e $t$. A partir de um caminho ótimo, podemos também 
encontrar um alinhamento ótimo.

No restante deste capítulo vamos desenvolver algoritmos para encontrar um 
caminho ótimo de $(0,0)$ a $(n,m)$ num \gred\ estendido $G$ de $s$ e $t$ ao 
invés de encontrar explicitamente o alinhamento ótimo com \invnsobs\ de $s$ e 
$t$. Muitas vezes estaremos interessados em obter apenas a pontuação de um 
caminho ótimo de $(0,0)$ a $(n,m)$ em $G$. Em geral, utilizamos matrizes de 
programação dinâmica e algumas outras estruturas de dados para obter as 
pontuações dos caminhos ótimos. Estas estruturas de dados permitem, a partir 
delas, construir um caminho ótimo de $(0,0)$ a $(n,m)$ em $G$ em tempo $O(n^2)$ 
e espaço $O(n^2)$. Os algoritmos que vamos descrever têm tempo de execução 
$O(n^3 \log n)$ e $O(n^3)$ e precisam de espaço $O(n^2)$ para obter o peso de 
um caminho ótimo de $(0,0)$ a $(n,m)$ num \gred\ estendido $G$ de $s$ e $t$, ou 
seja, a pontuação de um alinhamento ótimo com \invnsobs\ de $s$ e $t$. 
Portanto, um caminho ótimo de $(0,0)$ a $(n,m)$ em $G$, ou seja, um alinhamento 
ótimo com \invnsobs\ de $s$ e $t$, pode ser obtido em tempo $O(n^3 \log n)$ e 
$O(n^3)$ e utilizando espaço $O(n^2)$.


% Em outras palavras, se existe um caminho $P$ tal que 
% $\aligninvfunc(P)=\aligninvsym$ então a \seq\ de \opeds\ $\aligninvsym$ é um 
% alinhamento com \invnsobs\ de $s$ e $t$.  
% 
% \begin{proposicao}\label{prop:aligninv_align_path}
% Dado um caminho $P$ em um \gred\ estendido $G$ de $s$ e $t$ tal que 
% $\aligninvfunc(P)=\aligninvsym$ temos que, não existe outro caminho $P'$ em $G$ 
% tal que $\aligninvfunc(P')=\aligninvsym$.
% \end{proposicao}
% \begin{prova}
% Seja $P=(\egesym_0, \egesym_1, \ldots, \egesym_r)$ um caminho de $(0,0)$ a 
% $(n,m)$ num \gred\ estendido $G$ de $s$ e $t$ tal que 
% $\aligninvfunc(P)=\aligninvsym$. Suponha por absurdo que exista um outro 
% camimhno $P'=(\egesym'_0, \egesym'_1, \ldots, \egesym'_r)$ em $G$ tal que 
% $\aligninvfunc(P')=\aligninvsym'$ e $\aligninvsym=\aligninvsym'$. Seja $k$ tal 
% que, $0 \leq k \leq r$, $\egesym_k \neq \egesym'_k$ e $\egesym_l = \egesym'_l$ 
% para todo $l$ tal que $0 \leq l < k$. Como as arestas dos caminhos são iguais 
% até a $k$-ésima aresta de cada caminho então as arestas $\egesym_k$ e 
% $\egesym'_k$ partem do mesmo vértice e portanto, como são arestas diferentes, 
% não podem ser arestas simples do mesmo tipo (diagonal, vertical ou horizontal). 
% Logo, pela Observação~\ref{obs:aligninv_opinv_ninjetora}, 
% $\egeopedinvsym{G}(\egesym_k) \neq \egeopedinvsym{G}(\egesym'_k)$. Portanto 
% $\aligninvsym \neq \aligninvsym'$ e não pode existir outro caminho $P'$ em $G$ 
% tal que $\aligninvfunc(P')=\aligninvsym$.\cqd
% \end{prova}
% 
% Portanto, se $\aligninvfunc(P)=\aligninvsym$ então dizemos que $P$ é o
% caminho em $G$ correspondente ao alinhamento $\aligninvsym$ e vice-versa.
% 
% Repare que, como um alinhamento com \invnsobs\ $\aligninvsym$ de $s$ e $t$ 
% corresponde a um caminho num \gred\ estendido de $s$ e $t$ através da função 
% \aligninvfunc, temos que $\opedcompsym{\aligninvsym}(s)=t$.
% 
% Dado um \gred\ estendido $G=(V,E,\egweigsym)$ de $s$ e $t$, a pontuação de um 
% alinhamento com \invnsobs\ $\aligninvsym$ de $s$ e $t$ é o peso do caminho em 
% $G$ correspondente a $\aligninvsym$. Portanto a função \egweigsym\ que 
% estabelece os pesos das arestas de um \gred\ estendido de $s$ e $t$ determina o 
% sistema de pontuação para um alinhamento com \invnsobs\ de $s$ e $t$. Muitas vezes, 
% a função \egweigsym\ é definida por:
% \begin{itemize}
%   \item $\egweige{\eged{(i,j)}}=\opedweigsym(\opedsubsym{j}{t[j]}{s[i]})$,
%   \item $\egweige{\egeh{(i,j)}}=\opedweigsym(\opedinssym{j-1}{t[j]})$,
%   \item $\egweige{\egev{(i,j)}}=\opedweigsym(\opeddelsym{j+1}{s[i]})$ e
%   \item 
%   $\egweige{\egex{(i',j')}{(i,j)}}=\opedweigsym(\opedinvsym{j'+1}{j'+i-i'})+$ 
%   a pontuação de um alinhamento ótimo de $\invert{s[i'+1 \Rng i]}$ e $t[j'+1 
%   \Rng j]$.
% \end{itemize} 
% 
% Utilizando esta definição para a função \egweigsym, temos que se 
% $\opedweigsym(\eginvert{j'}(\opedsym))=\opedweigsym(\opedsym)$ e a pontuação de 
% um alinhamento $A$ de $\invert{s[i'+1 \Rng i]}$ e $t[j'+1 \Rng j]$ é a 
% somatória das pontuações de cada \oped\ associada a cada coluna de $A$, então a 
% pontuação de um alinhamento com \invnsobs\ $\aligninvsym$ de $s$ e $t$ é igual 
% a $\opedweigsym(\opedcompsym{\aligninvsym})$.
% 
% Um alinhamento com \invnsobs\ de $s$ e $t$ é \emph{ótimo} se ele tem pontuação máxima
% dentre todos os possíveis alinhamentos com \invnsobs\ de $s$ e $t$.
% 
% Portanto o problema de encontrar um alinhamento ótimo com \invnsobs\ de $s$ e
% $t$ é o mesmo que encontrar um caminho ótimo num \gred\ estendido de $s$ e $t$.
% 
% A seguir, vamos definir uma nova \oped\ chamada \emph{\oped\ de \inv\ 
% composta}. Esta \oped\ é simplesmente uma \oped\ composta por outras \opeds\ 
% elementares, de tal forma que a primeira \oped\ é uma \inv\ e as outras são 
% \opeds\ elementares. Ela é definida apenas para facilitar a leitura do texto e 
% não está associada a nenhuma mutação, mas a um conjunto de mutações que estão 
% associados à \seq\ de \opeds\ elementares que a compõem.
% 
% \begin{definicao}[\Oped\ de \inv\ composta]
% 
% \end{definicao}
%   {Inversão}: Dados $i$, $i'$ e $x$ tais que $1\leq i \leq i'+1$ e $x \in \alfabeto^*$,
%   dizemos que a função $\opedinvcompsym{i}{i'}{x}: \alfabeto^* \rightarrow \alfabeto^*$ definida por 
%   $\opedinvcompsym{i}{i'}{x}(s)=s[1\Rng i-1] x s[i'+1\Rng n]$, 
%   para $i' \leq n$, é uma \emph{\oped\ de inversão}, ou mais especificamente, a 
%   \emph{\oped\ de inversão do trecho de $i$ a $i'$}. Por exemplo, 
%   $\opedinvsym{4}{7}(AAC\mathbf{GCCT}TCG)=AAC\mathbf{AGGC}TCG$. Repare que 
%   $\invert{GCCT}=AGGC$, pois consideramos que a operação de inversão mapeia um 
%   trecho no seu reverso complementar. Diremos que $i$ e $i'$ são os índices 
%   desta \oped. Chamaremos de \emph{classe de \opeds\ de inversão} o conjunto 
%   com todas as possíveis \opeds\ de inversão. Vamos considerar que uma \oped\ 
%   de inversão corresponde a uma mutação de inversão.
%   
% 
% \begin{definicao}[Alinhamento com \invnsobs\ de $s$ e $t$]
% Um alinhamento com \invnsobs\ de $s$ e $t$ é uma \seq\ de \opeds\ que pode ser 
% associada a um caminho $P$ de $(0,0)$ a $(n,m)$ num \gred\ estendido de $s$ e
% $t$ da seguinte forma:
% \begin{itemize}
%   \item a cada aresta $\eged{(i,j)}$ $P$ é associada a \oped\ 
%   $\opedsubsym{j}{t[j]}{s[i]}$,
%   \item a cada aresta $\egeh{(i,j)}$ é associada a \oped\ 
%   $\opedinssym{j-1}{t[j]}$,
%   \item a cada aresta $\egev{(i,j)}$ é associada a \oped\ 
%   $\opeddelsym{j+1}{s[i]}$ e
%   \item a cada aresta $\egex{(i,j)}{(i',j')}$ é associada a \oped\ de 
%   \inv\ $\opedinvsym{j+1}{j+i'-i}$ mais a pontuação de um alinhamento 
%   ótimo de $\invert{s[i+1 \Rng i']}$ e $t[j+1 \Rng j']$.
% \end{itemize}
% \end{definicao}
% 
% Dadas duas \seqs\ $s=s[1\Rng n]$ e $t=t[1\Rng m]$ e uma \seq\ de \opeds\ 
% $\opedseqsym=(\opedsym_0, \opedsym_1, \ldots, \opedsym_r)$ tal que 
% $\opedcompsym{\opedseqsym}(s)=t$ e $\opedsym_k \in \{\opedinssym{i'}{t[j]}, 
% \opeddelsym{i'}{s[i]}, \opedsubsym{i'}{t[j]}{s[i]}, \opedinvsym{i'}{i''}\tq i' 
% \in \natset, i'' \in \natset, 1 \leq i \leq n \textrm{ e } 1 \leq j \leq m\}$, 
% para todo $k$ tal que $0 \leq k \leq r$, dizemos que
% 
% Sejam $s=s[1\Rng n]$ e $t=t[1\Rng m]$ as seqüências a serem alinhadas.
% 
% \begin{definicao}[Alinhamento com \invnsobs\ de $s$ e $t$] Dadas duas \seqs\ 
% $s$ e $t$, dizemos que um alinhamento com \invnsobs\ de $s$ e $t$ é uma 
% \seq\ de \opeds\ $\opedseqsym=(\opedsym_0, \opedsym_1, \ldots, \opedsym_r)$ tal 
% que:
% \begin{itemize}
%   \item $\opedcompsym{\opedseqsym}(s)=t$,
%   \item $\opedsym_k$ é uma \oped\ de inserção, remoção, substituição ou \inv, 
%   para todo $k$ tal que $0 \leq k \leq r$,
%   \item se $\opedsym_k$ é uma \oped\ de \inv\ então $\opedsym_{k+1}$ também é 
%   uma \oped\ de \inv, para todo $k$ tal que $0 \leq k \leq r-1$ e
%   \item se $\opedinvsym{i_1}{i_2} \ in \opedseqsym$ e $\opedinvsym{i_3}{i_4} 
%   \in \opedseqsym$ então $i_2 < i_3$ ou $i_4 < i_1$.
% \end{itemize}
% \end{definicao}
% 


% Sejam $\widehat G=(V,\widehat E,\widehat \omega)$ o grafo de edição estendido 
% de $s$ e $t$ e $\overline{G}=(V,\overline E,\overline{\omega})$ o grafo de 
% edição de $\invert{s}$ e $t$. Em $\overline{G}$, os pesos $\overline 
% \egweige{\egeh{(i,j)}}$, $\overline \omega(e_D^{i,j})$ e $\overline 
% \omega(e_V^{i,j})$ correspondem, respectivamente, às pontuações das operações 
% de inserção de $t[j]$, substituição de $\overline{s[i]}$ por $t[j]$ e remoção 
% de $\overline{s[i]}$.

% Seja a matriz $B_{(n+1) \times (m+1)}$ tal que $B[i,j]$ é a pontuação de um
% alinhamento ótimo considerando inversões não
%  sobrepostas entre $s[1\Rng i]$ e $t[1\Rng j]$ para quaisquer $i$ e $j$ tais que $0 
% \leq i \leq n$, $0 \leq j \leq m$, ou seja, $B[i,j]$ é o peso de um caminho 
% ótimo entre $(0,0)$ e $(i,j)$ em $\widehat G$.
% 
% 
\section{Caminhos ótimos em um \gred}
\label{sec:jeanette}

Seja $G=(V,E,\egweigsym)$ o \gred\ de $s$ e $t$. Dados $i$ e $i'$, tais que $0 
\leq i'\leq i \leq n$, queremos calcular o valor de $\egweigp{(i',j')}{(i,j)}$, 
ou seja, o peso de um caminho ótimo de $(i',j')$ a $(i,j)$ em $G$, para todo 
$j$ e $j'$ tais que $0 \leq j' \leq j \leq m$.

Dados $i$ e $i'$, tais que $0 \leq i'\leq i \leq n$, diremos que $i-i'=n'$. Um 
algoritmo simples que calcula os valores de $\egweigp{(i',j')}{(i,j)}$, para 
todo $j$ e $j'$ tais que $0 \leq j' \leq j \leq m$, é o seguinte: para cada 
$j'$ o algoritmo calcula para todo $j$, tal que $j' \leq j \leq m$, o valor de 
$\egweigp{(i',j')}{(i,j)}$. Com programação dinâmica simples é possível 
calcular, para um dado $j'$, o valor de todos os $\egweigp{(i',j')}{(i,j)}$ em 
tempo $O(mn')$. Portanto, para calcular $\egweigp{(i',j')}{(i,j)}$ para todos os $j'$ este algoritmo
simples leva tempo $O(m^2n')$.
	
Aggarwal e Park \cite{AggPar} e Apostolico et al.\ \cite{108168} desenvolveram 
um algoritmo recursivo que, dados um \gred, $i$ e $i'$, tais que $0 \leq i'\leq 
i \leq n$, calcula todos os valores de $\egweigp{(i',j')}{(i,j)}$ em tempo 
$O(mn'\log m)$.

%TODO:Obter estes artigos. Verificar se não dá para fazer incremental.
	
Jeanette Schmidt \cite{MR1621993} desenvolveu um algoritmo que, dados um \gred, 
$i$ e $i'$, tais que $0 \leq i'\leq i \leq n$, constrói uma estrutura de 
árvores que armazenam todos os valores de $\egweigp{(i',j')}{(i,j)}$. A 
construção desta estrutura de árvores leva tempo $O(mn'\log m)$ e o tempo de 
acesso ao valor de $\egweigp{(i',j')}{(i,j)}$ é $O(\log m)$. A vantagem do 
algoritmo proposto por Jeanette Schmidt, em relação aos outros algoritmos 
mencionados anteriormente, é o fato dele ser incremental. Para construir a 
estrutura de árvores com os valores de $\egweigp{(i',j')}{(i,j)}$ o algoritmo 
utiliza a estrutura de árvores com os valores de $\egweigp{(i',j')}{(i-1,j)}$. 
Dada a estrutura de árvores com os valores de $\egweigp{(i',j')}{(i-1,j)}$ o 
algoritmo leva tempo $O(m \log m)$ para construir a estrutura de árvores com os 
valores de $\egweigp{(i',j')}{(i,j)}$.

De agora em diante nesta seção, veremos detalhes bastante técnicos que se 
encontram essencialmente em \cite{MR1621993} e que descrevem como construir 
essa estrutura de árvores.
	 
\begin{lema}
Seja $G=(V,E,\egweigsym)$ um \gred\ de $s$ e $t$. Sejam $i$ e $i'$ tais que $0 
\leq i'\leq i \leq n$. Seja $\matw{G}{i'}{i}$ a matriz $(m+1) \times (m+1)$ tal que 
$\matw{G}{i'}{i}[j', j]=\egweigp{(i',j')}{(i,j)}$, para todo $j$ e $j'$ tais 
que $0 \leq j' \leq j \leq m$. A matriz $\matw{G}{i'}{i}$ é uma matriz de monge 
inversa triangular superior.
\label{lemaWMonge}
\end{lema}

\begin{prova}
Sejam  $(i',j_1)$, $(i',j_2)$, $(i,j_3)$ e $(i,j_4)$ vértices de $G$, tais que 
$0 \leq j_1 < j_2 \leq j_3 < j_4 \leq m$. Como é ilustrado na figura 
\ref{fig:Wmonge}, existe um vértice $v$ onde os caminhos ótimos de $(i',j_2)$ a 
$(i,j_3)$ e de $(i',j_1)$ a  $(i,j_4)$ se cruzam. Sejam 
$a=\egweigp{(i',j_1)}{(i,j_3)}$, $b=\egweigp{(i',j_2)}{(i,j_4)}$, 
$c=\egweigp{(i',j_1)}{v}$, $d=\egweigp{v}{(i,j_4)}$, $e=\egweigp{(i',j_2)}{v}$ 
e $f=\egweigp{v}{(i,j_3)}$. Suponha, por absurdo, que 
$\matw{G}{i'}{i}[j_1,j_3]+\matw{G}{i'}{i}[j_2,j_4] < \matw{G}{i'}{i}[j_1,j_4]+\matw{G}{i'}{i}[j_2,j_3]$. 
Logo teríamos:
\begin{equation*}
\begin{split}
(c+d)+(e+f)&> a+b \\
c+d+e+f-a -b &> 0  \\
(c+f-a)+(d+e-b) &> 0 \\
c+f-a & > 0 \textrm{ ou } (d+e-b) > 0 \\
c+f & > a \textrm{ ou } d+e > b \\
\end{split}
\end{equation*}

Porém se $c+f > a $ (ou $ d+e > b$) teríamos um caminho de $(i',j_1)$ a
$(i,j_3)$ (ou de $(i',j_2)$ a $(i,j_4)$) com peso $c+f > a $ (ou $d+e > b$).
Isto é impossível pois $a$ e $b$ são caminhos ótimos de $(i',j_1)$ a
$(i,j_3)$ e de $(i',j_2)$ a $(i,j_4)$ respectivamente.

Portanto $\matw{G}{i'}{i}[j_1,j_3]+\matw{G}{i'}{i}[j_2,j_4] \geq 
\matw{G}{i'}{i}[j_1,j_4]+\matw{G}{i'}{i}[j_2,j_3]$ para $0 \leq j_1 < j_2 \leq j_3 < j_4 \leq
m$. 

Além disso $\egweigp{(i',j')}{(i,j)}=-\infty$ se $0 \leq j < j' \leq m$.

Portanto $\matw{G}{i'}{i}$ é uma matriz de monge inversa triangular superior.\cqd
\end{prova}

Chamamos a matriz $\matw{G}{i'}{i}$ de matriz de pesos de 
caminhos ótimos em $G$ entre as linhas $i'$ e $i$.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{monge}
% \end{center}
\caption[$\matw{G}{i'}{i}$ é uma matriz de monge inversa]{Ilustração da prova que 
$\matw{G}{i'}{i}$ é uma matriz de monge inversa}
 \label{fig:Wmonge}
\end{figure}
	
Como conseqüência do Lema~\ref{lemaWMonge} pode-se calcular os máximos das 
colunas de $\matw{G}{i'}{i}$ em tempo linear, utilizando o 
Algoritmo~\ref{alg:maxTotMonotonica}.

\begin{observacao}
O valor de $\egweigp{(i',j')}{(i,j)}$ pode ser obtido com a seguinte recorrência:
\[\egweigp{(i',j')}{(i,j)}=\left\{ \begin{array} {ll}
-\infty&\textrm{,se }j'>j\\
0&\begin{array} {l}\textrm{,se } i'=i\\ \textrm{ e }j'=j \end{array}\\
\egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}&\begin{array} {l}\textrm{,se
}i'=i\\ \textrm{ e }j'<j\end{array} \\
\egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}&\begin{array} {l}\textrm{,se
}i'<i \\ \textrm{ e }j'=j \end{array}\\ \max \left(\begin{array} {l}
\egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}\\
\egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}\\
\egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}\\
\end{array}\right)&\begin{array} {l} \textrm{,se }i'<i\\ \textrm{ e }j'<j \end{array}
\end{array}\right. \]
\label{obs:W}
\end{observacao} 

\begin{definicao}[Funções $\hdifsym{G}$, $\vdifsym{G}$ e 
$\ddifsym{G}$] Dado um \gred\ $G=(V,E,\egweigsym)$ de $s$ e $t$, definimos as 
funções $\hdifsym{G}:V \times V \rightarrow \realset\cup 
\{-\infty\}$, $\vdifsym{G}:V \times V \rightarrow \realset\cup \{-\infty\}$ 
e $\ddifsym{G}:V \times V \rightarrow \realset\cup \{-\infty\}$ da seguinte 
forma:
\begin{itemize}
  \item $\hdiffunc{G}{i'}{j'}{i}{j} = \egweigp{(i',j')}{(i,j)} 
  -\egweigp{(i',j')}{(i,j-1)}$, se $j' < j$ e $i' \leq i$
  \item $\vdiffunc{G}{i'}{j'}{i}{j} = \egweigp{(i',j')}{(i-1,j)} 
  -\egweigp{(i',j')}{(i,j)}$, se $j' \leq j$ e $i' < i$
  \item $\ddiffunc{G}{i'}{j'}{i}{j} = \egweigp{(i',j')}{(i-1,j)} 
  -\egweigp{(i',j')}{(i,j-1)}$, se $j' < j$ e $i' < i$
  \item $\hdiffunc{G}{i'}{j'}{i}{j} = -\infty$, se $j' \geq j$ ou $i' > i$
  \item $\vdiffunc{G}{i'}{j'}{i}{j} = -\infty$, se $j' > j$ ou $i' \geq i$
  \item $\ddiffunc{G}{i'}{j'}{i}{j} = -\infty$, se $j' \geq j$ ou $i' \geq i$
\end{itemize}
\label{def:hdiff}
\end{definicao}

A Figura~\ref{fig:dif} ilustra os caminhos ótimos que são utilizados para obter
as diferenças $\hdiffunc{G}{i'}{j'}{i}{j}$, $\vdiffunc{G}{i'}{j'}{i}{j}$ e
$\ddiffunc{G}{i'}{j'}{i}{j}$ quando $j' < j$ e $i' < i$.

\begin{figure}[htbp] 
\centering 
\subfigure[] 
{\label{fig:dif:hdif} 
\includegraphics[scale=1.4]{hdif}} 
\subfigure[] 
{\label{fig:dif:vdif} 
\includegraphics[scale=1.4]{vdif}}
\subfigure[] 
{\label{fig:dif:ddif} 
\includegraphics[scale=1.4]{ddif}} 
\subfigure[] 
{\label{fig:dif:setas} 
\includegraphics[scale=0.9]{difsetas}} 

\caption[$\hdifsym{G}$, $\vdifsym{G}$ e $\ddifsym{G}$]{Ilustração dos caminhos 
ótimos utilizados nas fun\-ções $\hdifsym{G}$, $\vdifsym{G}$ e $\ddifsym{G}$ \\
\ref{fig:dif:hdif} $\hdiffunc{G}{i'}{j'}{i}{j} = \egweigp{(i',j')}{(i,j)} 
-\egweigp{(i',j')}{(i,j-1)}$, \\ \ref{fig:dif:vdif} $\vdiffunc{G}{i'}{j'}{i}{j} = 
\egweigp{(i',j')}{(i-1,j)} -\egweigp{(i',j')}{(i,j)}$, \\ \ref{fig:dif:ddif} 
$\ddiffunc{G}{i'}{j'}{i}{j} = \egweigp{(i',j')}{(i-1,j)} 
-\egweigp{(i',j')}{(i,j-1)}$ e \\ \ref{fig:dif:setas} Esquema para representar
as diferenças. O peso do caminho até o vértice da origem da seta é subtraído do
peso do caminho até o vértice apontado pela seta.}
 \label{fig:dif}
\end{figure}

A seguir vamos definir vetores que armazenam os valores das funções
$\hdifsym{G}$, $\vdifsym{G}$ e $\ddifsym{G}$ para $i'$ e $(i,j)$ fixos.

\begin{definicao}[Vetores $\hdifvec{G}{i'}{i}{j}$, $\vdifvec{G}{i'}{i}{j}$ e 
$\ddifvec{G}{i'}{i}{j}$] Sejam $G$ um \gred\ de $s$ e $t$, $(i,j)$ um vértice 
de $G$ e $i'$ um índice de $s$.
\begin{itemize}
\item Se $i' \leq i$ então existe o vetor $\hdifvec{G}{i'}{i}{j}$ de 
comprimento $j$ definido por 
$\hdifvec{G}{i'}{i}{j}[j']=\hdiffunc{G}{i'}{j'}{i}{j}$, para todo $j'$ tal que 
$0 \leq j'< j$.
\item Se $i' < i$ então existe o vetor $\vdifvec{G}{i'}{i}{j}$ de 
comprimento $j+1$ definido por 
$\vdifvec{G}{i'}{i}{j}[j']=\vdiffunc{G}{i'}{j'}{i}{j}$ , para todo $j'$ tal que 
$0 \leq j' \leq j$.
\item Se $i' < i$ então existe o vetor $\ddifvec{G}{i'}{i}{j}$ de 
comprimento $j$ definido por $\ddifvec{G}{i'}{i}{j}[j'] = 
\ddiffunc{G}{i'}{j'}{i}{j}$, para todo $j'$ tal que $0 \leq j'< j$.
\end{itemize}
\label{def:difvec}
\end{definicao}

\begin{proposicao}
Os vetores $\hdifvec{G}{i'}{i}{j}$, $\vdifvec{G}{i'}{i}{j}$ e 
$\ddifvec{G}{i'}{i}{j}$ são não decrescentes.
\label{prop:difcrescentes}
\end{proposicao}

\begin{prova}
Sejam $G$ um \gred\ de $s$ e $t$, $(i,j)$ um vértice de $G$ e $i'$ o índice de 
$s$ tal que $i' \leq i$. Como a matriz $\matw{G}{i'}{i}$, definida no 
Lema~\ref{lemaWMonge}, é uma matriz de monge inversa, temos que
\begin{equation*}
\begin{split}
\matw{G}{i'}{i}[j'-1,j-1] + \matw{G}{i'}{i}[j',j] \geq & \matw{G}{i'}{i}[j',j-1] + \matw{G}{i'}{i}[j'-1,j]\\
\matw{G}{i'}{i}[j',j] -\matw{G}{i'}{i}[j',j-1] \geq & \matw{G}{i'}{i}[j'-1,j] - \matw{G}{i'}{i}[j'-1,j-1]\\
\egweigp{(i',j')}{(i,j)}-\egweigp{(i',j')}{(i,j-1)} \geq &
\egweigp{(i',j'-1)}{(i,j)}-\\& \egweigp{(i',j'-1)}{(i,j-1)}\\
\hdiffunc{G}{i'}{j'}{i}{j} \geq & \hdiffunc{G}{i'}{j'-1}{i}{j}\\
\hdifvec{G}{i'}{i}{j}[j'] \geq & \hdifvec{G}{i'}{i}{j}[j'-1]
\end{split}
\end{equation*}

Portanto $\hdifvec{G}{i'}{i}{j}$ é não decrescente. 

De forma similar é possível verificar que $\vdifvec{G}{i'}{i}{j}$ é não 
decrescente. Como 
$\ddifvec{G}{i'}{i}{j}[j']=\hdifvec{G}{i'}{i}{j}[j']+\ddifvec{G}{i'}{i}{j}[j']$ 
então $\ddifvec{G}{i'}{i}{j}$ também é não decrescente.\cqd
\end{prova}

\begin{proposicao}
Dados um \gred\ $G$ de $s$ e $t$ e dois vértices, $(i',j')$ e $(i,j)$, de $G$ 
tais que $i'<i$ e $j'<j$, então podemos dizer que
\begin{enumerate}
  \item $\egweigp{(i',j')}{(i,j)}=\egweigp{(i',j')}{(i,j-1)}+ \egweige{\egeh{(i,j)}}$ se e somente se
  \begin{enumerate}
      \item $\vdiffunc{G}{i'}{j'}{i}{j-1} \leq \egweige{\egeh{(i,j)}}-\egweige{\eged{(i,j)}}$ e
      \item $\ddiffunc{G}{i'}{j'}{i}{j} \leq \egweige{\egeh{(i,j)}}-\egweige{\egev{(i,j)}}$
  \end{enumerate}
  \item $\egweigp{(i',j')}{(i,j)}=\egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}$ se e somente se
  \begin{enumerate}
      \item $\hdiffunc{G}{i'}{j'}{i-1}{j} \leq \egweige{\eged{(i,j)}}-\egweige{\egev{(i,j)}}$ e
      \item $\vdiffunc{G}{i'}{j'}{i}{j-1} \geq \egweige{\egeh{(i,j)}}-\egweige{\eged{(i,j)}}$
  \end{enumerate}
  \item $\egweigp{(i',j')}{(i,j)}=\egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}$ se e somente se
  \begin{enumerate}
      \item $\hdiffunc{G}{i'}{j'}{i-1}{j} \geq \egweige{\eged{(i,j)}}-\egweige{\egev{(i,j)}}$ e
      \item $\ddiffunc{G}{i'}{j'}{i}{j} \geq \egweige{\egeh{(i,j)}}-\egweige{\egev{(i,j)}}$
  \end{enumerate}
\end{enumerate}
\label{prop:BporDif}
\end{proposicao}

\begin{prova}
Utilizando as definições das funções $\hdifsym{G}$, $\ddifsym{G}$ e 
$\vdifsym{G}$ e a Observação~\ref{obs:W} temos que:
\begin{enumerate}
  \item 
  $\egweigp{(i',j')}{(i,j)}=\egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}$ 
  se e somente se \\ $\egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}} \geq 
  \egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}$ e \\
  $\egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}} \geq 
  \egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}$.
      
      Contudo, temos que
%   \begin{enumerate}
%       \item 
      \begin{equation*}
      \begin{split}
      &\egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}} \geq 
      \egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}} \sse \\
      &\egweigp{(i',j')}{(i,j-1)}-\egweigp{(i',j')}{(i-1,j-1)} \geq 
      \egweige{\eged{(i,j)}} - \egweige{\egeh{(i,j)}} \sse \\
      &-\vdiffunc{G}{i'}{j'}{i}{j-1} \geq \egweige{\eged{(i,j)}} - 
      \egweige{\egeh{(i,j)}} \sse \\
      &\vdiffunc{G}{i'}{j'}{i}{j-1} \leq
      \egweige{\egeh{(i,j)}}-\egweige{\eged{(i,j)}}
      \end{split}
      \end{equation*}
      e
%       \item
      \begin{equation*}
      \begin{split}
      &\egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}} \geq 
      \egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}\sse \\
      &\egweigp{(i',j')}{(i,j-1)}-\egweigp{(i',j')}{(i-1,j)} \geq 
      \egweige{\egev{(i,j)}} - \egweige{\egeh{(i,j)}} \sse \\
      &-\ddiffunc{G}{i'}{j'}{i}{j} \geq \egweige{\egev{(i,j)}} - 
      \egweige{\egeh{(i,j)}} \sse \\
      &\ddiffunc{G}{i'}{j'}{i}{j} \leq 
      \egweige{\egeh{(i,j)}}-\egweige{\egev{(i,j)}}.
      \end{split}
      \end{equation*}     
%   \end{enumerate}
          
  \item 
  $\egweigp{(i',j')}{(i,j)}=\egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}$ se 
  e somente se \\
  $\egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}} \geq 
  \egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}$ e \\
  $\egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}} \geq 
  \egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}$.
       
      Contudo, temos que
%   \begin{enumerate}
%       \item 
      \begin{equation*}
      \begin{split}
      &\egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}} \geq 
      \egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}  \sse \\
      &\egweigp{(i',j')}{(i-1,j-1)}-\egweigp{(i',j')}{(i-1,j)} \geq 
      \egweige{\egev{(i,j)}} - \egweige{\eged{(i,j)}} \sse \\
      &-\hdiffunc{G}{i'}{j'}{i-1}{j} \geq \egweige{\egev{(i,j)}} - 
      \egweige{\eged{(i,j)}} \sse \\
      &\hdiffunc{G}{i'}{j'}{i-1}{j} \leq
      \egweige{\eged{(i,j)}}-\egweige{\egev{(i,j)}}
      \end{split}
      \end{equation*}
      e
%       \item
      \begin{equation*}
      \begin{split}
      &\egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}} \geq 
      \egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}} \sse \\
      &\egweigp{(i',j')}{(i-1,j-1)}-\egweigp{(i',j')}{(i,j-1)} \geq 
      \egweige{\egeh{(i,j)}} - \egweige{\eged{(i,j)}} \sse \\
      &\vdiffunc{G}{i'}{j'}{i}{j-1} \geq \egweige{\egeh{(i,j)}} -
      \egweige{\eged{(i,j)}}.
      \end{split}
      \end{equation*}
%   \end{enumerate}

  \item 
  $\egweigp{(i',j')}{(i,j)}=\egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}}$ 
  se e somente se \\
  $\egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}} \geq 
  \egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}$ e \\
  $\egweigp{(i',j')}{(i-1,j)}+q\egweige{\egev{(i,j)}} \geq 
  \egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}$.
      
      Contudo, temos que
%   \begin{enumerate}
%       \item 
      \begin{equation*}
      \begin{split}
      &\egweigp{(i',j')}{(i-1,j)}+\egweige{\egev{(i,j)}} \geq 
      \egweigp{(i',j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}} \sse \\
      &\egweigp{(i',j')}{(i-1,j)}-\egweigp{(i',j')}{(i-1,j-1)} \geq 
      \egweige{\eged{(i,j)}} - \egweige{\egev{(i,j)}}  \sse \\
      &\hdiffunc{G}{i'}{j'}{i-1}{j} \geq
      \egweige{\eged{(i,j)}} - \egweige{\egev{(i,j)}}
      \end{split}
      \end{equation*}
	  e
%       \item
	  \begin{equation*}
	  \begin{split}
      &\egweigp{(i',j')}{(i-1,j)}+q\egweige{\egev{(i,j)}} \geq 
      \egweigp{(i',j')}{(i,j-1)}+\egweige{\egeh{(i,j)}} \sse \\
      &\egweigp{(i',j')}{(i-1,j)}-\egweigp{(i',j')}{(i,j-1)} \geq 
      \egweige{\egeh{(i,j)}} - \egweige{\egev{(i,j)}} \sse \\
      &\ddiffunc{G}{i'}{j'}{i}{j} \geq \egweige{\egeh{(i,j)}} - 
      \egweige{\egev{(i,j)}}. \cqd
	  \end{split}
	  \end{equation*}
%   \end{enumerate}
 
\end{enumerate}
\end{prova}

A Proposição~\ref{prop:BporDif} dá condições para provar o Lema \ref{lemaj1j2}, 
que por sua vez é fundamental na construção eficiente das estruturas de árvores 
descritas por Jeanette Schmidt em~\cite{MR1621993}.


\begin{lema}Dados um \gred\ $G$ de $s$ e $t$, um vértice $(i,j)$ de $G$ e a 
linha $i'$ de $G$ tal que $i' \leq i$, então existem $j_1$ e $j_2$ tais que $0 
\leq j_1 \leq j_2 \leq j$ e \[\egweigp{(i', j')}{(i,j)}=\left\{ \begin{array} 
{ll} \egweigp{(i', j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}& \forall\ j' \tq 0 \leq 
j' < j_1\\
\egweigp{(i', j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}& \forall\ j' \tq j_1 \leq 
j' < j_2\\
\egweigp{(i', j')}{(i-1,j)}+\egweige{\egev{(i,j)}}& \forall\ j' \tq j_2 \leq j' 
\leq j\\ \end{array}\right. \]
\label{lemaj1j2}
\end{lema}	
 
\begin{prova} 
Sejam um \gred\ $G$ de $s$ e $t$, um vértice $(i,j)$ de $G$ e a linha $i'$ de 
$G$ tal que $i' \leq i$. Estabelecidos os valores de $j_1$ e $j_2$, tais que $0 
\leq j_1 \leq j_2 \leq j$, vamos provar que:
\begin{enumerate}
  \item $\egweigp{(i', j')}{(i,j)}=\egweigp{(i',j')}{(i,j-1)} 
  +\egweige{\egeh{(i,j)}}$ para todo $j'$ tal que $0 \leq j' < j_1$.
  \label{lema:j1j2:casoh}
  \item $\egweigp{(i', j')}{(i,j)}=\egweigp{(i', j')}{(i-1,j-1)} 
  +\egweige{\eged{(i,j)}}$ para todo $j'$ tal que $j_1 \leq j' < 
  j_2$.\label{lema:j1j2:casod}
  \item $\egweigp{(i', j')}{(i,j)}=\egweigp{(i', j')}{(i-1,j)} 
  +\egweige{\egev{(i,j)}}$ para todo $j'$ tal que $j_2 \leq j' \leq 
  j$.\label{lema:j1j2:casov}
\end{enumerate}

Seja $j_1$ o menor $j'$ tal que \[\egweigp{(i', j')}{(i,j)} \neq \egweigp{(i', 
j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}.\] Repare que, pelo menos para $j'=j$ a 
desigualdade acima é satisfeita, pois $\egweigp{(i', j)}{(i,j-1)}=-\infty$.

Portanto, para todo $j'$, tal que $0 \leq j' < j_1$, \[\egweigp{(i', 
j')}{(i,j)} = \egweigp{(i', j')}{(i,j-1)}+\egweige{\egeh{(i,j)}},\] e está
provado que a afirmação~\ref{lema:j1j2:casoh} está correta.

Seja $j_2$ o menor $j'$ tal que $j_1 \leq j_2 \leq j$ e \[\egweigp{(i', 
j')}{(i,j)} = \egweigp{(i', j')}{(i-1,j)}+\egweige{\egev{(i,j)}}.\] Pela 
Proposição~\ref{prop:BporDif} temos que: \begin{enumerate}[\tabenum a)]
\item $\hdiffunc{G}{i'}{j_2}{i-1}{j} \geq 
\egweige{\eged{(i,j)}}-\egweige{\egev{(i,j)}}$ e
\item $\ddiffunc{G}{i'}{j_2}{i}{j} \geq 
\egweige{\egeh{(i,j)}}-\egweige{\egev{(i,j)}}$.
  \end{enumerate}
Pela Proposição~\ref{prop:difcrescentes} os vetores $\hdifvec{G}{i'}{i-1}{j}$ e 
$\ddifvec{G}{i'}{i}{j}$ são não decrescentes. Logo, para todo $j'$ tal que $j_2 
\leq j' < j$ as desigualdades se mantém, ou seja: \begin{enumerate}[\tabenum a)]
\item $\hdiffunc{G}{i'}{j'}{i-1}{j} \geq 
\egweige{\eged{(i,j)}}-\egweige{\egev{(i,j)}}$ e
\item $\ddiffunc{G}{i'}{j'}{i}{j} \geq 
\egweige{\egeh{(i,j)}}-\egweige{\egev{(i,j)}}$.
  \end{enumerate}
Portanto, pela Proposição~\ref{prop:BporDif}, para todo $j'$ tal que $j_2 \leq 
j' < j$ temos que \[\egweigp{(i', j')}{(i,j)} = \egweigp{(i', 
j')}{(i-1,j)}+\egweige{\egev{(i,j)}}.\] Para o caso onde $j'=j$ temos que, pela 
Observação~\ref{obs:W}, \[\egweigp{(i', j')}{(i,j)} = \egweigp{(i', 
j')}{(i-1,j)}+\egweige{\egev{(i,j)}}.\] Portanto, para todo $j'$ tal que $j_2 
\leq j' \leq j$ temos que \[\egweigp{(i', j')}{(i,j)} = \egweigp{(i', 
j')}{(i-1,j)}+\egweige{\egev{(i,j)}},\] e  está
provado que a afirmação~\ref{lema:j1j2:casov} 
está correta.

Se $j_1= j_2$ então a afirmação~\ref{lema:j1j2:casod} está
correta. Vamos supor que $j_1<j_2$. 
Portanto, de acordo com a escolha de $j_2$, para todo $j'$ tal que $0 \leq j'<
j_2$, temos que \[\egweigp{(i', 
j')}{(i,j)} \neq \egweigp{(i', j')}{(i-1,j)}+\egweige{\egev{(i,j)}}.\]

De acordo com a escolha de $j_1$ e pela Proposição~\ref{prop:BporDif} temos 
que: \begin{enumerate}[\tabenum a)]
      \item $\vdiffunc{G}{i'}{j_1}{i}{j-1} > \egweige{\egeh{(i,j)}}-\egweige{\eged{(i,j)}}$ ou
      \item $\ddiffunc{G}{i'}{j_1}{i}{j} > \egweige{\egeh{(i,j)}}-\egweige{\egev{(i,j)}}$
\end{enumerate}

Como os dois vetores $\vdifvec{G}{i'}{i}{j-1}$ e $\ddifvec{G}{i'}{i}{j}$ são 
não decrescentes então, independente de qual das duas desigualdades seja 
verdadeira, temos que para todo $j'$, tal que $j_1 \leq j' < j$, 
\[\egweigp{(i', j')}{(i,j)} \neq \egweigp{(i', 
j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}.\]

Portanto, para todo $j'$ tal que $j_1 \leq j' < j_2$ temos que \[\egweigp{(i', 
j')}{(i,j)} \neq \egweigp{(i', j')}{(i-1,j)}+\egweige{\egev{(i,j)}}\textrm{ e 
}\] \[\egweigp{(i', j')}{(i,j)} \neq \egweigp{(i', 
j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}.\]

Logo, pela recorrência da Observação~\ref{obs:W}, para todo $j'$ tal que $j_1 
\leq j' < j_2$, temos que \[\egweigp{(i', j')}{(i,j)}= \egweigp{(i', 
j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}.\] Portanto,  está
provado que a 
afirmação~\ref{lema:j1j2:casod} está correta.\cqd
\end{prova}

A idéia do Lema~\ref{lemaj1j2} é que a existência de $j_1$ e $j_2$ permite 
agrupar os índices $j'$, de $\egweigp{(i', j')}{(i,j)}$, em 3 grupos de acordo 
com a utilização das arestas horizontal, vertical e diagonal pelos caminhos 
ótimos que saem da linha $i'$ e chegam em $(i,j)$. Repare que a única aresta 
que obrigatoriamente é utilizada, quando $j'=j$, é a aresta vertical. A 
Figura~\ref{fig:j1j2} ilustra este agrupamento dos índices $j'$.

\begin{figure}[htbp] \centering \includegraphics[width=0.8\textwidth]{j1j2}
% \end{center}
\caption[Existem $j_1$ e $j_2$]{Os índices $j_1$ e $j_2$ agrupam os caminhos 
ótimos que chegam em $(i,j)$ de acordo com a utilização das arestas 
$e_H^{i,j}$, $e_D^{i,j}$ e $e_V^{i,j}$}
 \label{fig:j1j2}
\end{figure}

Na demonstração do Lema~\ref{lemaj1j2}, foi escolhida uma coluna $j_1^{max}$ de 
$G$ cujo índice é o máximo possível de ser o $j_1$, ou seja, foi escolhido um 
$j_1$ tal que $j_1$ é o menor $j'$ tal que $0 \leq j' \leq j$ e \[\egweigp{(i', 
j')}{(i,j)} \neq \egweigp{(i', j')}{(i,j-1)}+\egweige{\egeh{(i,j)}}.\] Contudo, 
pode-se demonstrar que  $j_1$ é tal que $j_1 \in 
[j_1^{min}, j_1^{max}]$, onde $j_1^{min}$ é o menor $j'$ tal que $0 \leq j' 
\leq j$ e $$\egweigp{(i', j')}{(i,j)} = \egweigp{(i', 
j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}\textrm{ ou}$$ $$\egweigp{(i', 
j')}{(i,j)} = \egweigp{(i', j')}{(i-1,j)}+\egweige{\egev{(i,j)}}.$$

Do mesmo modo, após a escolha de $j_1$, podemos 
escolher qualquer $j_2$ tal que $j_2 \in [j_2^{min}, j_2^{max}]$, onde 
$j_2^{min}$ (este foi o $j_2$ escolhido na demonstração do Lema~\ref{lemaj1j2}) é o menor $j'$ tal
que $j_1 \leq j' \leq j$ e $$\egweigp{(i', j')}{(i,j)} = \egweigp{(i', 
j')}{(i-1,j)}+\egweige{\egev{(i,j)}}$$ e $j_2^{max}$ é o menor $j'$ tal que 
$j_1 \leq j' \leq j$, $$\egweigp{(i', j')}{(i,j)} \neq \egweigp{(i', 
j')}{(i-1,j-1)}+\egweige{\eged{(i,j)}} \textrm{,}$$ $$\egweigp{(i', j')}{(i,j)} 
\neq \egweigp{(i', j')}{(i,j-1)}+\egweige{\egeh{(i,j)}} \textrm{ e}$$ $$\forall 
j''\tq j'' \in [j_1,j_2[ \textrm{ temos } \egweigp{(i', j'')}{(i,j)} = 
\egweigp{(i', j'')}{(i-1,j-1)}+\egweige{\eged{(i,j)}}.$$

Repare que este modo para obter $j_2^{min}$ e $j_2^{max}$, depende do valor escolhido
de $j_1$. No entanto, é possível obter $j_2^{min}$ e $j_2^{max}$ sem depender do 
valor escolhido de $j_1$. Porém, para isto, a obtenção de $j_1^{min}$ e
$j_1^{max}$ dependerá do valor escolhido de $j_2$.

Em suma, os índices $j_1$ e $j_2$ podem não ser únicos e existem intervalos 
$[j_1^{min}, j_1^{max}]$ e $[j_2^{min}, j_2^{max}]$ onde os índices $j_1$ e 
$j_2$, respectivamente, podem ser escolhidos.

Na linha~\ref{alg:controiB:encontraj1j2} do Algoritmo~\ref{alg:constroiB}, 
veremos como usar a Proposição~\ref{prop:BporDif} para calcular os valores 
$j_1$ e $j_2$ descritos no Lema~\ref{lemaj1j2}.

\section{Árvores para armazenar $\egweigp{(i', j')}{(i,j)}$}
\label{sec:aligninvarvb}

Nesta seção, vamos descrever uma estrutura de árvores que armazena os valores 
de $\egweigp{(i', j')}{(i,j)}$ de um \gred\ $G$ de $s$ e $t$. Dados um índice 
$i'$ de $s$ e um vértice $(i,j)$ de $G$ tal que $i'\leq i$, cada 
árvore armazena os valores de $\egweigp{(i', j')}{(i,j)}$ para todos os $j'$ 
tal que $0 \leq j' \leq j$. Cada árvore, apesar de manter $j+1$ valores de 
$\egweigp{(i', j')}{(i,j)}$, pode ser construída em tempo e espaço logarítmicos.

\begin{definicao}[Árvores para armazenar $\egweigp{(i', j')}{(i,j)}$] Sejam $G$ 
um \gred\ de $s$ e $t$, $(i,j)$ um vértice de $G$ e $i'$ o índice de uma linha 
de $G$ tal que $i' \leq i$. Seja a árvore binária $\arvb{G}{i'}{i}{j}$ definida 
da seguinte forma:
\begin{itemize}
  \item $\arvb{G}{i'}{i}{j}$ possui pesos nas arestas.
  \item $\arvb{G}{i'}{i}{j}$ tem $j+1$ folhas, tal que todas têm profundidade 
  $\lceil \log_2 (j+1) \rceil$ e são rotuladas seqüencialmente de $0$ a $j$.
  \item A cada vértice $v$ de $\arvb{G}{i'}{i}{j}$ associamos os seguintes 
  atributos:
    \begin{itemize}
  \item $esq_v$: o filho à esquerda de $v$,
  \item $dir_v$: o filho à direita de $v$,
  \item $h_v$: o comprimento do caminho de $v$ até uma folha,
  \item $p_v$: o peso do caminho da raiz até $v$ e
  \item $pe_v$: o peso do caminho de $v$ até a folha mais a direita da 
  subárvore esquerda de $v$, se esta subárvore for completa; e  $-\infty$ se 
  esta subárvore for incompleta.
    \end{itemize}
  \item Para cada $j'$ tal que $0 \leq j' \leq j$, o peso do caminho da raiz 
  até a folha $j'$ em $\arvb{G}{i'}{i}{j}$ é igual ao peso $\egweigp{(i', 
  j')}{(i,j)}$ em $G$.
\end{itemize}
\end{definicao}

\begin{figure}[htbp] \centering 
\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{exemploarvorebinaria} \caption[Árvore 
binária $\arvb{G}{i'}{i}{4}$]{Exemplo de árvore binária $\arvb{G}{i'}{i}{4}$. 
Neste exemplo, não são mostrados os pesos das arestas e os atributos $esq_v$, 
$dir_v$, $h_v$, $p_v$ e $pe_v$ de cada vértice.}
 \label{fig:exArvoreBinaria}
\end{figure}

A Figura~\ref{fig:exArvoreBinaria} ilustra a topologia de uma árvore 
$\arvb{G}{i'}{i}{j}$. Fixado um $j$, a topologia das árvores 
$\arvb{G}{i'}{i}{j}$ são todas iguais, para todos $i$ e $i'$ tais que $0 \leq 
i' \leq i \leq n$. A única diferença entre as árvores são os pesos nas arestas.

Como visto no Lema~\ref{lemaj1j2}, existe pelo menos um $j_1$ tal que, para 
todo $j'$ tal que $j' \in [0,j_1[$, $$\egweigp{(i', 
j')}{(i,j)}=\egweigp{(i',j')}{(i,j-1)} +\egweige{\egeh{(i,j)}}.$$ Portanto, o 
valor de $\egweigp{(i', j')}{(i,j)}$, para $j'$ tal que $j' \in [0,j_1[$, é o 
peso do caminho da raiz até a folha $j'$ na árvore $\arvb{G}{i'}{i}{j-1}$ mais 
$\egweige{\egeh{(i,j)}}$.

Assim, utilizando a subárvore de $\arvb{G}{i'}{i}{j-1}$ restrita aos caminhos 
da raiz até as folhas de $0$ até $j_1-1$, podemos obter a subárvore de 
$\arvb{G}{i'}{i}{j}$ restrita aos caminhos da raiz até as folhas de $0$ até 
$j_1-1$. Algumas poucas alterações nessa subárvore de $\arvb{G}{i'}{i}{j-1}$ 
bastam para contemplar o valor adicional $\egweige{\egeh{(i,j)}}$ e obter a 
subárvore análoga de $\arvb{G}{i'}{i}{j}$. Estas alterações podem ser feitas, 
adicionando-se este valor $\egweige{\egeh{(i,j)}}$ a toda aresta que parta de 
um vértice no caminho da raiz a $j_1$, e termine num vértice que não está neste 
caminho e é ancestral de uma folha $j'$, onde $j'$ é tal que $j' \in [0,j_1[$.

De forma equivalente é possível construir as subárvores de $\arvb{G}{i'}{i}{j}$ 
que contêm os caminhos da raiz até as folhas de $j_1$ até $j_2-1$ e de $j_2$ 
até $m$, com as subárvores análogas de $\arvb{G}{i'}{i-1}{j-1}$ e 
$\arvb{G}{i'}{i-1}{j}$, respectivamente.

A Figura~\ref{fig:constroiArvoreBinaria} ilustra como fica uma árvore
$\arvb{G}{i'}{i}{j}$ construída como descrito acima. 

\begin{figure}[htbp] \centering 
\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{exemploBlj} 
\caption[Construção da árvore binária $\arvb{G}{i'}{i}{j}$]{Exemplo de árvore 
binária $\arvb{G}{i'}{i}{j}$ construída a partir das árvores 
$\arvb{G}{i'}{i}{j-1}$ (subárvore $A$ e folha $j_1-1$), 
$\arvb{G}{i'}{i-1}{j-1}$ (subárvores $B$ e $C$) e $\arvb{G}{i'}{i-1}{j}$ 
(subárvores $D$ e $E$ e folha $j_2+1$).}

 \label{fig:constroiArvoreBinaria}
\end{figure}

Assim, uma árvore $\arvb{G}{i'}{i}{j}$ pode ser construída, essencialmente, com 
sub\-ár\-vo\-res das árvores $\arvb{G}{i'}{i}{j-1}$, $\arvb{G}{i'}{i-1}{j-1}$ e 
$\arvb{G}{i'}{i-1}{j}$.

O Algoritmo~\ref{alg:constroiB} constrói uma árvore binária 
$\arvb{G}{i'}{i}{j}$ a partir das árvores $\arvb{G}{i'}{i}{j-1}$, 
$\arvb{G}{i'}{i-1}{j-1}$ e $\arvb{G}{i'}{i-1}{j}$.

\begin{algorithm}[htbp]
%   \begin{algo}{constroiB_{i'}^{i,j}}{B_{i'}^{i,j-1}, 
  \begin{algo}{constroiB}{\arvb{G}{i'}{i}{j-1}, \arvb{G}{i'}{i-1}{j-1}, 
\arvb{G}{i'}{i-1}{j}, G, i, j}
  \COM{$G$ é o grafo de edição onde estão as arestas $\egev{(i,j)}$, $\eged{(i,j)}$ e
   $\egeh{(i,j)}$}
  \ACTT{Encontra $j_1$ e $j_2$} \label{alg:controiB:encontraj1j2}
  \ACTT{Constrói a partir de $r$ os caminhos $p_1$ e $p_2$ até $j_1$ e $j_2$
  respectivamente}
  \label{alg:controiB:constroip1p2} 
  \DOFOR{$cada $v \in p_1$ e $v \neq j_1}
  \COM{Coloca subárvores de $\arvb{G}{i'}{i}{j-1}$ à esquerda de $p_1$}  
  \COM{Coloca subárvores de $\arvb{G}{i'}{i-1}{j-1}$ à direita de $p_1$}
   \SET{v'}{$vértice de $\arvb{G}{i'}{i}{j-1}$ no caminho até $j_1$ cujo $h_v = h_{v'}}
   \SET{v''}{$vértice de $\arvb{G}{i'}{i-1}{j-1}$ no caminho até $j_1$ cujo $h_v = h_{v'}} 
   \IF{esq_v=nil}
   \ACTT{Coloca uma aresta esquerda em $v$ cujo peso é }
  \ACTT{$p_{esq_{v'}}+\egweige{\egeh{(i,j)}}$ e chega em $esq_{v'}$}
  \ELSE
  \ACTT{Coloca uma aresta direita em $v$ cujo peso é}
  \ACTT{$p_{dir_{v''}}+\egweige{\eged{(i,j)}}$ e chega em $dir_{v''}$}
   \FI
   \ACTT{Preenche os atributos de $v$ ($esq_v$,$dir_v$,$h_v$,$p_v$ e $pe_v$,)}
    \OD
  \DOFOR{$cada $v \in p_2$ e $v \neq j_2}  
  \COM{Coloca subárvores de $\arvb{G}{i'}{i-1}{j-1}$ à esquerda de $p_2$}  
  \COM{Coloca subárvores de $\arvb{G}{i'}{i-1}{j}$ à direita de $p_2$}
  
   \SET{v'}{$vértice de $\arvb{G}{i'}{i-1}{j-1}$ no caminho até $j_2$ cujo $h_v = h_{v'}}
   \SET{v''}{$vértice de $\arvb{G}{i'}{i-1}{j}$ no caminho até $j_2$ cujo $h_v = h_{v'}}
   \IF{esq_v=nil}
   \ACTT{Coloca uma aresta esquerda em $v$ cujo peso é }
  \ACTT{$p_{esq_{v'}}+\egweige{\eged{(i,j)}}$ e chega em $esq_{v'}$}
  \ELSE
  \ACTT{Coloca uma aresta direita em $v$ cujo peso é}
  \ACTT{$p_{dir_{v''}}+\egweige{\egev{(i,j)}}$ e chega em $dir_{v''}$}
   \FI
   \ACTT{Preenche os atributos de $v$ ($esq_v$,$dir_v$,$h_v$,$p_v$ e $pe_v$,)}
    \OD
    \RETURN{r}
  \caption[constroiB]{Algoritmo que constrói uma árvore
%   \caption[constroiB_{i'}^{i,j}]{Algoritmo que constrói uma árvore
  $\arvb{G}{i'}{i}{j}$} 
  \label{alg:constroiB}
  \end{algo}
\end{algorithm} 

A partir daqui descreveremos como o Algoritmo~\ref{alg:constroiB} funciona.

Na linha~\ref{alg:controiB:encontraj1j2} os valores de $j_1$ e $j_2$ são 
encontrados como descrito a seguir. Caminhe simultaneamente pelas árvores 
$\arvb{G}{i'}{i}{j-1}$, $\arvb{G}{i'}{i-1}{j-1}$ e $\arvb{G}{i'}{i-1}{j}$ e com 
os valores $pe_v$ de cada árvore, calcule, para a folha $j'$ mais à direita da 
subárvore esquerda de $v$, os valores de $\hdiffunc{G}{i'}{j'}{i-1}{j}$, 
$\ddiffunc{G}{i'}{j'}{i}{j}$ e $\vdiffunc{G}{i'}{j'}{i}{j-1}$. Desta forma, 
semelhante a uma busca binária, estenda para a direita ou para a esquerda os 
caminhos para $j_1$ e $j_2$ usando a Proposição~\ref{prop:BporDif}.
  
Na linha~\ref{alg:controiB:constroip1p2} a construção de $\arvb{G}{i'}{i}{j}$ é 
iniciada construindo os caminhos $p_1$ e $p_2$ da raiz até $j_1$ e $j_2$ 
respectivamente, atribuindo peso zero para todas as arestas de $p_1$ e $p_2$, 
exceto na última aresta dos caminhos onde são colocados pesos: $\egweigp{(i', 
j_1)}{(i-1,j-1)}+ \egweige{\eged{(i,j)}}$ para a aresta que chega em $j_1$ (se
$j_1 \neq j_2$) e em seguida 
$\egweigp{(i', j_2)}{(i-1,j)}+ \egweige{\egev{(i,j)}}$ para a aresta que chega 
em $j_2$.

A Figura~\ref{fig:constroiArvoreBinaria} ilustra como fica uma árvore 
$\arvb{G}{i'}{i}{j}$ construída pelo Algoritmo~\ref{alg:constroiB} a partir das 
árvores $\arvb{G}{i'}{i}{j-1}$,$\arvb{G}{i'}{i-1}{j-1}$ e 
$\arvb{G}{i'}{i-1}{j}$. Seja $v'$ o vértice em $\arvb{G}{i'}{i}{j-1}$ tal que 
$h_v = h_{v'}$. De modo análogo definimos os vértices $u'$ e $x'$ em 
$\arvb{G}{i'}{i-1}{j-1}$ e o vértice $y'$ em $\arvb{G}{i'}{i-1}{j}$ . A 
subárvore $A$ é exatamente a mesma subárvore de $B_{i'}^{i,j-1}$ cuja raiz é o 
vértice $esq_{v'}$. Analogamente, as subárvores $B$ e $C$ são subárvores de 
$B_{i'}^{i-1,j-1}$ cujas raízes são os vértice $dir_{u'}$ e $esq_{x'}$, 
respectivamente; e a subárvore $D$ é a subárvore de $B_{i'}^{i-1,j}$ cuja raiz 
é o vértice $dir_{y'}$. As folhas $j_1-1$ e $j_2+1$ de $B_{i'}^{i,j}$ são as 
folhas $j_1-1$ de $B_{i'}^{i,j-1}$ e $j_2+1$ de $B_{i'}^{i-1,j}$, 
respectivamente.
	
Para a construção de uma $\arvb{G}{i'}{i}{j}$ é necessário percorrer os 
caminhos até $j_1$ e até $j_2$ nas 4 árvores e ir acrescentando as subárvores 
correspondentes. Assim o tempo de execução do Algoritmo~\ref{alg:constroiB} é 
$O(\log m)$. São criados $O(\log m)$ vértices e arestas, assim a memória 
consumida é $O(\log m)$.
  
Se já tivermos calculado as $m$ árvores $\arvb{G}{i'}{i-1}{j}$, as $m$ árvores 
$\arvb{G}{i'}{i-1}{j-1}$e as $m$ árvores $\arvb{G}{i'}{i}{j-1}$, levaremos 
tempo $O(m \log m)$ para construir as $m$ árvores $\arvb{G}{i'}{i}{j}$. O 
Algoritmo~\ref{alg:constroiW} mostra como é feito a construção da matriz 
$\matw{G}{i'}{i}$ definida no Lema~\ref{lemaWMonge}.
  
O tempo de acesso a um valor de $\matw{G}{i'}{i}[j',j]$ é $O(\log m)$. Porém, 
para obter os valores dos $m$ elementos de uma coluna de 
$\matw{G}{i'}{i}[j',j]$ é necessário tempo $O(m)$.

Repare que, por uma questão de espaço e legibilidade do pseudo-código, não está 
contemplado no Algoritmo~\ref{alg:constroiB} o caso de construir uma árvore 
$\arvb{G}{i'}{i}{j}$, onde $i'=i$ ou $j=0$. O algoritmo pode ser facilmente 
alterado para tratar estes casos.

\begin{algorithm}[htbp]
  \begin{algo}{constroiW}{\matw{G}{i'}{i-1},G,i',i}
   \SET{\matw{G}{i'}{i}[0]}{constroiB(\emptyset,\emptyset,\matw{G}{i'}{i-1}[0],G,i,0)}
   \DOFORI{j}{1}{m}
   		\SET{\matw{G}{i'}{i}[j]}{constroiB(\matw{G}{i'}{i}[j-1],\matw{G}{i'}{i-1}[j-1],\matw{G}{i'}{i-1}[j],G,i,j)}
\OD
   \RETURN{\matw{G}{i'}{i}}
\caption[constroiW]{Representação da
%   \caption[constroi\matw{G}{i'}{i}]{Representação da
matriz $\matw{G}{i'}{i}$ por árvores binárias}
  \label{alg:constroiW}
  \end{algo}
\end{algorithm}

\section{Algoritmo $O(n^3 \log n)$}
\label{sec:algn3logn}

Sejam $s=s[1\Rng n]$ e $t=t[1\Rng m]$ as \seqs\ a serem alinhadas.

Sejam $G=(V,E,\egweigsym)$ o \gred\ estendido de $s$ e $t$ e 
$\overline{G}=(V,\overline{E},\egweigsymi)$ o \gred\ de $\invert{s}$ e $t$. 
Repare que em $\overline{G}$, os pesos $\egweigei{\egehi{(i,j)}}$, 
$\egweigei{\egedi{(i,j)}}$ e $\egweigei{\egevi{(i,j)}}$ correspondem, 
respectivamente, às pontuações das \opeds\ de inserção de $t[j]$, substituição 
de $\invert{s[n+1-i]}$ por $t[j]$ e remoção de $\invert{s[n+1-i]}$. Um caminho 
ótimo em $\overline{G}$ de $(n-i,j)$ a $(n-i',j)$ representa um alinhamento 
ótimo entre $\invert{s[i'+1\Rng i]}$ e $t[j'+1\Rng j]$.

Consideraremos que a pontuação para uma \oped\ de inversão é fixa e independe 
do trecho sendo invertido. Denotaremos esta pontuação por \opedweiginv.

Vamos considerar que o peso de uma aresta estendida $\egex{(i',j')}{(i,j)}$ em 
$G$ é igual ao peso de um caminho ótimo em $\overline{G}$ de $(n-i,j)$ a 
$(n-i',j)$ mais a pontuação de uma \oped\ de inversão, ou seja, 
\[\egweige{\egex{(i',j')}{(i,j)}}=\egweigpi{(n-i,j)}{(n-i',j)}+\opedweiginv.\]

\begin{figure}
 \centering 
 \includegraphics[width=0.7\textwidth,height=0.5\textwidth]{alinhamentoinvertido} 
 \caption[Uma aresta estendida e o alinhamento do trecho invertido]{A seta é a 
 aresta estendida $\egex{(i',j')}{(i,j)}$ em $G$ e a linha tracejada representa 
 o alinhamento ótimo entre $\invert{s[i'+1\Rng i]}$ e $t[j'+1\Rng j]$, ou seja, 
 um caminho ótimo em $\overline{G}$ de $(n-i,j)$ a $(n-i',j)$.}
\label{fig:alinhamentoinvertido}
\end{figure} 

A Figura~\ref{fig:alinhamentoinvertido} mostra a aresta estendida 
$\egex{(i',j')}{(i,j)}$ em $G$ e uma representação do alinhamento ótimo entre 
$\invert{s[i'+1\Rng i]}$ e $t[j'+1\Rng j]$, ou seja, uma representação de um 
caminho ótimo em $\overline{G}$ de $(n-i,j)$ a $(n-i',j)$.

Seja a matriz $B$ $(n+1) \times (m+1)$ tal que $B[i,j]$ é a pontuação de um 
alinhamento ótimo com \invnsobs\ entre $s[1\Rng i]$ e $t[1\Rng j]$, para 
quaisquer $i$ e $j$ tais que $0 \leq i \leq n$, $0 \leq j \leq m$, ou seja, 
$B[i,j]$ é o peso de um caminho ótimo entre $(0,0)$ e $(i,j)$ em $G$.

Seja $\matw{\overline{G}}{n-i}{n-i'}$ a matriz de pesos de caminhos em 
$\overline{G}$ entre $n-i$ e $n-i'$ de acordo com a definição do 
Lema~\ref{lemaWMonge}, ou seja, $\matw{\overline{G}}{n-i}{n-i'}[j',j]$ é a 
pontuação de um alinhamento ótimo entre $\invert{s[i'+1\Rng i]}$ e $t[j'+1\Rng 
j]$. Portanto 
$\egweige{\egex{(i',j')}{(i,j)}}=\matw{\overline{G}}{n-i}{n-i'}[j',j]+\opedweiginv$.

Podemos dizer que um caminho ótimo entre $(0,0)$ e $(i,j)$ em $G$, para 
qualquer $(i,j)$ tal que $(i,j)\neq (0,0)$, termina com uma aresta horizontal, 
vertical, diagonal ou estendida.

Ou seja, $B[0,0]=0  \mbox{ e } \forall\ (i,j) \in V\tq (i,j) \neq (0,0)$ temos
que 

$$B[i,j]=\max \left\{ \begin{array} {ll} 
	B[i-1,j]+\egweige{\egev{(i,j)}},& $$ se $$ \quad \exists \quad \egev{(i,j)}\in E,\\ 
	B[i,j-1]+\egweige{\egeh{(i,j)}},& $$ se $$\quad \exists \quad \egeh{(i,j)}\in E,\\ 
 	B[i-1,j-1]+\egweige{\eged{(i,j)}},& $$ se $$\quad \exists \quad \eged{(i,j)}\in E,\\ 
 	\max(B[i',j'] +
 	\egweige{\egex{(i',j')}{(i,j)}}),&\forall\ \egex{(i',j')}{(i,j)} \in E. \end{array}\right.$$

\begin{algorithm}[htbp]
  \begin{algo}{BIMN3logn}{s,t}
	\ACTT{Sejam $G=(V,E,\egweigsym)$ o \gred\ estendido de $s$ e $t$ e}
	\COM{$\overline{G}$ o \gred\ de $\overline{s}$ e $t$. }
	\COM{$B[i,j]=\egweigp{(i',j')}{(i,j)} \mbox{ em } G$}
    \DOFORI {i} {0} {|s|} \label{bimn3logn:loop1}
    	\IF {i=0} \label{bimn3logn:dirinicio}
    		\SET {B[0,0]}{0}
\ELSE
    		\COM{Na 1ª coluna $\nexists$ arestas horizontais nem diagonais}
    		\SET {B[i,0]}{B[i-1,0]+\egweige{\egev{(i,j)}}}
\FI
      	\DOFORI {j} {1} {|t|}
      		\IF {i=0}
    		\COM{Na 1ª linha $\nexists$ arestas verticais nem diagonais}
		    	\SET {B[0,j]}{B[0,j-1]+\egweige{\egeh{(i,j)}}}
\ELSE
      			\COM {Obtém o máximo entre os caminhos que termi-}
      			\COM { nam nas arestas horizontal, vertical e diagonal}
      			\SET{h}{B[i,j-1]+\egweige{\egeh{(i,j)}}}
      			\SET{v}{B[i-1,j]+\egweige{\egev{(i,j)}}}
      			\SET{d}{B[i-1,j-1]+\egweige{\eged{(i,j)}}}
        		\SET{B[i,j]}{\max(h,v,d)}
\FI
%        \EXT {\qquad\qquad\qquad B[i-1,j-1]+\weight{s[i],t[j]})}
\OD \label{bimn3logn:dirfim}
	\COM{Obtém, para cada $j$ da linha $i$, o máximo entre os }
	\COM {caminhos que terminam numa aresta estendida}
	\SET{\matw{\overline{G}}{n-i}{n-(i'+1)}}{\emptyset}
    \DOFORD {i'} {i} {0}\label{bimn3logn:loopiLinha}
        \SET {\matw{\overline{G}}{n-i}{n-i'}}
{\mathit{ConstroiW}(\matw{\overline{G}}{n-i}{n-(i'+1)},\overline{G},n-i,n-i')}
        \label{bimn3logn:constroiW} 
%         \COM {$\matw{G}{i'}{i}[j',j] = $ peso do alinhamento de $\invert{s[i'+1\Rng i]}$
%         e $t[j',j]$}
        \ACTT {Define $A_{i'}^i[1\Rng |t|,1\Rng |t|]$ através de $\matw{\overline{G}}{n-i}{n-i'}$ e}
		\ACTT {\mbox{    } da linha $i'$ de $B$}\label{bimn3logn:matrizA}
        
        \COM {$A_{i'}^i[j',j] = \matw{\overline{G}}{n-i}{n-i'}[j',j] + B[i',j']+\opedweiginv$}
         \COM{$MaxCol_{i'}^i[1\Rng |t|]$ é o vetor de máximos de $A_{i'}^i$}
        \ACTT {$maxTotMonotonica (A_{i'}^i,MaxCol_{i'}^i)$} \label{bimn3logn:maxtotmonotonica}
        \DOFORI {j} {0} {|t|}\label{bimn3logn:forComInv}
          \SET {B[i,j]} {\max(B[i,j],A_{i'}^i[MaxCol_{i'}^i[j],j])}
\OD \OD \OD \RETURN B \caption[BIMN3logn]{Algoritmo $O(n^3 \log n)$ para 
obtenção da matriz $B$}
  \label{alg:bimn3logn}
  \end{algo}
\end{algorithm}

\begin{figure}
 \centering
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{algn3logn}
\caption[Ilustração da execução do Algoritmo~\ref{alg:bimn3logn}]{Ilustração da execução do Algoritmo~\ref{alg:bimn3logn}. A linha
pontilhada representa um caminho de $(0,0)$ a $(i',j')$ em $G$. A
linha tracejada representa o alinhamento de $\overline{s[i'+1\Rng i]} \times
t[j'+1\Rng j]$}.
\label{fig:algn3logn}
\end{figure} 

O Algoritmo~\ref{alg:bimn3logn} constrói a matriz
$B$. A sua execução é ilustrada na Figura~\ref{fig:algn3logn} e é descrita
a seguir.

O laço controlado pela linha~\ref{bimn3logn:loop1} calcula os valores da linha 
$i$ de $B$. Os valores de $B[i,j]$ calculados nas linhas 
\ref{bimn3logn:dirinicio} a~\ref{bimn3logn:dirfim} não consideram a operação de 
inversão. Estas linhas levam tempo $O(m)$ para serem executadas.

Na linha~\ref{bimn3logn:constroiW}, para $i$ e $i'$ fixados, são calculados os 
valores dos alinhamentos ótimos de $\overline{s[i'+1\Rng i]} \times t[j'+1\Rng 
j]$, para todo $j$ e $j'$ tais que $0 \leq j' \leq j \leq m$. Para tanto, já se 
conhece $\matw{\overline{G}}{n-i}{n-(i'+1)}$ da iteração anterior e portanto, 
como já visto na seção \ref{sec:jeanette}, a execução desta linha leva tempo 
$O(m \log m)$. Convém observar que neste algoritmo é usada a construção 
incremental de $\matw{\overline{G}}{n-i}{n-(i'+1)}$ proposta por Jeanette em 
\cite{MR1621993}. O acesso a qualquer elemento da matriz 
$\matw{\overline{G}}{n-i}{n-i'}$, é feito em tempo $O(\log m)$.

A matriz $A_{i'}^i$ definida na linha~\ref{bimn3logn:matrizA} não é realmente 
construída, mas como o acesso a um elemento de $A_{i'}^i$ necessita do acesso a 
um elemento de $\matw{\overline{G}}{n-i}{n-i'}$, o acesso a qualquer elemento 
de $A_{i'}^i$ é feito em tempo $O(\log m)$. O elemento $A_{i'}^i[j',j]$ é o 
peso de um caminho ótimo de $(0,0)$ a $(i,j)$ em $G$ que usa a aresta 
$\egex{(i',j')}{(i,j)}$. Como já vimos, a matriz 
$\matw{\overline{G}}{n-i}{n-i'}$ é uma matriz de monge inversa. Dado $i'$, 
temos que $B[i',j']+\opedweiginv$ é um vetor, portanto a matriz $A_{i'}^i$ é 
uma matriz resultante da soma de uma matriz de monge com um vetor. Logo 
$A_{i'}^i$ também é uma matriz de monge, ou seja, $A_{i'}^i$ é totalmente 
monotônica, conforme visto na seção~\ref{sec:monge}. Portanto podemos obter os 
máximos de $A_{i'}^i$ com o Algoritmo \ref{alg:maxTotMonotonica} 
($maxTotMonotonica$). O Algoritmo \ref{alg:maxTotMonotonica} faz $O(m)$ acessos 
a matriz, portanto a linha \ref{bimn3logn:maxtotmonotonica} leva tempo $O(m 
\log m)$. Após a chamada da função $maxTotMonotonica$, o elemento 
$MaxCol_{i'}^i[j]$ contém o índice $j'$ associado ao máximo da coluna $j$ em 
$A_{i'}^i$.

%\TODO melhorar esta explicação
O laço controlado pela linha~\ref{bimn3logn:forComInv} analisa se o valor 
calculado em $A_{i'}^i[j',j]$ é maior do que todos os valores de $B[i,j]$ já 
encontrados anteriormente. Esse laço leva tempo $O(m)$.

Portanto, o laço controlado pela linha~\ref{bimn3logn:loopiLinha} leva tempo 
$O(nm \log m)$ e o algoritmo leva tempo $O(n^2m \log m)$. Quando $m=O(n)$  o 
algoritmo tem tempo de execução $O(n^3 \log n)$.

\section{Algoritmo $O(n^3)$}
\label{sec:algn3}

Sejam $s=s[1\Rng n]$ e $t=t[1\Rng m]$ as \seqs\ a serem alinhadas.

Sejam $G=(V,E,\egweigsym)$ o \gred\ estendido de $s$ e $t$ e 
$\overline{G}=(V,\overline{E},\egweigsymi)$ o \gred\ de $\invert{s}$ e $t$. 

Consideraremos que a pontuação para uma \oped\ de inversão é uma constante e 
independe do trecho sendo invertido. Denotaremos esta pontuação por 
\opedweiginv.

Vamos considerar, nesta seção, que o peso de uma aresta estendida 
$\egex{(i',j')}{(i,j)}$ do \gred\ estendido $G$ de $s$ e $t$ é igual à 
pontuação de um alinhamento ótimo entre $\invert{s[i'+1\Rng i]}$ e $t[j'+1\Rng 
j]$ mais a pontuação de uma \oped\ de inversão, ou seja, 
\[\egweige{\egex{(i',j')}{(i,j)}}=\egweigpi{(n-i,j')}{(n-i',j)}+\opedweiginv.\]

Seja a matriz $B$ $(n+1) \times (m+1)$ tal que $B[i,j]$ é a pontuação de um 
alinhamento ótimo com \invnsobs\ entre $s[1\Rng i]$ e $t[1\Rng j]$, para 
quaisquer $i$ e $j$ tais que $0 \leq i \leq n$, $0 \leq j \leq m$, ou seja, 
$B[i,j]$ é o peso de um caminho ótimo entre $(0,0)$ e $(i,j)$ em $G$.

Podemos dizer que um caminho ótimo entre $(0,0)$ e $(i,j)$ em $G$, para 
qualquer $(i,j)$ tal que $(i,j)\neq (0,0)$, termina com uma aresta horizontal, 
vertical, diagonal ou estendida.

Ou seja, $B[0,0]=0  \mbox{ e } \forall\ (i,j) \in V\tq (i,j) \neq (0,0)$ temos 
que

$$B[i,j]=\max \left\{ \begin{array} {ll} 
	B[i-1,j]+\egweige{\egev{(i,j)}},& $$ se $$ \quad \exists \quad \egev{(i,j)}\in E,\\ 
	B[i,j-1]+\egweige{\egeh{(i,j)}},& $$ se $$\quad \exists \quad \egeh{(i,j)}\in E,\\ 
 	B[i-1,j-1]+\egweige{\eged{(i,j)}},& $$ se $$\quad \exists \quad \eged{(i,j)}\in E,\\ 
 	\max(B[i',j'] +
 	\egweige{\egex{(i',j')}{(i,j)}}),&\forall\ \egex{(i',j')}{(i,j)} \in E. \end{array}\right.$$

No algoritmo que iremos descrever nesta seção, vamos obter em tempo $O(n\psi)$, 
para um dado vértice $(i,j)$, o vértice $(i',j')$ tal que $(B[i',j'] + 
\egweige{\egex{(i',j')}{(i,j)}})$ é máximo, onde $\psi$ é constante para muitos 
sistemas de pontuação para alinhamentos, inclusive aqueles comumente usados com 
pesos constantes. Juntamente com este vértice $(i',j')$ vamos obter o valor 
$(B[i',j'] + \egweige{\egex{(i',j')}{(i,j)}})$ e portanto o valor de $B[i,j]$. 
Logo, como existem $mn$ vértices $(i,j)$, vamos construir a matriz $B$ em tempo 
$O(mn^2\psi)$.

Fixados o vértice $(i,j)$ de um \gred\ $G$ qualquer e uma linha $i'$ de $G$, 
tal que $i' \leq i$, sabemos pela Proposição~\ref{prop:difcrescentes} que 
$\hdiffunc{G}{i'}{j'}{i}{j}$ não decresce quando $j'$ varia de $0$ a $j-1$, ou 
seja, $\hdiffunc{G}{i'}{j'}{i}{j} \geq \hdiffunc{G}{i'}{j'-1}{i}{j}$ para todo 
$j'$ tal que $0 < j' <j$. Portanto, iremos dizer que 
$\hdiffunc{G}{i'}{j'}{i}{j}$ assume no máximo $\psihfunc{G}{i'}{i}{j}$ valores 
distintos, sendo que $\psihfunc{G}{i'}{i}{j}$ é tal que $1 \leq 
\psihfunc{G}{i'}{i}{j} \leq j$.

Muitas vezes, os pesos das arestas de um \gred\ são inteiros e constantes. Por 
exemplo, para qualquer \gred\ $G$ onde todas as arestas verticais e horizontais 
recebem peso constante $-g$ e as arestas diagonais recebem peso $a$ ou $-g$, 
onde $a\geq 0$ e $g\geq 0$, temos que\footnote{A maioria do sistemas de 
pontuação de alinhamento atribuem uma pontuação negativa (penalidade) para os 
\emph{gaps} e \emph{mismatches}, e uma pontuação positiva para os
\emph{matches}.} $\egweigp{(i',j')}{(i,j)}
\geq \egweigp{(i',j')}{(i,j-1)}-g$ e $\egweigp{(i',j')}{(i,j-1)} \geq 
\egweigp{(i',j')}{(i,j)}-g-a$, portanto 
$\egweigp{(i',j')}{(i,j)}-\egweigp{(i',j')}{(i,j-1)} \in [-g,a+g]$ e 
$\egweigp{(i',j')}{(i,j)}-\egweigp{(i',j')}{(i,j-1)} \in \intset$. Logo, 
$\psihfunc{G}{i'}{i}{j} \leq a + 2g +1$ e podemos dizer que 
$\psihfunc{G}{i'}{i}{j}$ é constante.

\begin{definicao}[Ponto de mudança de $\hdifsym{G}$ fixados $i$, $i'$ e $j$] 
Seja $G$ um \gred. Dados um vértice $(i,j)$ e uma linha $i'$ de $G$ tais que 
$0 \leq i' \leq i \leq n$, diremos que $j'$ é um ponto de mudança de 
$\hdifsym{G}$ fixados $i$, $i'$ e $j$ se $1 \leq j' \leq j-1$ e 
$\hdiffunc{G}{i'}{j'}{i}{j} \neq \hdiffunc{G}{i'}{j'-1}{i}{j}$.
\end{definicao}

Cada um destes pontos de mudança de $\hdifsym{G}$ são chamados em 
\cite{MR1869256} de \emph{Borderline point}.

\begin{definicao}[Lista \blhvec{G}{i'}{i}{j}] Fixados o \gred\ $G$ e as linhas 
$i'$ e $i$ de $G$ tais que $0 \leq i' \leq i \leq n$, para todo $j$ de $1$ a 
$m$ definimos a lista $\blhvec{G}{i'}{i}{j}$ como a lista ordenada cujo 
primeiro elemento é o zero e os demais são os pontos de mudança de 
$\hdifsym{G}$ fixados $i$, $i'$ e $j$.
\end{definicao}

Dados um \gred\ $G$, uma linha $i'$ e um vértice $(i,j)$ de $G$, podemos dizer 
que a lista $\blhvec{G}{i'}{i}{j}$ armazena os valores de $j'$ onde inicia um 
novo valor de $\hdiffunc{G}{i'}{j'}{i}{j}$ e que o comprimento da lista 
$\blhvec{G}{i'}{i}{j}$ é 
$\psihfunc{G}{i'}{i}{j}$\footnote{$\psihfunc{G}{i'}{i}{j}$ é limitado por uma 
constante que depende unicamente do sistema de pontuação para o alinhamento}.

A Figura~\ref{fig:borderline} mostra um exemplo das listas \blhvec{G}{0}{n}{j} 
para diversos valores de $j$, onde $G$ é um \gred\ de $s=AATG$ e $t=TTCATGACG$ 
que utiliza um sistema de pontuação de \emph{gap} linear. Com os valores do 
sistema de pontuação da Figura~\ref{fig:borderline} temos que 
$\psihfunc{G}{i'}{i}{j} \leq 4$.

\begin{figure}[htbp] \centering
% \includegraphics*[0.75in,6.7in][9in,10in]{borderline}
\includegraphics[width=0.7\textwidth,height=0.7\textheight,angle=270]{borderline}
% \scalebox{0.85}{\includegraphics*[52pt,478pt][503pt,723pt]{borderline}}
% \end{center}
\caption[Borderline]{Exemplo de \emph{Borderline points}: os elementos de 
$\hdiffunc{ }{0}{j'}{n}{j}$ em negrito são \emph{Borderline points}. As colunas 
$j'$ onde ocorrem estes \emph{Borderline points} estão no vetor $BL_j$. Os 
elementos do vetor $BL_j$ são os elementos da lista $\blhvec{G}{0}{n}{j}$, onde 
$G$ é um \gred\ de $s=AATG$ e $t=TTCATGACG$.}
 \label{fig:borderline}
\end{figure}

Sejam as linhas $i$ e $i'$ fixadas. Suponha conhecidas as listas 
$\blhvec{G}{i'}{i-1}{j}$ para toda coluna $j$ de $G$. Podemos obter em 
tempo e espaço $O(m)$ todas as $m+1$ listas \blhvec{G}{i'}{i}{j}, através de um 
algoritmo descrito em \cite{MR1621993}. Além disto, este mesmo algoritmo também 
pode informar o valor de $\hdiffunc{G}{i'}{j_1}{i}{j}$ para cada elemento $j_1$ 
de $\blhvec{G}{i'}{i}{j}$.

\begin{definicao}[Função $\outsym{G}$] Dados um \gred\ estendido 
$G=(V,E,\egweigsym)$ de $s$ e $t$ e um \gred\ 
$\overline{G}=(V,\overline{E},\egweigsymi)$ de $\invert{s}$ e $t$, a função 
$\outsym{G}:V \times V \rightarrow \realset\cup \{-\infty\}$ é definida por 
$$\outfunc{G}{i'}{j'}{i}{j} = 
\egweigp{(0,0)}{(i',j')}+\egweigpi{(n-i,j')}{(n-i',j)}$$
% $$\outfunc{G}{i'}{j'}{i}{j} = \left\{
%   \begin{array}{ll}
% \egweigp{(0,0)}{(i',j')}+\egweige{\egex{(i',j')}{(i,j)}},&\mbox{se $\exists\
% \egex{(i',j')}{(i,j)}$,}\\ 
% \egweigp{(0,0)}{(i,j)}+\opedweiginv,&\mbox{se } (i,j)=(i',j'),\\
%  -\infty,&\mbox{caso contrário.}
%   \end{array}
% \right.$$
\label{def:out}
\end{definicao}

Repare que se existe a aresta $\egex{(i',j')}{(i,j)}$ então 
$$\outfunc{G}{i'}{j'}{i}{j} + \opedweiginv= 
\egweigp{(0,0)}{(i',j')}+\egweige{\egex{(i',j')}{(i,j)}},$$ ou seja, o valor 
$\outfunc{G}{i'}{j'}{i}{j} + \opedweiginv$ é o peso máximo dentre os pesos dos
caminhos de 
$(0,0)$ a $(i,j)$ em $G$ que contêm a aresta estendida $\egex{(i',j')}{(i,j)}$.

A Figura~\ref{fig:out} ilustra um caminho de $(0,0)$ a $(i,j)$ num \gred\ estendido cujo
peso é $\outfunc{G}{i'}{j'}{i}{j} + \opedweiginv$.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.6\textwidth,height=0.5\textwidth]{out}
% \end{center}
\caption[Caminho de $(0,0)$ a $(i,j)$ com peso 
$\outfunc{G}{i'}{j'}{i}{j} + \opedweiginv$]{Representação de um caminho de 
$(0,0)$ a $(i,j)$ num \gred\ estendido com peso $\outfunc{G}{i'}{j'}{i}{j} + 
\opedweiginv$. A linha tracejada representa um caminho ótimo de $(0,0)$ a 
$(i',j')$ e a seta é a aresta estendida $\egex{(i',j')}{(i,j)}$.}
 \label{fig:out}
\end{figure}

\begin{proposicao}
Para todo par de vértices $(i',j')$ e $(i,j)$ do \gred\ estendido $G$ de $s$ e 
$t$, tais que $j' < j$ e $i' \leq i$, temos que \\
$$\outfunc{G}{i'}{j'}{i}{j}-\outfunc{G}{i'}{j'}{i}{j-1}=\hdiffunc{\overline{G}}{n-i}{j'}{n-i'}{j}.$$
\label{prop:outhdif}
\end{proposicao}
\begin{prova}
Sejam $(i',j')$ e $(i,j)$ um par de vértices do \gred\ estendido $G$ de $s$ e 
$t$, tais que $j' < j$ e $i' \leq i$. 

Utilizando a definição da função $\hdifsym{\overline{G}}$ 
(definição~\ref{def:hdiff}) e a definição da função $\outsym{G}$ (definição~\ref{def:out}), temos que,
\begin{equation*} 
\begin{array}{l}
\outfunc{G}{i'}{j'}{i}{j}-\outfunc{G}{i'}{j'}{i}{j-1}=\\
\hspace{15pt}\egweigp{(0,0)}{(i',j')}+\egweigpi{(n-i,j')}{(n-i',j)}-\\
\hspace{30pt}(\egweigp{(0,0)}{(i',j')}+\egweigpi{(n-i,j')}{(n-i',j-1)})=\\
\hspace{15pt}\egweigpi{(n-i,j')}{(n-i',j)}-\egweigpi{(n-i,j')}{(n-i',j-1)}=\\
\hspace{15pt}\hdiffunc{\overline{G}}{n-i}{j'}{n-i'}{j} \cqd
\end{array}  
\end{equation*}
\end{prova}

Devido a esta proposição, podemos fazer a seguinte observação.

\begin{observacao}
Para todos três vértices $(i',j_1)$, $(i',j_2)$ e $(i,j)$ do \gred\ estendido 
$G$ de $s$ e $t$, tais que $j_1 < j_2 < j$ e $i' \leq i$, temos que 
$\outfunc{G}{i'}{j_2}{i}{j}-\outfunc{G}{i'}{j_1}{i}{j}- 
(\outfunc{G}{i'}{j_2}{i}{j-1}-\outfunc{G}{i'}{j_1}{i}{j-1})=\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j}- 
\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$.
\label{obs:n3difoutigualdifhdif}
\end{observacao}


Fixados um \gred\ estendido $G$ de $s$ e $t$, um vértice $(i,j)$ de $G$ e uma 
linha $i'$ de $G$, tal que $i' \leq i$, descreveremos a seguir como obter o 
valor máximo de $\outfunc{G}{i'}{j'}{i}{j}$ em tempo 
$O(\psihfunc{\overline{G}}{i'}{i}{j})$. Para obter esta complexidade, iremos 
analisar somente as colunas $j'$ de $G$ tais que 
$\hdiffunc{\overline{G}}{n-i}{j'}{n-i'}{j} \neq 
\hdiffunc{\overline{G}}{n-i}{j'}{n-i'}{j-1}$, onde $\overline{G}$ é o \gred\ de 
$\invert{s}$ e $t$. Ou seja, iremos analisar somente as colunas $j'$ de $G$ que 
estão em $\blhvec{\overline{G}}{n-i}{n-i'}{j}$.

\begin{proposicao}
Seja $G$ o \gred\ estendido de $s$ e $t$. Dados três vértices $(i',j_1)$, 
$(i',j_2)$ e $(i,j)$ de $G$, tais que $i' \leq i$ e $j_1 < j_2 < j$ temos que:
\begin{itemize}
  \item se $\outfunc{G}{i'}{j_2}{i}{j-1} \geq \outfunc{G}{i'}{j_1}{i}{j-1}$ 
  então \\ $\outfunc{G}{i'}{j_2}{i}{j} \geq \outfunc{G}{i'}{j_1}{i}{j}$,
  \item se $\outfunc{G}{i'}{j_2}{i}{j-1} > \outfunc{G}{i'}{j_1}{i}{j-1}$ então \\
  $\outfunc{G}{i'}{j_2}{i}{j} > \outfunc{G}{i'}{j_1}{i}{j}$.
\end{itemize}
 
\label{prop:candidatelist}
\end{proposicao}
\begin{prova}
Sejam os vértices $(i',j_1)$, $(i',j_2)$ e $(i,j)$ de $G$, tais que $i' \leq 
i$, $j_1 < j_2 < j$.

Para facilitar o leitura da demonstração, vamos dizer que:
\begin{itemize}
  \item $\outfunc{G}{i'}{j_2}{i}{j} = a$
  \item $\outfunc{G}{i'}{j_2}{i}{j-1} = b$
  \item $\outfunc{G}{i'}{j_1}{i}{j} = c$
  \item $\outfunc{G}{i'}{j_1}{i}{j-1} = d$
\end{itemize}

% \begin{figure}[htbp] \centering 
% \includegraphics[width=0.6\textwidth,height=0.5\textwidth]{j2maiorj1}
% % \end{center}
% \caption{Caminhos que passam por $j_1$ e $j_2$ e chegam em $j-1$ e $j$}
%  \label{fig:j2maiorj1}
% \end{figure}
% 
% A Figura~\ref{fig:j2maiorj1} ilustra os caminhos que passam por $j_1$ e $j_2$ na
% linha $i'$ e chegam em $j-1$ e $j$.
% 
Seja $\overline{G}$ o \gred\ de 
$\invert{s}$ e $t$.

Pela Proposição~\ref{prop:difcrescentes}, sabemos que 
$$\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} \geq 
\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}.$$

Utilizando a Proposição~\ref{prop:outhdif}, substituímos os valores de 
$\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j}$ e 
$\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$ por $a-b$ e $c-d$, 
respectivamente, e obtemos $$a-b \geq c-d\textrm{, ou seja, }a-c \geq b-d.$$

Logo, se $$b \geq d \textrm{, ou seja, } b-d \geq 0 \textrm{, então } a-c \geq 
0 \textrm{, ou seja, } a \geq c \textrm{ e se }$$ $$b > d \textrm{, ou seja, } 
b-d > 0 \textrm{, então } a-c > 0 \textrm{, ou seja, } a > c.\cqd$$
\end{prova}

Com esta proposição podemos afirmar que uma coluna $j_1$, tal que $j_1 < j$, 
não poderá ser a coluna com o máximo $\outfunc{G}{i'}{j'}{i}{j}$, quando estão 
fixados $i'$, $i$ e $j$, se existir alguma outra coluna $j_2$ tal que $j_1 < 
j_2 < j$ e $\outfunc{G}{i'}{j_2}{i}{j-1} > \outfunc{G}{i'}{j_1}{i}{j-1}$.

A seguir, vamos descrever estruturas e dar definições que são relativas a 
um \gred\ estendido $G$ de $s$ e $t$ e a linhas fixas $i$ e $i'$ de $G$, tais 
que $0 \leq i' \leq i \leq n$

Portanto, para facilitar a leitura e não 
sobrecarregar nos índices das definições e notações, vamos supor que $G$ é um 
\gred\ estendido de $s$ e $t$ e que $i$ e $i'$ são linhas dadas de $G$,
tais que $i' \leq i$.

\begin{definicao}[Lista $\outlist{j}$] Fixadas as linhas $i$ e $i'$ de um 
\gred\ estendido $G$, diremos que, para uma dada coluna $j$ de $G$, 
$\outlist{j}$ é a lista com os valores de $\outfunc{G}{i'}{j'}{i}{j}$, para 
todo $j'$ tal que $0 \leq j' \leq j$.
\end{definicao}

Ou seja, dadas uma coluna $j$ e as linhas $i$ e $i'$ de $G$, $\outlist{j}$ é a 
lista com todos os valores de $\outfunc{G}{i'}{j'}{i}{j}$ que são diferentes de
$-\infty$.

\begin{definicao}[Candidato a máximo de $\outlist{j}$] Dada a coluna $j$ de 
$G$, diremos que $j_1$ tal que, $0 \leq j_1 \leq j$, é um candidato a máximo de 
$\outlist{j}$ se não existe outra coluna $j_2$ de $G$ tal que $j_1 < j_2 \leq 
j$ e $\outfunc{G}{i'}{j_2}{i}{j} \geq \outfunc{G}{i'}{j_1}{i}{j}$.
\end{definicao}

Repare que se $j_1$ é um candidato a máximo de $\outlist{j}$ e existe uma outra 
coluna $j_2$ tal que $\outfunc{G}{i'}{j_2}{i}{j} = \outfunc{G}{i'}{j_1}{i}{j}$ 
então $j_2 < j_1$ e $j_2$ não é um candidato a máximo de $\outlist{j}$. Logo, 
se $j_1$ é um candidato a máximo de $\outlist{j}$ tal que 
$\outfunc{G}{i'}{j_1}{i}{j}$ é máximo de $\outlist{j}$, então até pode existir 
uma outra coluna $j_2$ tal que $\outfunc{G}{i'}{j_2}{i}{j} = 
\outfunc{G}{i'}{j_1}{i}{j}$, porém neste caso $j_2 < j_1$.

\begin{definicao}[Lista de candidatos $\cl{j}$] Dada a coluna $j$ de $G$, 
diremos que $\cl{j}$ é a lista ordenada com todos os candidatos a máximo de 
$\outlist{j}$.
\end{definicao}

A seguir seguem algumas observações sobre a lista $\cl{j}$ decorrentes 
diretamente das definições da lista de candidatos $\cl{j}$ e do candidato a 
máximo de $\outlist{j}$.

\begin{observacao}
Seja $j_1$ tal que $j_1$ é o menor índice de coluna de $G$ candidato a máximo 
de $\outlist{j}$, ou seja, $j_1$ é o primeiro elemento de $\cl{j}$. Então 
$\outfunc{G}{i'}{j_1}{i}{j}$ é um máximo de $\outlist{j}$.
\end{observacao}

\begin{observacao}
Para toda coluna $j$ de $G$ temos que $j \in \cl{j}$.
\label{obs:jestaemLj}
\end{observacao}

\begin{observacao}
Se $j_1$ é tal que $j_1 \notin \cl{j}$ e $0 \leq j_1 < j$ então existe um 
índice de coluna $j_2$ tal que $j_2 \in \cl{j}$, $j_2 > j_1$ e 
$\outfunc{G}{i'}{j_2}{i}{j} \geq \outfunc{G}{i'}{j_1}{i}{j}$, pois, se $j_1 
\notin \cl{j}$ então existe pelo menos um índice de coluna $j_2$ tal que $j_2 > 
j_1$ e $\outfunc{G}{i'}{j_2}{i}{j} \geq \outfunc{G}{i'}{j_1}{i}{j}$, e pelo 
menos o maior dentre tais índices está em $\cl{j}$.
\label{obs:j2maiorj1emLj}
\end{observacao}

\begin{proposicao}
Dados $j$ e $j_1$, tais que $0 \leq j_1 < j \leq m$ temos que, se $j_1 \in 
\cl{j}$ então $j_1 \in \cl{j-1}$.
\label{prop:j1inclj-1}
\end{proposicao}
\begin{prova}
Sejam $j$ e $j_1$ tais que $j_1 \in \cl{j}$ e $0 \leq j_1 < j \leq m$.

Suponha por absurdo que $j_1 \notin \cl{j-1}$. Portanto, existe alguma coluna $j_2$ tal 
que $j_1 < j_2 \leq j-1$ e $\outfunc{G}{i'}{j_2}{i}{j-1} \geq 
\outfunc{G}{i'}{j_1}{i}{j-1}$. Pela Proposição~\ref{prop:candidatelist} então 
$\outfunc{G}{i'}{j_2}{i}{j} \geq \outfunc{G}{i'}{j_1}{i}{j}$, o que é uma 
contradição com a hipótese que $j_1$ é um candidato a máximo de 
$\outlist{j}$. Portanto a suposição que $j_1 \notin \cl{j-1}$ é falsa. \cqd
\end{prova}

Devido a esta proposição, sabemos que todos os candidatos a máximo de 
$\outlist{j}$, exceto o candidato $j$, são candidatos a máximo de 
$\outlist{j-1}$. 

Devido a Proposição~\ref{prop:j1inclj-1} e a Observação~\ref{obs:jestaemLj}, 
podemos fazer a observação a seguir.

\begin{observacao}
Sempre existe um e somente um novo elemento em $\cl{j}$ em relação à 
$\cl{j-1}$: o próprio $j$.
\label{obs:n3inserejclj}
\end{observacao}

Assim, para toda coluna $j_1$ de $G$, existe uma coluna $j_2$ de $G$ tal que:
\begin{itemize}
  \item $j_2 \geq j_1$,
  \item para todo $j$ tal que $j \in [j_1,j_2]$ temos que $j_1 \in \cl{j}$ e
  \item para todo $j'$ tal que $j' \in [0,j_1[$  $\cup$  $]j_2,m]$, temos que 
  $j_1 \notin \cl{j'}$.
\end{itemize}

A seguir vamos ver quais os candidatos a máximo de $\outlist{j-1}$ se mantêm 
candidatos a máximo de $\outlist{j}$.

\begin{lema}
Sejam as colunas $j$ e $j_1$ de $G$, tais que $0 < j \leq m$ e $j_1 \in 
\cl{j-1}$. Temos que, $j_1 \in \cl{j}$ se e somente se:
\begin{enumerate}
  \item não existe uma coluna $j_2$ de $G$ tal que $j_2 \in \cl{j-1}$, $j_2 > 
  j_1$ e $\outfunc{G}{i'}{j_2}{i}{j-1}-\outfunc{G}{i'}{j_1}{i}{j-1}+
  \hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} 
  -\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j} \geq 
  0$.\label{lema:candidateinclj:cond1}

\item $\outfunc{G}{i'}{j}{i}{j}-\outfunc{G}{i'}{j_1}{i}{j} < 0$.
\label{lema:candidateinclj:cond2}
\end{enumerate}
\label{lema:candidateinclj}
\end{lema}
\begin{prova}
Primeiro vamos provar que se as 
condições~\ref{lema:candidateinclj:cond1}~e~\ref{lema:candidateinclj:cond2} 
são satisfeitas então $j_1 \in \cl{j}$. Em seguida vamos provar que se  $j_1 
\in \cl{j}$ então as 
condições~\ref{lema:candidateinclj:cond1}~e~\ref{lema:candidateinclj:cond2} 
são satisfeitas.

Para facilitar a leitura da demonstração, vamos dizer que:
\begin{itemize}
  \item $\outfunc{G}{i'}{j_2}{i}{j} = a$
  \item $\outfunc{G}{i'}{j_2}{i}{j-1} = b$
  \item $\outfunc{G}{i'}{j_1}{i}{j} = c$
  \item $\outfunc{G}{i'}{j_1}{i}{j-1} = d$
\end{itemize}
\begin{enumerate}
  \item Se as 
  condições~\ref{lema:candidateinclj:cond1}~e~\ref{lema:candidateinclj:cond2} 
  são satisfeitas então $j_1 \in \cl{j}$.
  
  Suponha que as 
  condições~\ref{lema:candidateinclj:cond1}~e~\ref{lema:candidateinclj:cond2} 
  são satisfeitas.
  
  Como $j_1 \in \cl{j-1}$ então $j_1 < j$ e portanto para que $j_1 \in \cl{j}$ 
  é necessário demonstrar que não existe $j_2$ tal que $a \geq c$ e $j_1 < j_2 
  \leq j$.
  
  Vamos dividir a demonstração em duas partes e demonstrar que para todo $j_2$ 
  tal que $j_2 \in ]j_1, j[$ temos que $a < c$, e que para $j_2=j$ temos que $a 
  < c$.
\begin{enumerate}
  \item não existe $j_2$ em $]j_1, j[$ tal que $a \geq c$.
  
  Pela condição~\ref{lema:candidateinclj:cond1} não existe uma coluna $j_2$ tal 
  que $j_2 \in \cl{j-1}$, $j_2 > j_1$ e $$b-d+
  \hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} 
  -\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j} \geq 0.$$ Utilizando a 
  Proposição~\ref{prop:outhdif} temos que: $$b-d+ a-b -(c-d) \geq 0\textrm{, ou 
  seja, } a - c \geq 0.$$ Portanto não existe uma coluna $j_2$ tal que $j_2 \in 
  \cl{j-1}$, $j_2 >  j_1$ e $a \geq c$.
  
%   Precisamos agora demonstrar que não existe uma coluna $j_2$ tal que $j_2 
%   \notin \cl{j-1}$, $j_1 < j_2 < j$ e $a \geq c$.
%   
  Agora, suponha por absurdo que existe um $j_2$ tal que $j_2 \notin \cl{j-1}$,
  $j_1 < j_2 < j$ e $a \geq c$.
  
  Sabemos pela Observação~\ref{obs:jestaemLj} que $j-1 \in \cl{j-1}$. Como $j_2 
  \notin \cl{j-1}$ temos que $j_2\neq j-1$ e portanto $j_2 < j-1$ e, pela 
  Observação~\ref{obs:j2maiorj1emLj}, existe uma coluna $j_3$ de $G$ tal que 
  $j_3 \in \cl{j-1}$, $j_3 > j_2$ e $\outfunc{G}{i'}{j_3}{i}{j-1} \geq b$.

  Como  $a \geq c$ temos que $$a - c \geq 0 \textrm{, ou seja, } a-c+b-b+d-d 
  \geq 0 \textrm{, ou seja, }$$ $$b-d+
  \hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} 
  -\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j} \geq 0.$$
  
  Como $j_3 > j_2 >j_1$ e $\outfunc{G}{i'}{j_3}{i}{j-1} \geq b$, temos que 
  $\outfunc{G}{i'}{j_3}{i}{j-1}-d+
  \hdiffunc{\overline{G}}{n-i}{j_3}{n-i'}{j} 
  -\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j} \geq 0.$ Porém, isto é uma 
  contradição com a condição \ref{lema:candidateinclj:cond1} e portanto 
  não existe $j_2$ tal que $j_2 \notin \cl{j-1}$, $j_1 < j_2 < j$ e $a \geq c$.
  
  \item se $j_2=j$ então $a < c$.
  
  Devido a condição~\ref{lema:candidateinclj:cond2}, temos que $$a-c < 
  0.$$
  
  Portanto, se $j_2=j$ temos que $a < c$.
\end{enumerate}
  \item Se $j_1 \in \cl{j}$ então as 
  condições~\ref{lema:candidateinclj:cond1}~e~\ref{lema:candidateinclj:cond2} 
  são satisfeitas.
  
  Seja $j_1$ tal que $j_1 \in \cl{j}$, ou seja, pela definição de  
  candidato a máximo de $\outlist{j}$, temos que, não existe outra coluna $j_2$
  de $G$ tal que $j_1 < j_2 \leq j$ e $\outfunc{G}{i'}{j_2}{i}{j} \geq 
  \outfunc{G}{i'}{j_1}{i}{j}$.
  
  Portanto a condição~\ref{lema:candidateinclj:cond2} é satisfeita.
  
  Utilizando a Proposição~\ref{prop:outhdif} e a definição de candidato 
  a máximo de $\outlist{j}$, podemos dizer que não existe outra coluna $j_2$ de 
  $G$ tal que $j_1 < j_2 < j$ e $$b + 
  \hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} \geq d + 
  \hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}\textrm{, ou seja, } $$ $$b + 
  \hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} - d - 
  \hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}\geq 0.$$
  
    Portanto a condição~\ref{lema:candidateinclj:cond1} também é 
    satisfeita. \cqd

\end{enumerate}
\end{prova}

Devido a este lema, podemos afirmar que conseguimos obter a lista $\cl{j}$ a
partir da lista $\cl{j-1}$ fazendo apenas verificações de 
diferenças de $\outsym{G}$ e de diferenças de $\hdifsym{\overline{G}}$.

Repare que se $j_1$ e $j_2$ são duas colunas de $G$ tais que $j_1 \in 
\cl{j-1}$, $j_2 \in \cl{j-1}$, $j_1 < j_2$ e 
$\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j}=\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$ 
então $\outfunc{G}{i'}{j_2}{i}{j} < \outfunc{G}{i'}{j_1}{i}{j}$ e $j_2$ não 
é uma coluna tal que a condição~\ref{lema:candidateinclj:cond1} do 
Lema~\ref{lema:candidateinclj} é falsa.

\begin{observacao}
Para encontrar um $j_2$ que torne a condição~\ref{lema:candidateinclj:cond1} do 
Lema \ref{lema:candidateinclj} falsa é necessário que 
$\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} \neq 
\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$. Logo, é necessário que haja pelo 
menos uma coluna $j_3$ tal que $j_3 \in \blhvec{\overline{G}}{n-i}{n-i'}{j}$ e 
$j_1 < j_3 \leq j_2$.
\label{obs:j2inblhvec}
\end{observacao}

% \begin{observacao}
% Sejam $j_1$ e $j_2$ dois índices que estão em $\cl{j-1}$ e $j_3$ um índice de
% $t$ tais que, $j_1 < j_2 < j_3$ e $\outfunc{G}{i'}{j_2}{i}{j-1}+\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j}< 
% \outfunc{G}{i'}{j_1}{i}{j-1} + \hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$.
% 
% Sejam $j_1$ e $j_2$ dois índices que estão em $\cl{j-1}$ em posições 
% consecutivas e $j_1 < j_2$ , ou seja, não existe um $j_3$ em $\cl{j-1}$ tal que 
% $j_1 < j_3 < j_2$. Se $j_2 \in \cl{j}$ e 
% $\outfunc{G}{i'}{j_2}{i}{j-1}+\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j}< 
% \outfunc{G}{i'}{j_1}{i}{j-1} + \hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$ 
% então $j_1 \in \cl{j}$.
% \label{obs:n3j1j2consecutivos}
% \end{observacao}

% \begin{definicao}[Vetor $CL_{i'}^{i,j}$]  Dados $i'$, $i$ e $j$ tais que $0 
% \leq i' \leq i \leq n$ e $0 \leq j \leq m$ definimos $CL_{i'}^{i,j}$ como um 
% vetor tal que $CL_{i'}^{i,j}[\beta]$ é igual ao $\beta$-ésimo $j'$, tal que $0 
% \leq j' \leq j$ , onde $Out_{i'}^{i}[j',j] > Out_{i'}^{i}[j'',j]\ \forall\ j''\ 
% \tq\ j'<j''\leq j$.
% \end{definicao}
% 
% \begin{definicao}[Vetor $\Delta C_{i'}^{i,j}$]  Dados $i'$, $i$ e $j$ tais 
% que $0 \leq i' \leq i \leq n$ e $0 \leq j \leq m$ definimos 
% $\Delta C_{i'}^{i,j}$ como um vetor tal que 
% $\Delta C_{i'}^{i,j}[\beta]=Out_{i'}^{i}[CL_{i'}^{i,j}[\beta],j] 
% - Out_{i'}^{i}[CL_{i'}^{i,j}[\beta-1],j]$ para  $0 < \beta \leq 
% |CL_{i'}^{i,j}|$ e 
% $\Delta C_{i'}^{i,j}[0]=Out_{i'}^{i}[CL_{i'}^{i,j}[0],j]$.
% \end{definicao}

% \TODO figura \difoutsym{G}

A seguir iremos definir a função parcial \difoutsym{G}, que representa as 
diferenças $\outfunc{G}{i'}{j_2}{i}{j}-\outfunc{G}{i'}{j_1}{i}{j}$ para cada 
dois elementos consecutivos $j_1$ e $j_2$ de $\cl{j}$. Se $j_2$ é o primeiro 
elemento da lista $\cl{j}$, então assumimos que existe um fictício elemento 
$j_1$ em $\cl{j}$ tal que $\outfunc{G}{i'}{j_1}{i}{j}=0$ e $j_1 < j_2$.

Dizemos que o elemento $j_1$ é o \emph{antecessor de $j_2$ em \cl{j}} se $j_1 < 
j_2$, $j_1 \in \cl{j}$ e não existe uma coluna $j_3$ de $G$ tal que $j_1 < j_3 
< j_2$ e $j_3 \in \cl{j}$.

\begin{definicao}[Função \difoutsym{G}] Dado um \gred\ estendido 
$G=(V,E,\egweigsym)$ de $s$ e $t$, a função parcial $\difoutsym{G}:V \times V 
\rightarrow \realset$ é definida por
\begin{enumerate}
  \item $\difoutfunc{G}{i'}{j_2}{i}{j} = \outfunc{G}{i'}{j_2}{i}{j} - 
  \outfunc{G}{i'}{j_1}{i}{j},$ se $i' \leq i$, $j_2 \in \cl{j}$ e $j_2$ não é o 
  primeiro elemento de $\cl{j}$, onde $j_1$ é o antecessor de $j_2$ em \cl{j};
  \item $\difoutfunc{G}{i'}{j_1}{i}{j} = \outfunc{G}{i'}{j_1}{i}{j},$ se $i' 
  \leq i$ e $j_1$ é o primeiro elemento de $\cl{j}$.
\end{enumerate}
\end{definicao}

\begin{observacao}
Se $j_1 \in \cl{j}$, $j_2 \in \cl{j}$ e $j_2 > j_1$, então 
$$\outfunc{G}{i'}{j_2}{i}{j}-\outfunc{G}{i'}{j_1}{i}{j}=\sum_{j_3\in \cl{j}, 
j_1 < j_3\leq j_2}\difoutfunc{G}{i'}{j_3}{i}{j}.$$
\label{obs:n3somadifout}
\end{observacao}

Sabemos que $\outfunc{G}{i'}{j_2}{i}{j}-\outfunc{G}{i'}{j_1}{i}{j}<0$, para 
cada dois elementos consecutivos $j_1$ e $j_2$ de $\cl{j}$, logo, para todo 
$j_2$ tal que $j_2 \in \cl{j}$ e $j_2$ não é o primeiro elemento de \cl{j} 
temos que \difoutfunc{G}{i'}{j_2}{i}{j} é negativo.

Repare que existem sempre $|\cl{j}|$ valores válidos de 
$\difoutfunc{G}{i'}{j_2}{i}{j}$ quando $i'$, $i$ e $j$ são fixos.

De acordo com a Observação~\ref{obs:n3difoutigualdifhdif} e a definição de
\difoutsym{G}, podemos fazer a observação a seguir.

\begin{observacao}
Sejam $j$, $j_1$ e $j_2$ tais que, $0 \leq j_1 < j_2 < j$, $j_1 \in \cl{j}$, 
$j_2 \in \cl{j}$ e $j_1$ é o antecessor de $j_2$ em $\cl{j}$. Temos que 
$\difoutfunc{G}{i'}{j_2}{i}{j}=
\difoutfunc{G}{i'}{j_2}{i}{j-1}+ \hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} 
-\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$.
\label{obs:n3difoutj2blh}
\end{observacao}

Portanto, o valor de
\difoutfunc{G}{i'}{j_2}{i}{j} é diferente de \difoutfunc{G}{i'}{j_2}{i}{j-1}
quando existe pelo menos um elemento $j_3$ contido em $\blhvec{G}{i'}{i}{j}$ tal que $j_1 
< j_3 \leq j_2$ e $j_1$ é o antecessor de $j_2$ na lista \cl{j}.

De acordo com a definição de \difoutsym{G} e com a
Observação~\ref{obs:n3somadifout} podemos fazer a seguinte observação para o
cálculo do primeiro elemento de \difoutsym{G}.

\begin{observacao}
Sejam $j$ e $j_2$ tais que, $0 \leq j_2 < j$, $j_2 \in \cl{j}$ e $j_2$ é o 
primeiro elemento de $\cl{j}$. Temos que \\
$\difoutfunc{G}{i'}{j_2}{i}{j}=\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j}+$ $$
\sum_{j_1 \tq j_1 \in \cl{j-1}, j_1 \leq j_2} \difoutfunc{G}{i'}{j_1}{i}{j-1}.$$
\label{obs:n3difoutj2max}
\end{observacao}

Para o cálculo de \difoutfunc{G}{i'}{j}{i}{j} usaremos a seguinte observação.

\begin{observacao}
Para todo $j$ tal que $1 \leq j \leq m$ temos que 
$\outfunc{G}{i'}{j}{i}{j}-\outfunc{G}{i'}{j-1}{i}{j}= \outfunc{G}{i'}{j}{i}{j}- 
\hdiffunc{\overline{G}}{n-i}{j-1}{n-i'}{j}- \outfunc{G}{i'}{j-1}{i}{j-1}$.
\label{obs:n3difoutj}
\end{observacao}

% \begin{definicao}[Lista \difoutvec{j}] Fixados o \gred\ estendido $G$ de $s$ e
% $t$ e as linhas $i$ e $i'$ de $G$, tais que $i' \leq i$, defimos o vetor
% $\difoutvec{j}$ de comprimento $m$ tal que $\difoutvec{j}[j_1]=
% \difoutfunc{G}{i'}{j_1}{i}{j}$, se $j_1 \in \cl{j}$ e $\difoutvec{j}[j_1]=-1$ se
% $j_1 \notin \cl{j}$.
% \end{definicao}

% 
% Sejam as colunas $j$, $j_1$ e $j_2$ de $G$ tais que, $j_1 < j_2 \leq j$, $j_1 
% \in \cl{j-1}$ e, $j_2 \in \cl{j-1}$ ou $j_2=j$. Diremos que $j_2$ \emph{domina} 
% $j_1$ em $j$ se $\outfunc{G}{i'}{j_2}{i}{j} \geq \outfunc{G}{i'}{j_1}{i}{j} = 
% \outfunc{G}{i'}{j_1}{i}{j-1}+\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$.
% 
% Sejam $j$, $j_1$ e $j_2$ tais que, $0 \leq j_1 < j_2 \leq j \leq m$, $j_2 \in 
% \cl{j-1}$, $j_1 \in \cl{j-1}$ e $\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} = 
% \hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$. Temos que $j_2$ não domina $j_1$.
% 
% \begin{observacao}
% Sejam $j_1$ e $j_2$ tais que $j_1 \in \cl{j-1}$, $j_2 \in \cl{j-1}$, $j_1 < j_2$ e
% não existe $j_3$ tal que $j_1 < j_3 < j_2$ e $j_3 \in \cl{j-1}$. Se $j_2 \notin
% \blhvec{j}$ então todo $j_4$ consumido por $j_2$ também é consumido por $j_1$. 
% \end{observacao}
% 
% Ou seja, para todo $j_2 \in \cl{j-1}$, somente são consumidos $j_1$ por $j_2$ se
% $j_2 \in \blhvec{j}$ ou se $j_1$ é consumido por algum
% 
% Até aqui está quase tudo pronto. Daqui em diante, ainda muita coisa vai mudar\ldots

 % Portanto, para
% obtermos os $j_1$
% tais que $j_1 \in \cl{j-1}$ e $j_1 \notin \cl{j}$, ou seja, os $j_1$ consumidos
% por algum $j_2$ em $\cl{j-1}$, precisamos analisar somente os $j_2$ tais que

% \begin{definicao}[Função $\blhsym{G}$] Dado um \gred\ $G=(V,E,\egweigsym)$ de 
% $s$ e $t$, a função parcial $\blhsym{G}:\natset \times V \times \natset 
% \rightarrow \natset \}$ é definida por $$\blhfunc{G}{i'}{i}{j}{k} = j' 
% \textrm{, }$$ se $0 \leq k \leq \psihfunc{G}{i'}{i}{j}-1$ e $0 \leq i' \leq i$, 
% onde $j'$ é tal que, $\hdiffunc{G}{i'}{j'}{i}{j} \neq 
% \hdiffunc{G}{i'}{j'-1}{i}{j}$ e existem $k$ outros índices $j''$ distintos tais 
% que, $1 \leq j'' < j'$  e $\hdiffunc{G}{i'}{j''}{i}{j} \neq 
% \hdiffunc{G}{i'}{j''-1}{i}{j}$.
% \label{def:blh}
% \end{definicao}

% Repare que, para todo $j_1$ e $j_2$ tais que, $j_1 \in \cl{j-1}$, $j_2 \in 
% \cl{j-1}$ e $j_2 > j_1$, temos que 
% $\outfunc{G}{i'}{j_2}{i}{j-1}-\outfunc{G}{i'}{j_1}{i}{j-1}<0$. Portanto a 
% condição~\ref{lema:candidateinclj:cond1} do Lema~\ref{lema:candidateinclj} 
% somente será verdadeira se $\hdiffunc{\overline{G}}{n-i}{j_2}{n-i'}{j} 
% -\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j} > 0$.
% 
% Pelas Observações~\ref{obs:n3j1j2consecutivos}~e~\ref{obs:n3somadifout}, temos 
% que a condição~\ref{lema:candidateinclj:cond1} do 
% Lema~\ref{lema:candidateinclj} pode ser verificada para cada elemento $j_1 \in 
% \cl{j-1}$, utilizando-se o vetor $\difoutvec{j-1}$ e os valores de 
% $\hdiffunc{\overline{G}}{n-i}{j_1}{n-i'}{j}$ para cada elemento $j_1$ de 
% $\blhvec{j}$.



% \begin{definicao}[Vetor $\Delta H_{i'}^{i,j}$] Dados $i'$, $i$ e $j$ tais que $0 
% \leq i' \leq i \leq n$ e $0 \leq j \leq m$, definimos o vetor $\Delta H_{i'}^{i,j}$  
% de comprimento $\psi H_{i'}^{i,j}$ tal que 
% $\Delta H_{i'}^{i,j}[\alpha]=hDif_{i'}^{i,j}[BLH_{i'}^{i,j}[\alpha]]$.
% \end{definicao}

% Assim, para cada índice $\alpha$ de $BLH_{i'}^{i,j}$ criamos um 
% elemento $\Delta H_{i'}^{i,j}[\alpha]$. Podemos dizer que em 
% $BLH_{i'}^{i,j}$ armazenamos os $j'$ onde houve aumento do valor de 
% $hDif_{i'}^{i,j}$ e em $\Delta H_{i'}^{i,j}$ o novo valor de $hDif_{i'}^{i,j}$.
% 
% De forma análoga, a partir de $vDif_{i'}^{i,j}$ definimos os vetores 
% $BLV_{i'}^{i,j}$ e $\Delta V_{i'}^{i,j}$.

% A seguir iremos definir uma lista que contém os candidatos a serem máximos de
% colunas de $Out_{i'}^{i}$.

O Algoritmo~\ref {alg:obtemMaxOut} obtém, para $i$ e $i'$ fixos tais que $0 
\leq i \leq i' \leq n$, o máximo da lista $\outlist{j}$ para cada $j$ tal que, 
$0 \leq j \leq m$ e funciona como descrito a seguir.


\begin{algorithm}[htbp]
\begin{algo}{obtémMaxOut}{BL, OUT_G}
\COM{$OUT_G[j]=B[i',j]+\egweigpi{(n-i,j)}{(n-i',j)}$}
\COM{$BL[j].\psi = \psihfunc{\overline{G}}{n-i}{n-i'}{j}$}
\COM{$BL[j].j'[\alpha] = \blhvec{j}[\alpha]$} 
\COM{$BL[j].\hdifsym{\overline{G}}[\alpha] = \hdiffunc{\overline 
G}{n-i}{\blhvec{j}[\alpha]}{n-i'}{j}$}
\COM{Coloca o zero na lista de candidatos}
\ACT{CL.add(0)} \label{alg:obtemMaxOut:cl0}
\SET{\difoutsym{G}[0]}{OUT_G[0]} \label{alg:obtemMaxOut:difout0}
\SET{maxOut[0]}{\difoutsym{G}[0]} \label{alg:obtemMaxOut:maxout0}
\DOFORI{j}{1}{m} \label{alg:obtemMaxOut:loopj}
	\SET{\alpha}{0}\label{alg:obtemMaxOut:loopj:inicio}
	\SET{\hdifsym{\overline{G}}Prev}{0}
	\DOWHILE {\alpha < BL[j].\psi}\label{alg:obtemMaxOut:loopalpha}
		\COM{Obtém o menor $j_1$ em $CL$ tal que $j_1 \geq BL[j].j'[\alpha]$}
		\SET{j_1}{CL.find(BL[j].j'[\alpha])}
		\DOWHILE{\alpha < BL[j].\psi-1$ e $CL.find(BL[j].j'[\alpha+1])=j_1} \label{alg:obtemMaxOut:loopalpha1}
			\SET{\alpha}{\alpha+1}
		\OD
		\COM{\difoutsym{G}[j_1]=\difoutfunc{G}{i'}{j_1}{i}{j}}
		\SET{\difoutsym{G}[j_1]}{\difoutsym{G}[j_1]+ 
			BL[j].\hdifsym{\overline{G}}[\alpha]-
			\hdifsym{\overline{G}}Prev} \label{alg:obtemMaxOut:setadifoutj1}
		\DOWHILE {(\difoutsym{G}[j_1] \geq 0)$ e $(j_1 \neq CL.first())} \label{alg:obtemMaxOut:loopremovej2cond1}
			\SET{j_2}{CL.previous(j_1)}
			\ACT{CL.remove(j_2)}\label{alg:obtemMaxOut:removej2cond1}
			\SET{\difoutsym{G}[j_1]}{\difoutsym{G}[j_1]+\difoutsym{G}[j_2]} 
			    \label{alg:obtemMaxOut:atualizadifoutj1} 
		\OD
		\SET{\hdifsym{\overline{G}}Prev}{BL[j].\hdifsym{\overline{G}}[\alpha]} 
		\SET{\alpha}{\alpha+1}
	\OD

	\COM{Insere $j$ na lista de candidatos}
	\ACT{CL.add(j)} \label{alg:obtemMaxOut:Addj}
	\COM{Obtém $\difoutsym{G}[j]$}
	\SET{\difoutsym{G}[j]}{OUT_G[j]-BL[j].\hdifsym{\overline{G}}[\alpha-1]- 
		OUT_G[j-1]} \label{alg:obtemMaxOut:setadifoutj}
	\DOWHILE {(\difoutsym{G}[j] \geq 0)$ e $(j \neq CL.first())}\label{alg:obtemMaxOut:loopremovej2cond2}
		\SET{j_2}{CL.previous(j)}
		\ACT{CL.remove(j_2)}\label{alg:obtemMaxOut:removej2cond2}
		\SET{\difoutsym{G}[j]}{\difoutsym{G}[j]+\difoutsym{G}[j_2]} \label{alg:obtemMaxOut:atualizadifoutj}
	\OD

	\SET{maxOut[j]}{\difoutsym{G}[CL.first()]}\label{alg:obtemMaxOut:setmaxoutj}
\OD\label{alg:obtemMaxOut:loopj:fim}
\RETURN{maxOut}
  \caption[obtemMaxCol]{Obtém o máximo de $\outlist{j}$ para cada $j$}
  \label{alg:obtemMaxOut}
\end{algo}
\end{algorithm}

O Algoritmo~\ref{alg:obtemMaxOut} considera que as linhas $i$ e $i'$ do \gred\
estendido $G$ de $s$ e $t$ estão fixas.

O algoritmo constrói a lista de candidatos $CL$ para cada $j$ de $0$ a $m$ e 
mantém um vetor $\difoutsym{G}$ de tal forma que, para um dado $j$, cada valor 
válido de \difoutfunc{G}{i'}{j_1}{i}{j} está em $\difoutsym{G}[j_1]$. No 
algoritmo, o vetor $maxOut$ contém os valores máximos de $\outlist{j}$ e será 
devolvido pelo algoritmo.

Quando $j=0$ a lista $\cl{j}$ contém somente um elemento, que é o zero 
(linha~\ref{alg:obtemMaxOut:cl0}). O valor de $\difoutfunc{G}{i'}{0}{i}{0}$ é 
$\outfunc{G}{i'}{0}{i}{0}$ que é igual a $B[i',0]+\egweigpi{(n-i,0)}{(n-i',0)}$ 
(linha~\ref{alg:obtemMaxOut:difout0}). Portanto, o máximo de $\outlist{0}$ é 
$\outfunc{G}{i'}{0}{i}{0}$ (linha~\ref{alg:obtemMaxOut:maxout0}).

Durante a execução dos comandos das linhas \ref{alg:obtemMaxOut:loopj:inicio} a 
\ref{alg:obtemMaxOut:loopj:fim} que estão dentro do laço da 
linha~\ref{alg:obtemMaxOut:loopj}, a lista $\cl{j}$ é obtida usando a lista 
$\cl{j-1}$ e os valores válidos de \difoutfunc{G}{i'}{j_1}{i}{j} são
atualizados em $\difoutsym{G}$. Além disso, após a construção da lista $\cl{j}$
e de atualizar $\difoutsym{G}$, o último comando dentro deste laço
(linha \ref{alg:obtemMaxOut:setmaxoutj}) coloca em $maxOut$ o valor máximo de
$\outlist{j}$. 

% Para obter $\cl{j}$ a partir de $\cl{j-1}$ e atualizar os valores válidos de 
% \difoutfunc{G}{i'}{j_1}{i}{j} no vetor $\difoutsym{G}$, a 
% Proposição~\ref{prop:n3difoutj2blh} e a Observação~\ref{obs:j2inblhvec} dizem 
% que precisamos analisar somente os valores $j_2$ em \cl{j-1} tais que existam 
% pelo menos um elemento $j_3$ contido em $\blhvec{j}$, onde $j_1 < j_3 \leq j_2$ 
% e $j_1$ é o antecessor de $j_2$ na lista \cl{j-1}.
% 
A seguir vamos dar uma breve explicação de como a lista $\cl{j}$ é construída e 
como $\difoutsym{G}$ é atualizado dentro dos comandos que estão dentro do laço 
da linha~\ref{alg:obtemMaxOut:loopj}.

A lista $\cl{j}$ é construída da seguinte forma:
\begin{itemize}
  \item Na linha~\ref{alg:obtemMaxOut:Addj} do algoritmo é inserida a coluna $j$ na 
  lista $\cl{j-1}$, que de acordo com a observação~\ref{obs:n3inserejclj} é a 
  única coluna que deve ser inserida na lista $\cl{j-1}$ para obter a lista 
  $\cl{j}$.
  \item A linha~\ref{alg:obtemMaxOut:removej2cond1} do algoritmo remove as colunas 
  de $\cl{j-1}$ que tornam a condição~\ref{lema:candidateinclj:cond1} do 
  Lema~\ref{lema:candidateinclj} falsa.
  \item A linha~\ref{alg:obtemMaxOut:removej2cond2} do algoritmo remove as colunas 
  de $\cl{j-1}$ que tornam a condição~\ref{lema:candidateinclj:cond2} do 
  Lema~\ref{lema:candidateinclj} falsa.
\end{itemize}
  
Os valores de \difoutfunc{G}{i'}{j_1}{i}{j} são alterados no vetor 
$\difoutsym{G}$, para cada $j_1 \in \cl{j}$, nas linhas 
\ref{alg:obtemMaxOut:setadifoutj1}, \ref{alg:obtemMaxOut:atualizadifoutj1}, 
\ref{alg:obtemMaxOut:setadifoutj} e \ref{alg:obtemMaxOut:atualizadifoutj}, de acordo 
com as observações \ref{obs:n3somadifout}, \ref{obs:n3difoutj2blh}, 
\ref{obs:n3difoutj2max} e \ref{obs:n3difoutj}.

A lista de candidatos $CL$ pode ser implementada como uma lista ligada, de tal 
forma que as operações de remoção de um elemento ($CL.remove()$), inclusão de 
um novo elemento ($CL.add()$) e obtenção do elemento anterior a um elemento da 
lista ($CL.previous(j_1)$) podem ser executadas em tempo constante. Além disto, 
utilizando uma estrutura do tipo \emph{disjoint sets} para armazenar os 
elementos da lista de candidatos, podemos realizar $k$ operações de 
inclusão(\emph{make-set}), de remoção (\emph{union}) e de encontrar 
(\emph{find}) na lista de candidatos em tempo $O(k)$, se utilizarmos o 
algoritmo proposto por~\cite{808753}\footnote{Na implementação que realizamos 
do algoritmo, utilizamos a estrutura clássica descrita em \cite{580470} que tem 
tempo de execução $O(\alpha(k))$, sendo $\alpha$ a função inversa de 
Ackermann.}. Portanto, qualquer operação na lista de candidatos pode ser
executada em tempo amortizado constante.

Portanto, qualquer linha do algoritmo pode ser executada em tempo constante.

A linha~\ref{alg:obtemMaxOut:loopj} é executada $m$ vezes. 

Para cada $j$ de $1$ a $m$ o número de vezes que a linha
\ref{alg:obtemMaxOut:loopalpha} é executada mais o número de vezes que a linha 
e \ref{alg:obtemMaxOut:loopalpha1} é executada é igual ou menor a
$2\psihfunc{\overline{G}}{n-i}{n-i'}{j}+1$, ou seja, estas linhas são executadas
$O(m)$ vezes. 

O número de remoções dos candidatos da lista $CL$ é igual ou menor a $m$. 
Portanto, o número de vezes que a linha \ref{alg:obtemMaxOut:removej2cond1} é 
executada mais o número de vezes que a linha 
\ref{alg:obtemMaxOut:removej2cond2} é executada é igual ou menor a $m$.

O espaço consumido pelo algoritmo é composto pela lista $CL$ e pelos vetores 
$\difoutsym{G}$ e $maxOut$, os quais consomem espaço $O(m)$, e por algumas 
variáveis com espaço constante.

Assim o Algoritmo~\ref{alg:obtemMaxOut} executa em tempo e espaço $O(m)$.

% Invariante: após a execução da linha~\ref{alg:obtemMaxOut:loopj} a lista de
% candidatos $CL$ é a lista $\cl{j-1}$ e os valores válidos
% de \difoutfunc{G}{i'}{j_1}{i}{j-1} estão no vetor $\difoutsym{G}$.
% 
% Na primeira vez que a linha~\ref{alg:obtemMaxOut:loopj} é executada o valor de 
% $j$ é 1 (um) e a invariante é verdadeira pois: a linha~\ref{obtemMaxOut:cl0}
% coloca em $CL$ o valor zero, que é o único elemeno em $\cl{0}$; e a linha 
% \ref{obtemMaxOut:difout0} coloca o único valor válido de 
% \difoutfunc{G}{i'}{j_1}{i}{0} em $\difoutsym{G}[0]$.
% 
% Nas próximas execuções da linha~\ref{alg:obtemMaxOut:loopj} a lista $\cl{j-1}$ 
% e os valores válidos de \difoutfunc{G}{i'}{j_1}{i}{j-1} são construídos pelos 
% comandos que estão dentro do laço da linha~\ref{alg:obtemMaxOut:loopj},
% executados no valor anterior de $j$ ($j-1$).
% 
% Durante a execução dos comandos das linhas \ref{alg:obtemMaxOut:loopj:inicio} a 
% \ref{alg:obtemMaxOut:loopj:fim} que estão dentro do laço da 
% linha~\ref{alg:obtemMaxOut:loopj}, a lista $\cl{j}$ é obtida usando a lista 
% $\cl{j-1}$. Na linha~\ref{obtemMaxOut:Addj} do algoritmo é inserida a coluna 
% $j$ na lista $\cl{j-1}$, que de acordo com a observação~\ref{obs:n3inserejclj} 
% é a única coluna que deve ser inserida na lista $\cl{j-1}$ para obter a lista 
% $\cl{j}$. A linha~\ref{obtemMaxOut:removej2cond1} do algoritmo remove as 
% colunas de $\cl{j-1}$ que tornam a 
% condição~\ref{lema:candidateinclj:cond1} do Lema~\ref{lema:candidateinclj} 
% falsa, assim como a linha~\ref{obtemMaxOut:removej2cond2} do algoritmo remove 
% as colunas de $\cl{j-1}$ que tornam a 
% condição~\ref{lema:candidateinclj:cond2} do Lema~\ref{lema:candidateinclj} 
% falsa.
% 
% 
%  e é
% garantida ser a lista $\cl{j-1}$ pelo Lema~\ref{lema:candidateinclj}
% 

% A partir de agora, descreveremos como funciona o 
% Algoritmo~\ref{alg:obtemMaxCol}. Daremos um esboço da análise de sua 
% complexidade sem no entanto demonstrar a sua corretude.
% 
% Dados $BLH_{i'}^{i,j}$ e $\Delta H_{i'}^{i,j}$ o algoritmo obtém os vetores
% $CL_{i'}^{i,j}$ e $\Delta C_{i'}^{i,j}$ para cada
% $j$ tal que $0 \leq j \leq m$. Pela definição de $CL_{i'}^{i,j}$ o
% elemento $CL_{i'}^{i,j}[0]$  é o índice do máximo da coluna $j$ de
% $Out_{i'}^{i}$ e $\Delta C_{i'}^{i,j}[0]$ é o seu valor máximo. 
% 
% Para obter os vetores $CL_{i'}^{i,j}$ e
% $\Delta C_{i'}^{i,j}$ o algoritmo se baseia no fato de que um elemento
% $BLH_{i'}^{i,j}[\alpha]=j'$ reflete um aumento no valor de
% $Out_{i'}^{i}[j',j]$ em
% relação a $Out_{i'}^{i}[j',j-1]$, assim como para todo $j''$ tal que $j' < j''
% < j$. 
%  
% Logo, para cada $BLH_{i'}^{i,j}[\alpha]$ (linha~\ref{obtemMaxCol:loopAlpha}),  
% os vetores $CL_{i'}^{i,j}$ e $\Delta C_{i'}^{i,j}$ são atualizados como 
% descrito a seguir. Seja $CL_{i'}^{i,j}[\beta]$ tal que $CL_{i'}^{i,j}[\beta -1] 
% < BLH_{i'}^{i,j}[\alpha] \leq CL_{i'}^{i,j}[\beta] < j$. O valor de $\Delta 
% C_{i'}^{i,j}[\beta]$, que é negativo, deve ser aumentado por $\Delta 
% H_{i'}^{i,j}[\alpha]$. Se $\Delta C_{i'}^{i,j}[\beta]$ for maior ou igual a 
% zero o elemento $\beta -1$ deve ser removido da lista de candidatos, pois 
% $Out_{i'}^{i}[CL_{i'}^{i,j}[\beta],j] \geq 
% Out_{i'}^{i}[CL_{i'}^{i,j}[\beta-1],j]$ não está de acordo com a definição do 
% vetor $CL_{i'}^{i,j}$. Já que o candidato $\beta -1$ foi removido, o valor de 
% $\Delta C_{i'}^{i,j}[\beta]$ deve ser acrescido do valor $\Delta 
% C_{i'}^{i,j}[\beta-1]$, o qual também é removido do vetor $\Delta 
% C_{i'}^{i,j}$. O processo é repetido até que $\Delta C_{i'}^{i,j}[\beta]$ seja 
% negativo ou $\beta$ seja o primeiro elemento da lista de candidatos, ou seja, 
% este processo é executado no máximo $m$ vezes e portanto tem custo amortizado 
% $O(1)$.
% 
% Nas linhas~\ref{obtemMaxCol:inicioAddj} a~\ref{obtemMaxCol:fimAddj}, para cada
% $j$ é acrescentado o índice $j$ como último candidato da lista
% $CL_{i'}^{i,j}$ e $Out_{i'}^{i}[j,j] 
% - Out_{i'}^{i}[j-1,j]$ na lista correspondente
% $\Delta C_{i'}^{i,j}$.

\begin{algorithm}[htbp]
\begin{algo}{BimN3}{s,t}
 	\COM{$G=(V,E,\egweigsym)$ é o \gred\ estendido de $s$ e $t$ e}
 	\COM{$\overline{G}=(V,\overline{E},\egweigsymi)$ o \gred\ de $\overline{s}$ e $t$}
	\COM{$B[i,j]=\egweigp{(0,0)}{(i,j)}$ em $G$}
    \DOFORI {i} {0} {|s|} \label{bimn3:loop1}
    	\IF {i=0} \label{bimn3:dirinicio}
    		\SET {B[0,0]}{0}
    	\ELSE
    		\COM{Na 1ª coluna $\nexists$ arestas horizontais nem diagonais}
    		\SET {B[i,0]}{B[i-1,0]+\egweige{\egev{(i,j)}}}
    	\FI
      	\DOFORI {j} {1} {|t|}
      		\IF {i=0}
    		\COM{Na 1ª linha $\nexists$ arestas verticais nem diagonais}
		    	\SET {B[0,j]}{B[0,j-1]+\egweige{\egeh{(i,j)}}}
      		\ELSE
      			\COM {Obtém o máximo entre os caminhos que termi-}
      			\COM { nam nas arestas horizontal, vertical e diagonal}
      			\SET{h}{B[i,j-1]+\egweige{\egeh{(i,j)}}}
      			\SET{v}{B[i-1,j]+\egweige{\egev{(i,j)}}}
      			\SET{d}{B[i-1,j-1]+\egweige{\eged{(i,j)}}}
        		\SET{B[i,j]}{\max(h,v,d)}
      		\FI
		\OD \label{bimn3:dirfim}
	\COM{Obtém, para cada $j$ da linha $i$, o máximo entre os }
	\COM {caminhos que terminam numa aresta estendida}
	\SET{BL}{\emptyset}
    \DOFORD {i'} {i} {0}\label{bimn3:loopiLinha}
     \SET{BL}{constroiBL(\overline G,BL,i, i')}\label{bimn3:constroiBL}
	\COM{Obtém $OUT_G[j]=B[i',j]+\egweigpi{(n-i,j)}{(n-i',j)}$}
    \DOFORI {j} {0} {|t|}\label{bimn3:forComInv}
		\IF{i' = i}
			\SET{W[j]}{0}
		\ELSE
			\SET{W[j]}{W[j]+\egweigei{\egevi{(n-i',j)}}}
		\FI
		\SET{OUT_G[j]}{B[i',j]+W[j]}
	\OD
    \SET{maxOut}{obtemMaxOut(BL,OUT_G)} 
    \label{bimn3:obtemMaxout}
        \DOFORI {j} {0} {|t|}\label{bimn3:forComInv}
          \SET {B[i,j]} {\max(B[i,j],maxOut[j]+\opedweiginv)}
\OD \OD \OD \RETURN B
  \caption[BimN3]{Algoritmo $O(n^3)$ para obtenção da matriz $B$}
  \label{alg:bimn3}
\end{algo}
\end{algorithm}

O Algoritmo~\ref{alg:bimn3} constrói a matriz $B$, descrita anteriormente, e 
funciona como descrito a seguir.

O laço controlado pela linha~\ref{bimn3:loop1} calcula os valores da linha $i$ 
de $B$. Os valores de $B[i,j]$ calculados nas linhas \ref{bimn3:dirinicio} 
a~\ref{bimn3:dirfim} não consideram que a última aresta seja uma aresta 
estendida. Estas linhas levam tempo $O(m)$ para serem executadas.

O laço controlado pela linha~\ref{bimn3:loopiLinha} calcula o valor de $B[i,j]$ 
considerando que a última aresta é uma aresta estendida. Os comandos 
controlados por este laço calculam, para cada $i'$ e $i$, os valores máximos de 
\outfunc{G}{i'}{j'}{i}{j} e atualiza $B[i,j]$ se necessário.

O algoritmo $constroiBL$ para construir o vetor $BL$ executado na linha
\ref{bimn3:constroiBL} pode ser desenvolvido como descrito em \cite{MR1621993} 
na seção 6 com tempo de execução de $O(m)$.

Os comandos controlados pelo laço da linha~\ref{bimn3:forComInv} calculam os 
valores de \outfunc{G}{i'}{j}{i}{j} e executam em tempo $O(m)$ para $i$ e $i'$ 
fixos.

A linha~\ref{bimn3:obtemMaxout} executa o Algoritmo~\ref{alg:obtemMaxOut}, o 
qual já vimos que executa em tempo $O(m)$ para $i$ e $i'$ fixos.

Como os laços nas linhas~\ref{bimn3:loop1} e~\ref{bimn3:loopiLinha} variam, 
respectivamente, as linhas $i$ e $i'$ temos que o Algoritmo~\ref{alg:bimn3} 
executa em tempo $O(n^2m)$.

Se quisermos considerar a constante $\psihfunc{\overline{G}}{n-i}{n-i'}{j}$, que
depende do sistema de pontuação, na análise da complexidade do algoritmo,
teremos que o algoritmo tem tempo de execução $O(\psi n^2m)$, onde $\psi$ é o 
maior $\psihfunc{\overline{G}}{n-i}{n-i'}{j}$, para $0 \leq i' \leq i \leq n$ e 
$ 0 \leq j \leq m$.

% Nas análises de tempo que fizemos sempre consideramos 
% $\psihfunc{\overline{G}}{n-i}{n-i'}{j}$ como uma constante. Se isto não for 
% verdade então o algoritmo tem tempo de execução $O(\psi n^2m)$, onde $\psi$ é o 
% maior $\psihfunc{\overline{G}}{n-i}{n-i'}{j}$, para $0 \leq i' \leq i \leq n$ e 
% $ 0 \leq j \leq m$.
% 
Testes realizados com dados reais para alinhamento de duas seqüências mostraram 
que o algoritmo $O(n^3)$ é, como seria esperado, mais rápido que os algoritmos 
$O(n^3 \log n)$ e $O(n^4)$ \cite{MR2132586}. Para matrizes com alto grau de 
esparsidade o algoritmo esparso \cite{MR2132586} é praticamente instantâneo e o 
mais rápido de todos.

Antes de desenvolvermos os algoritmos \ref{alg:bimn3} ($O(n^3)$) e 
\ref{alg:bimn3logn} ($O(n^3 \log n)$) os algoritmos com as melhores 
complexidades no tempo de execução eram algoritmos que executavam em tempo 
$O(n^4)$~\cite{lago03:wob03,gao03:_space_effic_algor_sequen_align_inver}. 
Portanto, com os nossos algoritmos conseguimos melhorar a complexidade de tempo 
de execução para solucionar o problema de obtenção de um alinhamento ótimo com 
\invnsobs.

% \begin{algorithm}[htbp]
% \begin{algo}{buildBorderline}{BLHPrev, G, i}
% \IF{BLHPrev = null} 
% \RCOM{4}{$i' = i$}
% \SET{BLH[0].\psi}{0}
% \DOFORI{j}{1}{m}
% \SET{BLH[j].j'[0]}{0}
% \SET{BLH[j].\Delta[0]}{\egweige{\egeh{(i,j)}}}
% \SET{BLH[j].\psi}{1}
% \OD
% \RETURN{BLH}
% \FI
% 
% % \SET{BLV[0].j'[0]}{0}
% % \SET{BLV[0].\Delta[0]}{wv[0]}
% % \SET{BLV[0].\psi}{1}
% 
% \DOFORI{j}{0}{m}
% \SET{\alpha^*H}{0}
% \SET{\alpha^*V}{0}
% \SET{\alpha H}{0}
% \SET{\alpha V}{0}
% \SET{j'}{0}
% 
% \DOWHILE {j' < j}
% \SET{max}{\Call{max}{BLV[j-1].\Delta[\alpha^*V]+\egweige{\egeh{(i,j)}}, \egweige{\eged{(i,j)}}}}
% \SET{max}{\Call{max}{max, BLHPrev[j].\Delta[\alpha^*H]+\egweige{\egev{(i,j)}}}}
% \IF{\alpha H = 0 $ ou $ BLH[j].\Delta[\alpha H-1] \neq max-BLV[j-1].\Delta[\alpha^*V]}
% \SET{BLH[j].\Delta[\alpha H]}{max-BLV[j-1].\Delta[\alpha^*V]}
% \SET{BLH[j].j'[\alpha H]}{j'}
% \INCR{\alpha H}
% \FI
% \IF{\alpha V = 0 $ ou $ BLV[j].\Delta[\alpha V-1] \neq max-BLHPrev[j].\Delta[\alpha^*H]}
% \SET{BLV[j].\Delta[\alpha V]}{max-BLHPrev[j].\Delta[\alpha^*H]}
% \SET{BLV[j].j'[\alpha V]}{j'}
% \INCR{\alpha V}
% \FI
% \CALL{nextBorderLine}{}
% \OD
% \IF{\alpha V = 0 $ ou $ BLV[j].\Delta[\alpha V-1] \neq \egweige{\egev{(i,j)}}}
% \SET{BLV[j].\Delta[\alpha V]}{\egweige{\egev{(i,j)}}}
% \SET{BLV[j].j'[\alpha V]}{j'}
% \INCR{\alpha V}
% \FI
% \SET{BLH[j].\psi}{\alpha H }
% \SET{BLV[j].\psi}{\alpha V }
% 
% \OD
% \RETURN{BLH}
% \end{algo}
% \end{algorithm}
% 
% \begin{algorithm}[htbp]
% \begin{algo}{nextBorderLine}{}
% \IF{\alpha^*h = BLHPrev[j].\psi -1 $ e $ \alpha^*v = BLV[j-1].\psi-1 }
% \SET{j'}{j}
% \ELSEIF {\alpha^*h = BLHPrev[j].\psi -1 $ e $ \alpha^*v < BLV[j-1].\psi-1 }
% \INCR{\alpha^*v}
% \SET{j'}{BLV[j-1].j'[\alpha^*v]}
% \ELSEIF {\alpha^*h < BLHPrev[j].\psi -1 $ e $ \alpha^*v = BLV[j-1].\psi-1 }
% \INCR{\alpha^*h}
% \SET{j'}{BLHPrev[j].j'[\alpha^*h]}
% \ELSEIF{BLHPrev[j].j'[\alpha^*h+1]\leq BLV[j-1].j'[\alpha^*v+1]}
% \INCR{\alpha^*h}
% \SET{j'}{BLHPrev[j].j'[\alpha^*h]}
% \ELSEIF{BLHPrev[j].j'[\alpha^*h+1]\geq BLV[j-1].j'[\alpha^*v+1]}
% \INCR{\alpha^*v}
% \SET{j'}{BLV[j-1].j'[\alpha^*v]}
% \FI
% \end{algo}
% \end{algorithm}
% 


\chapter{Alinhamento com \dups}
\label{cap:aligndup}

\section{Introdução}
\label{sec:aligndupintro}

Neste capítulo, consideraremos que $s$ e $t$ são duas \seqs\ de comprimentos 
$n$ e $m$, respectivamente.

Os eventos biológicos típicos que são considerados normalmente nos 
procedimentos de alinhamentos atuais de \seqs\ de DNA são: substituição, 
remoção e inserção de nucleotídeos. Um outro evento biológico que ocorre, mas 
que normalmente não é considerado nos alinhamentos usuais, é a \dup, a qual 
iremos considerar sob algumas restrições nos algoritmos de alinhamentos deste 
capítulo. São dois os tipos de duplicações que consideraremos que ocorrem:
duplicações encadeadas (em \emph{tandem}) ou transposições.

Sejam duas \seqs\ tais que somente uma delas sofreu um evento de \dup. Ao 
analisarmos estas \seqs\ através de um alinhamento usual, é muito provável que 
neste alinhamento haja uma \seq\ de colunas que correspondam a inserções (ou 
remoções) no trecho que corresponde a \dup. Neste caso, pretendemos mostrar, 
num alinhamento com \dups, que houve uma \dup\ em uma das \seqs, ao invés de 
mostrar a \seq\ de colunas que correspondem a inserções (ou remoções) como é 
mostrado num alinhamento comum.

Em 1997, Benson~\cite{267526} propôs um modelo para o alinhamento de \seqs\ que 
considera a presença de repetições em \emph{tandem} de mesmo tamanho nas \seqs. 
Ele propôs dois algoritmos exatos para obter um tal alinhamento ótimo que 
considera estas repetições. O primeiro algoritmo proposto executa em tempo 
$O(n^5)$ e espaço $O(n^2)$. O segundo algoritmo proposto executa em tempo 
$O(n^4)$ e espaço $O(n^3)$.

Iremos propor modelos parecidos com este modelo apresentado por Benson e
algoritmos exatos que executam em tempo $O(n^3)$ e memória $O(n^2)$. Utilizando
as técnicas utilizadas no algoritmo $O(n^3)$ para a obtenção de um alinhamento
ótimo com \invnsobs, existe um algoritmo que, em tempo $O(n^3)$ e memória
$O(n^2)$, obtém um alinhamento ótimo com \dups\ em \emph{tandem} segundo o mesmo
modelo proposto pode Benson. Porém acreditamos que os modelos que iremos propor,
são modelos mais gerais e que consideram mais casos de \dups. 



% Num alinhamento comum de duas \seqs\ pode haver muitos trechos com várias 
% inserções ou remoções consecutivas. Estes trechos podem existir devido a 
% inserção na \seq\ analisada de segmentos da própria \seq, ou seja, devido a 
% ocorrência de \dups. Pretende-se, num alinhamento com 
% \dups, mostrar que alguns dos trechos que num alinhamento global correspondem a 
% inserções ou remoções consecutivas, podem na verdade corresponder a \dups.
% 
Em \seqs\ biológicas é comum, com o decorrer do tempo, ocorrerem eventos que 
alteram estas \seqs. Estas alterações podem ocorrer inclusive em trechos das 
\seqs\ que participaram de uma \dup. Sendo assim, ao analisarmos \dups\ em 
\seqs\ biológicas devemos considerar a possibilidade da \seq\ original e da 
\rep\ terem sofrido mutações e não serem mais iguais.

\begin{definicao}[Intervalo de \rep\ em $\aligndupsym$] Seja $\aligndupsym$ uma 
matriz de $3$ linhas e $r+1$ colunas tal que, $\aligndupsym[2,k] \in 
\{\aligndupdirectsym,\aligndupinicdupsym,\aligndupextdupsym\}$ para todo $k$ 
tal que, $0 \leq k \leq r$. Dizemos que o intervalo $[k_1,k_2]$ de colunas de 
$\aligndupsym$ é um \intrep\ em $\aligndupsym$, ou mais 
especificamente é o \intrep\ $[k_1,k_2]$ de $\aligndupsym$, se $k_1$ 
e $k_2$ são tais que $0 \leq k_1 \leq k_2 \leq r$, 
$\aligndupsym[2,k_1]=\aligndupinicdupsym$, 
$\aligndupsym[2,k']=\aligndupextdupsym$, para todo $k'$ tal que $k_1 < k' \leq 
k_2$, e não existe uma coluna $k_2+1$ em $\aligndupsym$ tal que 
$\aligndupsym[2,k_2+1]=\aligndupextdupsym$.
\end{definicao}

Este conceito de \intrep\ será utilizado em um alinhamento com \dups\ 
para associarmos um trecho do alinhamento a uma duplicação.

% Sejam $\Sigma_1$ e $\Sigma_2$ dois conjuntos, denotamos por $\Sigma_1 \setminus
% \Sigma_2$ o conjunto com os símbolos de $\Sigma_1$ que não estão no conjunto
% $\Sigma_2$.
% 
\begin{definicao}[Função \excludefunc] A função $\excludefunc:\Sigma_1^* \times 
\Sigma_1^* \rightarrow \Sigma_1^*$, onde $\Sigma_1^*$ é o conjunto com todas as 
possíveis \seqs\ de símbolos de um alfabeto $\Sigma_1$ qualquer, é definida por 
$\excludefunc(w,X)=w'$, onde $w'=w[i_1]w[i_2]\ldots w[i_r]$, $w'[i'] \notin X$ 
para todo índice $i'$ de $w'$ e $w[i] \in X$ para todo índice $i$ de $w$ tal 
que $i \notin (i_1,i_2,\ldots,i_r)$.
\end{definicao}

Ou seja, $\excludefunc(w,X)$ gera uma nova \seq, excluindo da \seq\ $w$ todos e 
somente os símbolos de $w$ que estão em $X$.

Seja o conjunto $\aligndupsetgapdupsym=\aligndupsetgapdupsym_s \cup 
\aligndupsetgapdupsym_t$, onde $\aligndupsetgapdupsym_s=\{(s,x)\tq x \in 
[1,n]\}$ e $\aligndupsetgapdupsym_t=\{(t,y)\tq y \in [1,m]\}$.

\begin{definicao}[Alinhamento com \dups\ de $s$ e $t$] Um alinhamento com 
\dups\ de $s$ e $t$ é uma matriz \aligndupsym\ de 3 linhas e $r$ colunas, tal 
que:
\begin{itemize}
  \item $r \geq \max(m,n)$ e $r \leq m+n$;
  \item para toda coluna $k$ de $\aligndupsym$ temos que:
  \begin{itemize}
      \item $\aligndupsym[0,k]\in [1,n] \cup \{\aligngapd\} \cup 
      \aligndupsetgapdupsym$,
      \item $\aligndupsym[1,k]\in [1,m] \cup \{\aligngapd\} \cup 
      \aligndupsetgapdupsym$,
      \item $\aligndupsym[2,k]\in 
      \{\aligndupdirectsym,\aligndupinicdupsym,\aligndupextdupsym\}$,
      \item se $\aligndupsym[0,k]=\aligndupsym[1,k]$ então $\aligndupsym[0,k] 
      \in [1,n]$,
      \item se $\aligndupsym[0,k]\in \aligndupsetgapdupsym$ então 
      $\aligndupsym[1,k] \notin \aligndupsetgapdupsym$,
      \item se $\aligndupsym[0,k] \in \aligndupsetgapdupsym$ ou 
      $\aligndupsym[1,k] \in \aligndupsetgapdupsym$ então $\aligndupsym[2,k] 
      \in \{\aligndupinicdupsym,\aligndupextdupsym\}$;
      \item se $\aligndupsym[0,k] \in [1,n]$ e $\aligndupsym[1,k] \in [1,m]$ 
      então $\aligndupsym[2,k] = \aligndupdirectsym$;
      \item se $\aligndupsym[2,k] = \aligndupextdupsym$ então 
      $\aligndupsym[2,k-1] \in \{\aligndupinicdupsym,\aligndupextdupsym\}$;
  \end{itemize} 
      \item $\excludefunc(\aligndupsym[0,0 \Rng r-1]\aligndupsetgapdupsym
      \cup \{\aligngapd\} )=(1,2,\ldots,n)$;
      \item $\excludefunc(\aligndupsym[1,0 \Rng r-1],\aligndupsetgapdupsym \cup 
      \{\aligngapd\} )=(1,2,\ldots,m)$;
      \item Para todo \intrep\ $[k_1,k_2]$ em $\aligndupsym$ temos que:
  \begin{enumerate}
      \item se $\aligndupsym[0,k_1] \in [1,n] \cup \{\aligngapd\}$ e 
      $\aligndupsym[1,k_1] \in \aligndupsetgapdupsym \cup \{\aligngapd\}$ então 
      $\excludefunc(\aligndupsym[0,$ $k_1\Rng k_2], $ $
      \{\aligngapd\})=(i_1,i_1+1,\ldots,i_1+x_1)$, onde $1\leq i_1 \leq i_1+x_1 
      \leq n$, e $\excludefunc(\aligndupsym[1,$ $k_1\Rng k_2],
      \{\aligngapd\})=X$, onde $X$ é uma das seguintes \seqs:
      \begin{enumerate}
          \item $((s,i_2),(s,i_2+1),\ldots,(s,i_2+x_2))$, onde $1 \leq i_2 \leq 
          i_2+x_2+1 \leq i_1$ ou $i_1+x_1+1 \leq i_2 \leq i_2+x_2+1 \leq n+1$,
          \label{def:aligndup:casossnormal}
          \item $((s,i_3),(s,i_3+1),\ldots,(s,i_1-1),(s,i_1+x_1+1), \ldots, 
          (s,i_1+x_1+x_3))$, onde $1 \leq i_3 \leq i_1$ e $i_1+x_1+1 \leq 
          i_1+x_1+x_3+1 \leq n+1$,\label{def:aligndup:casossintercalado}
          \item $((t,j),(t,j+1),\ldots,(t,j+x_4))$, onde $1 \leq j \leq j+x_4+1 
          \leq m+1$;\label{def:aligndup:casost}
      \end{enumerate}
      
      \item se $\aligndupsym[1,k_1] \in [1,m] \cup \{\aligngapd\}$ e 
      $\aligndupsym[0,k_1] \in \aligndupsetgapdupsym \cup \{\aligngapd\}$ então 
      $\excludefunc(\aligndupsym[1,$ $k_1\Rng k_2], 
      \{\aligngapd\})=(j_1,j_1+1,\ldots,j_1+y_1)$, onde $1\leq j_1 \leq j_1+y_1 
      \leq m$, e $\excludefunc(\aligndupsym[0,k_1\Rng k_2], \{\aligngapd\})=Y$, 
      onde $Y$ é uma das seguintes \seqs:
      \begin{enumerate}
          \item $((t,j_2),(t,j_2+1),\ldots,(t,j_2+y_2))$, onde $1 \leq j_2 \leq 
          j_2+y_2+1 \leq j_1$ ou $j_1+y_1+1 \leq j_2 \leq j_2+y_2+1 \leq 
          m+1$,\label{def:aligndup:casottnormal}
          \item $((t,j_3),(t,j_3+1),\ldots,(t,j_1-1),(t,j_1+y_1+1), \ldots, 
          (t,j_1+y_1+y_3))$, onde $1 \leq j_3 \leq j_1$ e $j_1+y_1+1 \leq 
          j_1+y_1+y_3+1 \leq m+1$,\label{def:aligndup:casottintercalado}
          \item $((s,i),(s,i+1),\ldots,(s,i+y_4))$, onde $1 \leq i \leq i+y_4+1 
          \leq n+1$.\label{def:aligndup:casots}
      \end{enumerate}
  \end{enumerate}
\end{itemize}
\label{def:aligndup}
\end{definicao}

Os Exemplos~\ref{ex:aligndup}, \ref{ex:aligndupcasossintercalado} e
\ref{ex:aligndupcasost} mostram alinhamentos com \dups.

O número de colunas de um alinhamento com \dups\ \aligndupsym\ é o comprimento 
de \aligndupsym.

Seja $\alignsetd$ o conjunto de todos os possíveis alinhamentos com \dups\ 
de duas \seqs. 

\begin{definicao}[Função parcial $\aligndsimbsym$] Seja a função parcial 
$\aligndsimbsym: \alignsetd \times \{0,1\} \times \natset \rightarrow \alfabeto 
\cup \{\aligngapd\}$ definida por:
\begin{itemize}
  \item $\aligndsimb{\aligndupsym}{0}{k}=s[\aligndupsym[0,k]]$ se 
  $\aligndupsym[0,k] \in [1 , n]$ e $k$ é o índice de uma coluna de 
  \aligndupsym, onde \aligndupsym\ é um alinhamento com \dups\ de $s$ e $t$;
  
  \item $\aligndsimb{\aligndupsym}{1}{k}=t[\aligndupsym[1,k]]$ se 
  $\aligndupsym[1,k] \in [1 , m]$ e $k$ é o índice de uma coluna de 
  \aligndupsym, onde \aligndupsym\ é um alinhamento com \dups\ de $s$ e $t$;
  
  \item para $x \in \{0,1\}$, $\aligndsimb{\aligndupsym}{x}{k}=s[i]$ se 
  $\aligndupsym[x,k] = (s,i)$ e $k$ é o índice de uma coluna de \aligndupsym, 
  onde \aligndupsym\ é um alinhamento com \dups\ de $s$ e $t$;
  
  \item para $x \in \{0,1\}$, $\aligndsimb{\aligndupsym}{x}{k}=t[j]$ se 
  $\aligndupsym[x,k] = (t,j)$ e $k$ é o índice de uma coluna de \aligndupsym, 
  onde \aligndupsym\ é um alinhamento com \dups\ de $s$ e $t$;
  
  \item para $x \in \{0,1\}$, $\aligndsimb{\aligndupsym}{x}{k}=\aligngapd$ se 
  $\aligndupsym[x,k] = \aligngapd$ e $k$ é o índice de uma coluna de 
  \aligndupsym;
  
\end{itemize} 
\end{definicao}

Para todo \intrep\ $[k_1,k_2]$ de um alinhamento com \dups\ $\aligndupsym$ de 
$s$ e $t$ temos que,
\begin{itemize}
  \item se $\aligndupsym[0,k_1] \in [1,n] \cup \{\aligngapd\}$ e 
  $\aligndupsym[1,k_1] \in \aligndupsetgapdupsym \cup \{\aligngapd\}$ então 
  dizemos que
  \begin{itemize}
      \item o \intrep\ $[k_1,k_2]$ de \aligndupsym\ é um \emph{\intrep\ por 
      excisão},
      \item $\excludefunc(\aligndsimb{\aligndupsym}{0}{k_1} 
      \aligndsimb{\aligndupsym}{0}{k_1+1} \ldots 
      \aligndsimb{\aligndupsym}{0}{k_2}, \{\aligngapd\})$ é a \emph{\rep\ do 
      \intrep\ $[k_1,k_2]$ de \aligndupsym},
      \item $\excludefunc(\aligndsimb{\aligndupsym}{1}{k_1} 
      \aligndsimb{\aligndupsym}{1}{k_1+1} \ldots 
      \aligndsimb{\aligndupsym}{1}{k_2}, \{\aligngapd\})$ é a \emph{\seq\ base 
      do \intrep\ $[k_1,k_2]$ de \aligndupsym};
%       \item $s[i_1 \Rng i_1+x_1]$ é a \emph{repetição do \intrep 
%       $[k_1,k_2]$ de \aligndupsym}, onde $i_1$ e $x_1$ são tais que 
%       $\excludefunc(\aligndupsym[0,k_1\Rng k_2], \{\aligngapd\}) = (i_1,i_1+1, 
%       \ldots,i_1+x_1)$,
%       \item $x$ é a \emph{\seq\ base do \intrep $[k_1,k_2]$ de 
%       \aligndupsym}, onde $x$ é tal que:
%       \begin{itemize}
%           \item se existem $i_2$ e $x_2$ tais que 
%           $\excludefunc(\aligndupsym[1,k_1\Rng k_2], \{\aligngapd\}) 
%           =((s,i_2),(s,i_2+1),\ldots,(s,i_2+x_2))$ então 
%           $x=s[i_2]s[i_2+1]\ldots s[i_2+x_2]$,
%           \item se existem $i_3$ e $x_3$ tais que 
%           $\excludefunc(\aligndupsym[1,k_1\Rng k_2], \{\aligngapd\}) 
%           =((s,i_3),(s,i_3+1),\ldots,(s,i_1-1),(s,i_1+x_1+1), \ldots, 
%           (s,i_1+x_1+x_3))$ então $x=s[i_3]s[i_3+1]\ldots 
%           s[i_1-1]s[i_1+x_1+1]\ldots s[i_1+x_1+x_3]$,
%           \item se existem $j$ e $x_4$ tais que 
%           $\excludefunc(\aligndupsym[1,k_1\Rng k_2], \{\aligngapd\}) 
%           =((t,j),(t,j+1),\ldots,(t,j+x_4))$ então $x=t[j]t[j+1]\ldots 
%           t[j+x_4]$;
%       \end{itemize}
  \end{itemize}     
  
  \item se $\aligndupsym[1,k] \in [1,m] \cup \{\aligngapd\}$ e 
  $\aligndupsym[0,k] \in \aligndupsetgapdupsym \cup \{\aligngapd\}$ então 
  dizemos que
  \begin{itemize}
      \item o \intrep\ $[k_1,k_2]$ de \aligndupsym\ é um \emph{\intrep\ por 
      \dup},
      \item $\excludefunc(\aligndsimb{\aligndupsym}{1}{k_1} 
      \aligndsimb{\aligndupsym}{1}{k_1+1} \ldots 
      \aligndsimb{\aligndupsym}{1}{k_2}, \{\aligngapd\})$ é a \emph{\rep\ do 
      \intrep\ $[k_1,k_2]$ de \aligndupsym},
      \item $\excludefunc(\aligndsimb{\aligndupsym}{0}{k_1} 
      \aligndsimb{\aligndupsym}{0}{k_1+1} \ldots 
      \aligndsimb{\aligndupsym}{0}{k_2}, \{\aligngapd\})$ é a \emph{\seq\ base 
      do \intrep\ $[k_1,k_2]$ de \aligndupsym};
      
%       \item $t[j_1 \Rng j_1+y_1]$ é a \emph{repetição do \intrep 
%       $[k_1,k_2]$ de \aligndupsym}, onde $j_1$ e $y_1$ são tais que 
%       $\excludefunc(\aligndupsym[1,k_1\Rng k_2], \{\aligngapd\}) = 
%       (j_1,j_1+1,\ldots,j_1+y_1)$,
%       \item $y$ é a \emph{\seq\ base do \intrep $[k_1,k_2]$ de 
%       \aligndupsym}, onde $y$ é tal que:
%       \begin{itemize}
%           \item se existem $j_2$ e $y_2$ tais que 
%           $\excludefunc(\aligndupsym[0,k_1\Rng k_2], \{\aligngapd\})= 
%           ((t,j_2),(t,j_2+1),\ldots,(t,j_2+y_2))$ então $y=t[j_2]t[j_2+1]\ldots 
%           t[j_2+y_2]$,
%           \item se existem $j_3$ e $y_3$ tais que 
%           $\excludefunc(\aligndupsym[0,k_1\Rng k_2], \{\aligngapd\})= 
%           ((t,j_3),(t,j_3+1),\ldots,(t,j_1-1),(t,j_1+y_1+1), \ldots, 
%           (t,j_1+y_1+y_3))$ então $y=t[j_3]t[j_3+1]\ldots 
%           t[j_1-1]t[j_1+y_1+1]\ldots t[j_1+y_1+y_3]$,
%           \item se existem $i$ e $y_4$ tais que 
%           $\excludefunc(\aligndupsym[0,k_1\Rng k_2], \{\aligngapd\})= 
%           ((s,i),(s,i+1),\ldots,(s,i+y_4))$ então $y=s[i]s[i+1]\ldots s[i+y_4]$.
%       \end{itemize}
  \end{itemize}
\end{itemize}

O Exemplo~\ref{ex:aligndup} mostra um alinhamento com \dups\ de $s=s[1..7]$ e 
$t=t[1..5]$. O \intrep\ $[1,4]$ de \aligndupsym\ é um intervalo de 
\rep\ por excisão e está de acordo com o caso \ref{def:aligndup:casossnormal} 
de um \intrep\ na Definição~\ref{def:aligndup}. A \seq\ $s[2 \Rng 4]$ 
é a \rep\ e $s[5 \Rng 7]$ é a \seq\ base do \intrep\ $[1,4]$ de 
\aligndupsym.

\begin{exemplo}[Alinhamento com \dups\ caso \ref{def:aligndup:casossnormal}]
\label{ex:aligndup}
\[\aligndupsym=\left[\begin{array}{ccccccccc} 
1&2&3&\aligngapd&4&5&6&\aligngapd&7\\
1&(s,5)&\aligngapd&(s,6)&(s,7)&2&3&4&5\\
+&\aligndupinicdupsym&\aligndupextdupsym&\aligndupextdupsym&\aligndupextdupsym&+&+&+&+ \end{array}\right]\]
\end{exemplo}

No alinhamento com \dups\ do Exemplo~\ref{ex:aligndupcasossintercalado} o 
\intrep\ $[2,5]$ de \aligndupsym\ é um \intrep\ por excisão 
e está de acordo com o caso \ref{def:aligndup:casossintercalado} de um 
\intrep\ na Definição~\ref{def:aligndup}. A \seq\ $s[2 \Rng 4]$ é a 
\rep\ e $s[1]s[5 \Rng 6]$ é a \seq\ base do \intrep\ $[2,5]$ de 
\aligndupsym.

\begin{exemplo}[Alinhamento com \dups\ caso \ref{def:aligndup:casossintercalado}]
\label{ex:aligndupcasossintercalado}
\[\aligndupsym=\left[\begin{array}{cccccccccc} 
\aligngapd&1&2&3&\aligngapd&4&5&6&\aligngapd&7\\
1&2&(s,1)&\aligngapd&(s,5)&(s,6)&3&4&5&6\\
+&+&\aligndupinicdupsym&\aligndupextdupsym&\aligndupextdupsym&\aligndupextdupsym&+&+&+&+ \end{array}\right]\]
\end{exemplo}

No alinhamento com \dups\ do Exemplo~\ref{ex:aligndupcasost} o intervalo de 
\rep\ $[5,8]$ de \aligndupsym\ é um \intrep\ por excisão e está de 
acordo com o caso \ref{def:aligndup:casost} de um \intrep\ na 
Definição~\ref{def:aligndup}. A \seq\ $s[4 \Rng 6]$ é a \rep\ e $t[3 \Rng 5]$ é 
a \seq\ base do \intrep\ $[5,8]$ de \aligndupsym.

\begin{exemplo}[Alinhamento com \dups\ caso \ref{def:aligndup:casost}]
\label{ex:aligndupcasost}
\[\aligndupsym=\left[\begin{array}{cccccccccc} 
\aligngapd&1&2&3&\aligngapd&4&5&6&\aligngapd&7\\
1&2&3&4&5&(t,3)&\aligngapd&(t,4)&(t,5)&6\\
+&+&+&+&+&\aligndupinicdupsym&\aligndupextdupsym&\aligndupextdupsym&\aligndupextdupsym&+ \end{array}\right]\]
\end{exemplo}

Seja \aligndupsym\ um alinhamento com \dups\ de $s$ e $t$ e o intervalo de 
\rep\ $[k_1,k_2]$ em $\aligndupsym$. Se o intervalo de \rep\ $[k_1,k_2]$ em 
$\aligndupsym$ é um \intrep\ por excisão, então as colunas $(k_1, k_1+1, 
\ldots, k_2)$ do alinhamento estão mostrando a ocorrência de uma \dup\ em $s$ 
que não ocorreu em $t$ ou a ocorrência de uma excisão em $t$ que não ocorreu em 
$s$. Equivalentemente, se o \intrep\ $[k_1,k_2]$ em $\aligndupsym$ é um 
\intrep\ por \dup, então as colunas $(k_1\Rng k_2)$ do alinhamento estão 
mostrando a ocorrência de uma excisão em $s$ que não ocorreu em $t$ ou a 
ocorrência de uma \dup\ em $t$ que não ocorreu em $s$.

Associaremos a cada coluna $k$ de um alinhamento com \dups\ \aligndupsym\ uma 
ou duas \opeds, similarmente como é feito num alinhamento com \invnsobs\ 
através da função \alignopedinvsym, da seguinte forma:
\begin{itemize}
  \item se $\aligndupsym[0,k]=\aligngapd$ então associamos a coluna $k$ de 
  \aligndupsym\ uma \oped\ de inserção de $\aligndsimb{\aligndupsym}{1}{k}$;
  
  \item se $\aligndupsym[1,k]=\aligngapd$ então associamos a coluna $k$ de 
  \aligndupsym\ uma \oped\ de remoção de \aligndsimb{\aligndupsym}{0}{k};
  
  \item se $\aligndupsym[0,k]\neq \aligngapd$ e $\aligndupsym[1,k]\neq 
  \aligngapd$  então associamos a coluna $k$ de \aligndupsym\ uma \oped\ de 
  substituição de $\aligndsimb{\aligndupsym}{0}{k}$ por 
  $\aligndsimb{\aligndupsym}{1}{k}$;
  
  \item se a coluna $k$ é tal que existe um \intrep\ por \dup\ 
  $[k,k']$ em \aligndupsym, então também associamos a coluna $k$ de 
  \aligndupsym\ uma \oped\ de \dup\ tal que, a \seq\ original da \oped\ de 
  \dup\ é igual a \seq\ base do \intrep\ $[k,k']$ de \aligndupsym;
  
  \item se a coluna $k$ é tal que existe um \intrep\ por excisão 
  $[k,k']$ em \aligndupsym, então também associamos a coluna $k$ de 
  \aligndupsym\ uma \oped\ de excisão tal que, a \seq\ original da \oped\ de 
  excisão é igual a \seq\ base do \intrep\ $[k,k']$ de \aligndupsym;
\end{itemize}

Repare que sempre associamos a uma coluna $k$ de um alinhamento com \dups\ uma 
\oped\ pontual e, na primeira coluna de um \intrep\ por \dup, além 
desta \oped\ pontual, também associamos uma \oped\ de \dup, assim como na 
primeira coluna de um \intrep\ por excisão, além dessa \oped\ 
pontual, também associamos uma \oped\ de excisão.

Como um alinhamento com \dups\ é uma \seq\ de colunas, associamos a um 
alinhamento com \dups\ uma \seq\ de \opeds.

\begin{definicao}[Transformação com \dups\ de $s$ e $t$] Dadas duas \seqs\ $s$ 
e $t$, dizemos que uma transformação com \dups\ de $s$ e $t$ é qualquer \seq\ 
de \opeds\ $\opedseqsym=(\opedsym_0, \opedsym_1, \ldots, \opedsym_r)$ tal que 
$\opedcompsym{\opedseqsym}(s)=t$ e $\opedsym_k$ é uma \oped\ de inserção, 
remoção, substituição, \dup\ ou excisão, para todo $k$ tal que $0 \leq k \leq 
r$.
\end{definicao}

\begin{definicao}[Grafo de \dups\ de \aligndupsym] Dado um alinhamento com 
\dups\ \aligndupsym\ de $s$ e $t$, o grafo de \dups\ de \aligndupsym\ é um 
grafo dirigido $\graphdup{\aligndupsym}=(V,E)$ tal que, cada vértice de $V$ tem 
um rótulo distinto em $\aligndupsetgapdupsym$ e $(u,v) \in E$ se uma das 
seguintes condições é satisfeita:
\begin{itemize}
  \item $u=(s,i)$ e existe uma coluna $k$ em \aligndupsym\ tal que 
  $\aligndupsym[0,k]=i$ e $\aligndupsym[1,k]=v$;
  \item $u=(t,j)$ e existe uma coluna $k$ em \aligndupsym\ tal que 
  $\aligndupsym[1,k]=j$ e $\aligndupsym[0,k]=v$;
\end{itemize}
\end{definicao}

Diferente de um alinhamento com \invnsobs, a \seq\ de \opeds\ associada a um 
alinhamento com \dups\ de $s$ e $t$, nem sempre é uma transformação com \dups\ 
de $s$ e $t$. Mais especificamente, a \seq\ de \opeds\ associada a um 
alinhamento com \dups\ \aligndupsym\ de $s$ e $t$, tal que o grafo de \dups\ de 
\aligndupsym\ tem ciclos, não é uma transformação com \dups\ de $s$ e $t$. 

Repare que cada aresta do grafo de \dups\ $G$ de \aligndupsym\ corresponde a 
uma coluna de \aligndupsym\ cuja \oped\ pontual associada é uma substituição. 
Se alterarmos uma das colunas de \aligndupsym, correspondente a uma aresta $e$ 
de um ciclo de $G$, para uma coluna com \emph{gap}, ou seja, cuja \oped\ 
pontual associada é uma inserção ou uma remoção, então a aresta $e$ é removida 
de $G$ e este ciclo deixa de existir.

Se o grafo de \dups\ de \aligndupsym\ é acíclico, então podemos, com algumas 
(ou nenhuma) alterações na \seq\ de \opeds\ \opedseqsym\ associada a 
\aligndupsym, obter uma transformação com \dups\ de $s$ e $t$. As possíveis 
alterações em \opedseqsym\ podem ser:
\begin{itemize}
  \item alterar a ordem das \opeds\ de \opedseqsym\
  \item dividir um \intrep\ em dois ou mais intervalos de \reps, ou 
  seja, associar mais de uma \oped\ de \dup\ (ou excisão) a um intervalo de 
  \rep.
\end{itemize}

Em suma, com possivelmente algumas alterações num alinhamento com \dups, 
podemos obter, a partir deste alinhamento com \dups, uma transformação com 
\dups. 
% Contudo, a transformação com \dups\ de $s$ e $t$ obtida de um 
% alinhamento ótimo com \dups\ de $s$ e $t$ pode não ter pontuação máxima dentre
% todas as transformações com \dups\ de $s$ e $t$.

\begin{definicao}[Pontuação de um alinhamento com \dups] A pontuação de um 
alinhamento com \dups\ \aligndupsym\ é a soma das pontuações das colunas deste 
alinhamento e será denotado por \aligndupscoresym.
\end{definicao}

Dizemos que um alinhamento com \dups\ de $s$ e $t$ é ótimo se ele tem pontuação
máxima dentre todos os possíveis alinhamentos com \dups\ de $s$ e $t$.

Em alinhamentos que levam em conta somente as substituições, as remoções e as 
inserções, é comum que para a determinação da pontuação de uma coluna, 
considere-se somente a \oped\ pontual associada a esta coluna. Porém, num 
alinhamento com \dups, além da \oped\ pontual associada a uma coluna, vamos 
considerar também se a coluna está ou não em um \intrep\ para a 
determinação da pontuação desta coluna. Além disso, para a primeira coluna de 
um \intrep, vamos considerar na pontuação da coluna, além da \oped\ 
pontual, a \oped\ de \dup\ ou excisão associada a esta coluna e a \rep\ do 
\intrep. 

Sejam $\vomega{s}{i}$, $\homega{t}{j}$ e $\domega{s}{t}{i}{j}$ as pontuações 
das \opeds\ de remoção do símbolo $s[i]$, inserção do símbolo $t[j]$ e 
substituição do símbolo $s[i]$ pelo símbolo $t[j]$, respectivamente.

Considerando que um \intrep\ em um alinhamento com \dups\ representa uma \dup\ 
(ou uma excisão), e que o tamanho desta \dup\ (ou excisão) é igual ao 
comprimento da \rep\ do \intrep\ então, propomos um sistema de pontuação que 
considera que as probabilidades da ocorrência de \dups\ e excisões de tamanhos 
diferentes podem ser diferentes, ou seja, a pontuação para as \opeds\ de \dup\ 
e excisão podem considerar o tamanho da \dup\ ou excisão, aliás não só o 
tamanho como a própria \seq\ da \rep. Para tanto, consideramos que a 
pontuação da \oped\ de \dup\ ou de excisão associada a um \intrep\ é 
$\xomega{s}{i_1}{i_2}$ ou $\uomega{t}{j_1}{j_2}$, respectivamente, onde $s[i_1 
\Rng i_2]$ ou $t[j_1 \Rng j_2]$ é a \rep\ deste \intrep.

Portanto a pontuação de uma coluna $k$ de um alinhamento com \dups\ 
\aligndupsym\ é igual a:
\begin{itemize}
  \item $\vomega{s}{i}+z$ se a coluna $k$ está associada a \oped\ de remoção do 
  símbolo $s[i]$,
  \item $\homega{t}{j}+z$ se a coluna $k$ está associada a \oped\ de inserção do 
  símbolo $t[j]$,
  \item $\domega{s}{t}{i}{j}+z$ se a coluna $k$ está associada a \oped\ de 
  substituição do símbolo $s[i]$ pelo símbolo $t[j]$.
\end{itemize}
%????? pesos devem ser negativos?
  onde $z$ é igual a:
\begin{itemize}
  \item $\xomega{s}{i_1}{i_2}$, se existe um \intrep\ por excisão 
  $[k,k']$ em \aligndupsym, onde $s[i_1 \Rng i_2]$ é a repetição deste 
  \intrep,
  \item $\uomega{t}{j_1}{j_2}$, se existe um \intrep\ por \dup\ 
  $[k,k']$ em \aligndupsym, onde $t[j_1 \Rng j_2]$ é a repetição deste 
  \intrep,
  \item $0$ (zero), se não existe um \intrep\ $[k,k']$ em 
  \aligndupsym.
\end{itemize}

Observe que os valores $\xomega{s}{i_1}{i_2}$ e $\uomega{t}{j_1}{j_2}$ são
utilizados somente na primeira coluna de um intervalo de \rep. 

Assim como muitas vezes ocorre com outros eventos, simplesmente podemos adotar
uma penalidade constante para uma \dup/excisão.

Dados índices $i_1,i_2,j_1$ e $j_2$ tais que $0 < i_1 \leq i_2+1 \leq n+1$, $0 
< j_1 \leq j_2+1 \leq m+1$, vamos denotar a pontuação de um alinhamento ótimo 
considerando \dups\ de $s[i_1 \Rng i_2] \times t[j_1 \Rng j_2]$ por 
$\aligndupoptscorest{s}{t}{i_1}{i_2}{j_1}{j_2}$. 

Dados $i$ e $j$ tais que $0\leq i\leq n$ e $0\leq j\leq m$, definimos a matriz 
$M$ por $M[i,j]=\aligndupoptscorest{s}{t}{1}{i}{1}{j}$.

Definimos $\mt{i}{j}$ como a pontuação máxima de um alinhamento com \dups\ 
\aligndupsym\ de $s[1 \Rng i] \times t[1 \Rng j]$ tal que, a última coluna de 
\aligndupsym\ pertence a um \intrep\ por \dup, $\forall i,j \tq 0\leq 
i\leq n$ e $1 \leq j\leq m$. De forma análoga definimos $\ms{i}{j}$ como a 
pontuação máxima de um alinhamento com \dups\ \aligndupsym\ de $s[1 \Rng i] 
\times t[1 \Rng j]$ tal que, a última coluna de \aligndupsym\ pertence a um 
\intrep\ por excisão, $\forall i,j \tq 1 \leq i\leq n$ e $0\leq j\leq 
m$.

De acordo com as possibilidades da última coluna de um alinhamento com \dups,
podemos obter os valores de $M[i,j]$ da seguinte forma:
\begin{equation} 
\begin{array}{l}
M[0,0]=0\\
  
  M[i,0]= \max \left\{\begin{array}{l} M[i-1,0]+\vomega{s}{i}, \\
  \ms{i}{0} \end{array}\right\}\textrm{, } i > 0\\

  M[0,j]=\max \left\{\begin{array}{l} M[0,j-1]+\homega{t}{j}, \\
  \mt{0}{j} \end{array}\right\}\textrm{, }j > 0\\

  M[i,j]= \max \left\{\begin{array}{l} M[i,j-1]+\homega{t}{j}, \\
  M[i-1,j]+\vomega{s}{i}, \\
  M[i-1,j-1]+\domega{s}{t}{i}{j},\\
  \ms{i}{j}, \\ \mt{i}{j}
  \end{array}\right\}$, $i > 0\textrm{ e }j > 0
\end{array}
 \label{eq:dupM}
\end{equation}

% Diremos que 
% $\alignoptscorest{s}{t}{i_1}{i_2}{j_1}{j_2}$ é a pontuação do alinhamento 
% global ótimo de $s[i_1 \Rng i_2] \times t[j_1 \Rng j_2]$. 
Utilizando o sistema de pontuação de \emph{gap} linear, descrito na
página~\pageref{gaplinear} da seção~\ref{gaplinear}, tal que para qualquer 
coluna $k$ de um alinhamento $A$ temos que $\alignscore(A[0,k],A[1,k])$ é igual 
a:
\begin{itemize}
  \item $\vomegad{s}{i}$ se $A[0,k]=s[i]$ e $A[1,k]=\aligngap$,
  \item $\homegad{t}{j}$ se $A[0,k]=\aligngap$ e $A[1,k]=t[j]$,
  \item $\domegad{s}{t}{i}{j}$ se $A[0,k]=s[i]$ e $A[1,k]=t[j]$,
\end{itemize}
  diremos que $\alignoptlocscore{s'}{t'}$ é a pontuação do alinhamento 
  ótimo sem \dups\ de $s'$
  com  qualquer fator de $t'$ e $\alignoptscore{s'}{t'}$ é a pontuação 
  do alinhamento global ótimo sem \dups\ de $s' \times t'$.
   
Utilizaremos este sistema de pontuação para obter a pontuação de um alinhamento 
ótimo entre a \seq\ base e a \rep\ de um \intrep\ num alinhamento com \dups.

\begin{definicao}[Função parcial \dupwsym]
Dadas as \seqs\ $s$ e $t$, definimos a função parcial $\dupwsym:\{s,t\} \times
\natset \times \natset \rightarrow \realset$ da seguinte forma:
\begin{itemize}
  \item $\dupw{t}{j'}{j}=\uomega{t}{j'}{j}+ \max( 
  \alignoptlocscore{t[j' \Rng j]}{s},\alignoptlocscore{t[j' \Rng 
  j]}{t[1\Rng j'-1]t[j+1\Rng m]})$, se $1 \leq j' \leq j \leq m$,
  \item $\dupw{s}{i'}{i}=\xomega{s}{i'}{i}+ \max( 
  \alignoptlocscore{s[i' \Rng i]}{t},\alignoptlocscore{s[i' \Rng 
  i]}{s[1\Rng i'-1]s[i+1\Rng n]})$, se $1 \leq i' \leq i \leq n$.
\end{itemize}
\end{definicao}

Ou seja, o valor de \dupw{t}{j'}{j} é o valor máximo dentre as pontuações 
associadas aos possíveis \intrep\ por \dup\ $[k_1,k_2]$ de um alinhamento com 
\dups\ \aligndupsym\ de $s$ e $t$ tal que, $\excludefunc(\aligndupsym[1,k_1\Rng 
k_2], \{\aligngapd\})=(j',j'+1,\ldots,j)$. De modo similar, o valor de 
\dupw{s}{i'}{i} é o valor máximo dentre as pontuações associadas aos possíveis 
\intrep\ por excisão $[k_1,k_2]$ de um alinhamento com \dups\ \aligndupsym\ de 
$s$ e $t$ tal que, $\excludefunc(\aligndupsym[0,k_1\Rng k_2], 
\{\aligngapd\})=(i',i'+1,\ldots,i)$.
% e não existe outro alinhamento com \dups\ \aligndupsym' tal que a pontuação de 
% \aligndupsym' seja maior que a pontuação de \aligndupsym\ e 
% $\excludefunc(\aligndupsym'[1,k_1\Rng k_2], \{\aligngapd\})=(j',j'+1,\ldots,j)$.

Portanto, temos que 
$$\mt{i}{j}= \maxnew{j'}{1\leq j'\leq j 
}{M[i,j'-1]+\dupw{t}{j'}{j}}$$

Analogamente, temos que 
$$\ms{i}{j}= \maxnew{i'}{1\leq i'\leq 
i}{M[i'-1,j]+\dupw{s}{i'}{i}}$$

Seja $G=(V,E,\egweigsym)$ um \gredes\ de $s$ e $t$, onde \egweigsym\ é tal que:
\begin{itemize}
  \item $\egweigsym(\egeh{(i,j)})=\homega{t}{j}$,
  \item $\egweigsym(\eged{(i,j)})=\domega{s}{t}{i}{j}$,
  \item $\egweigsym(\egev{(i,j)})=\vomega{s}{i}$,
  \item $\egweigsym(\egex{(i',j')}{(i,j)})=\dupw{s}{i'+1}{i}$, se $i' \neq i$ e 
  $j' = j$,
  \item $\egweigsym(\egex{(i',j')}{(i,j)})=\dupw{t}{j'+1}{j}$, se $i' = i$ e $j' 
  \neq j$,
  \item $\egweigsym(\egex{(i',j')}{(i,j)})=-\infty$ se $i' \neq i$ e $j' \neq 
  j$.
\end{itemize}

Pode-se verificar que o peso de um caminho ótimo em $G$ é igual a pontuação de
um alinhamento ótimo com \dups\ de $s$ e $t$.

Dado que, existem $O(n^3)$ arestas estendidas $\egex{(i',j')}{(i,j)}$ tal que 
$i' \neq i$ ou $j' \neq j$, e que a obtenção do valor $\dupw{s}{i'}{i}$ assim 
como do valor $\dupw{t}{j'}{j}$ levam tempo $O(n^2)$, temos que, dadas as 
\seqs\ $s$ e $t$, um algoritmo trivial, que obtém o peso de um caminho ótimo em 
$G$, executa em tempo $O(n^5)$.

% a obtenção do valor de $\alignoptlocscore{t[j' \Rng j]}{s}$ (assim 
% como de $\alignoptlocscore{t[j' \Rng j]}{t[1\Rng j'-1]t[j+1\Rng m]})$, 
% \alignoptlocscore{s[i' \Rng i]}{t} e \alignoptlocscore{s[i' \Rng i]}{s[1\Rng 
% i'-1]s[i+1\Rng n]})) leva tempo $O(n^2)$, um algoritmo trivial que, dadas as \seqs\ $s$ e
% $t$, obtém o peso de um caminho ótimo em $G$, executa em tempo $O(n^4)$.

A seguir descreveremos um algoritmo que, dadas as \seqs\ $s$ e $t$, obtém o 
peso de um caminho ótimo em $G$ em tempo $O(n^3)$ e utilizando $O(n^2)$ de 
espaço.


% Se $\dupi{s}{t}{i}{j'}{j}=\dupi{s}{t}{i'}{j'}{j}$, para todo $i'$ tal que $0 \leq
% i' \leq n$, então dizemos que $\dupi{s}{t}{i}{j'}{j}=\fmii{t}{j'}{j}$. Da mesma
% forma, se $\dupi{t}{s}{j}{i'}{i}=\dupi{t}{s}{j'}{i'}{i}$, para todo $j'$ tal que $0 \leq
% j' \leq m$, então dizemos que $\dupi{t}{s}{j}{i'}{i}=\fmii{s}{i'}{i}$.
% 


\section{Algoritmo para alinhamento com \dups}
\label{sec:aligndupalg}

Para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ definimos os
conjuntos de fatores das \seqs\ $s$ e $t$, \setA{t}{j'}{j}, \setB{t}{j'}{j},
\setC{t}{j'}{j} e \setD{s} da seguinte forma:
\begin{enumerate}
  \item $\setA{t}{j'}{j} = \{t[j_1 \Rng j_2]\tq 0 < j_1 \leq j_2+1 \leq j'\}$,
  \item $\setB{t}{j'}{j} = \{t[j_3 \Rng j_4]\tq j < j_3 \leq j_4+1 \leq |t|+1\}$,
  \item $\setC{t}{j'}{j} = \{t[j_5 \Rng j'-1]t[j+1 \Rng j_6]\tq 0 < j_5 \leq j' 
  \textrm{ e } j \leq j_6 \leq |t|\}$ e
  \item $\setD{s} = \{s[i_1 \Rng i_2]\tq 1 \leq i_1 \leq i_2+1 \leq 
  |s|+1\}$.
\end{enumerate}

Para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ definimos, para cada 
conjunto \setA{t}{j'}{j}, \setB{t}{j'}{j}, \setC{t}{j'}{j} e 
\setD{s}, a pontuação máxima do alinhamento ótimo sem \dups\ de $t[j' 
\Rng j]$ com um elemento do conjunto da seguinte forma: 
\begin{align*}\bestScoreA{t}{j'}{j}&= \max(\alignoptscore{t[j'\Rng 
j]}{\seqbaseLetter}\tq \seqbaseLetter \in \setA{t}{j'}{j})\\
&= \maxnew{j_1,j_2}{0 < j_1 \leq j_2+1 \leq 
j'}{\alignoptscorest{t}{t}{j'}{j}{j_1}{j_2}}\textrm{,}\end{align*}

\begin{align*}\bestScoreB{t}{j'}{j}&= 
\max(\alignoptscore{t[j' \Rng j]}{\seqbaseLetter}\tq \seqbaseLetter \in 
\setB{t}{j'}{j})\\&= \maxnew{j_3,j_4}{j < j_3 \leq j_4+1 \leq m+1}{\alignoptscorest{t}{t}{j'}{j}{j_3}{j_4}}\textrm{,}\end{align*} 

\begin{align*}
\bestScoreC{t}{j'}{j}&= 
\max(\alignoptscore{t[j' \Rng j]}{\seqbaseLetter}\tq \seqbaseLetter \in 
\setC{t}{j'}{j})\\
&= \maxnew{j_5,j_6}{0 < j_5 \leq j' 
  \textrm{ e } j \leq j_6 \leq m}{\alignoptscore{t[j' \Rng j]}{t[j_5 \Rng j'-1]t[j+1 \Rng j_6]}}\textrm{ e
}\end{align*}  

 \begin{align*}
 \bestScoreD{t}{s}{j'}{j}&= 
\max(\alignoptscore{t[j' \Rng j]}{\seqbaseLetter}\tq \seqbaseLetter \in
  \setD{s})
  \\&= \maxnew{i_1,i_2}{1 \leq i_1 \leq i_2+1 \leq n+1} 
  {\alignoptscorest{t}{s}{j'}{j}{i_1}{i_2}}\textrm{.}\end{align*}

Portanto, para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$, temos que
\begin{displaymath}
\dupw{t}{j'}{j}=\max\left( \begin{array}{l}
\bestScoreA{t}{j'}{j}\\
\bestScoreB{t}{j'}{j}\\
\bestScoreC{t}{j'}{j}\\
\bestScoreD{t}{s}{j'}{j}
\end{array}\right)+\uomega{t}{j'}{j} \textrm{.}
\end{displaymath} 

A seguir, analisaremos separadamente cada um destes valores que podem compor a
função  \dupw{t}{j'}{j}: \bestScoreA{t}{j'}{j}, \bestScoreB{t}{j'}{j}, 
\bestScoreC{t}{j'}{j} e \bestScoreD{t}{s}{j'}{j}; e vamos propor algoritmos para
construir matrizes com os valores pré-computados destas funções.


\subsection{Função \bestScoreA{t}{j'}{j}}

Seja $\alignsym$ um alinhamento ótimo de $t[j'+1 \Rng j]\times t[j_1+1 \Rng 
j_2]$, tal que não existe outro alinhamento de $t[j'+1 \Rng j] \times t[j_1'+1 
\Rng j_2]$ com pontuação maior que a pontuação de $\alignsym$, onde $j'$, $j$, 
$j_1$, $j_2$ e $j_1'$ são tais que $0 \leq j_1 \leq j_2 \leq j' \leq j \leq m$ 
e $0 \leq j_1' \leq j_2$. Diremos que este é um \emph{alinhamento ótimo para 
$j_2$ em \setA{t}{j'+1}{j}}. Se o comprimento de $\alignsym$ é igual a zero, o 
que acontece somente se $j_1 = j_2$ e $j'= j$, então a pontuação de $\alignsym$ 
também é zero. Se o comprimento de $\alignsym$ é $r+1$ e é maior que zero então 
a última coluna de $\alignsym$ é de uma das seguintes formas:
\begin{itemize}
  \item $A[0,r]=t[j]$ e $A[1,r]=\aligngap$. Neste caso, o alinhamento formado 
  pelas primeiras $r-1$ linhas de $\alignsym$ é um alinhamento ótimo para $j_2$ 
  em \setA{t}{j'+1}{j-1} e portanto a pontuação de $\alignsym$ é igual a 
  pontuação de um alinhamento ótimo para $j_2$ em \setA{t}{j'+1}{j-1} mais o 
  valor $\vomegad{t}{j}$.
  \item $A[1,r]=t[j_2]$ e $A[0,r]=\aligngap$. Neste caso, o alinhamento formado 
  pelas primeiras $r-1$ linhas de $\alignsym$ é um alinhamento ótimo para 
  $j_2-1$ em \setA{t}{j'+1}{j} e portanto a pontuação de $\alignsym$ é igual a 
  pontuação de um alinhamento ótimo para $j_2-1$ em \setA{t}{j'+1}{j} mais o 
  valor $\homegad{t}{j_2}$.
  \item $A[0,r]=t[j]$ e $A[1,r]=t[j_2]$. Neste caso, o alinhamento formado 
  pelas primeiras $r-1$ linhas de $\alignsym$ é um alinhamento ótimo para 
  $j_2-1$ em \setA{t}{j'+1}{j-1} e portanto a pontuação de $\alignsym$ é igual 
  a pontuação de um alinhamento ótimo para $j_2-1$ em \setA{t}{j'+1}{j-1} mais 
  o valor $\domegad{t}{t}{j}{j_2}$.
\end{itemize}

A Figura~\ref{fig:semigalignA} ilustra os caminhos num \gred\ para a obtenção 
da pontuação de um alinhamento ótimo para $j_2$ em \setA{t}{j'+1}{j}.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{semigalignA}
% \end{center}
\caption[Caminhos para calcular \wbestScoreAj{t}{j_2}{j'}{j}]{Ilustração das 3
possibilidades de um caminho ótimo até $(j,j_2)$ a partir de qualquer vértice da
linha $j'$. As linhas tracejadas indicam caminhos ótimos de qualquer vértice da
linha $j'$ até $(j,j_2-1)$, $(j-1,j_2-1)$ e $(j-1,j_2)$.}
 \label{fig:semigalignA}
\end{figure}


Com isto, vamos definir a matriz \wbestScoreAjm{t} tal que, 
\wbestScoreAj{t}{j_2}{j'}{j} contém a pontuação de um alinhamento ótimo para 
$j_2$ em \setA{t}{j'+1}{j}.

Seja \wbestScoreAjm{t} a matriz $(m+1) \times (m+1) \times (m+1)$ definida por
\begin{itemize}
  \item $\wbestScoreAj{t}{0}{j'}{j}=0$, se $0 \leq j'= j \leq m$,
  \item 
  $\wbestScoreAj{t}{0}{j'}{j}=\wbestScoreAj{t}{0}{j'}{j-1}+\vomegad{t}{j}$, se 
  $0 \leq j' < j \leq m$,
  \item $\wbestScoreAj{t}{j_2}{j'}{j}=\max\left(\begin{array}{l}0,\\
  \wbestScoreAj{t}{j_2-1}{j'}{j}+\homegad{t}{j_2}\end{array}\right)$, se $0 \leq 
  j' = j \leq m$ e $1 \leq j_2 \leq j'$,
  \item $\wbestScoreAj{t}{j_2}{j'}{j}=\max\left(\begin{array}{l} 
  \wbestScoreAj{t}{j_2-1}{j'}{j}+\homegad{t}{j_2},\\
  \wbestScoreAj{t}{j_2}{j'}{j-1}+\vomegad{t}{j},\\
  \wbestScoreAj{t}{j_2-1}{j'}{j-1}+\domegad{t}{t}{j_2}{j}\end{array}\right)$, se 
  $0 \leq j' < j \leq m$ e $1 \leq j_2 \leq j'$,
  \item $\wbestScoreAj{t}{j_2}{j'}{j}=-\infty$, se $0 \leq j < j' \leq m$ ou 
  $j' < j_2 \leq m$.
\end{itemize}


Seja \wbestScoreAm{t} a matriz $(m+1) \times (m+1)$ tal que
\begin{displaymath}
\wbestScoreA{t}{j'}{j} = \maxnew{j_2}{0 \leq j_2 \leq j'}{
\wbestScoreAj{t}{j_2}{j'}{j}}\textrm{.}
\end{displaymath}

Ou seja, \wbestScoreA{t}{j'}{j} contém o valor máximo do alinhamento ótimo sem 
duplicações de $t[j'+1 \Rng j]\times \seqbaseLetter$, $\forall\ \seqbaseLetter 
\in \setA{t}{j'+1}{j}$.

Para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ temos que 
$\bestScoreA{t}{j'}{j} = \wbestScoreA{t}{j'-1}{j}$.

O Algoritmo~\ref{alg:buildwa} constrói a matriz \wbestScoreAm{t} utilizando as recorrências
descritas acima. O algoritmo utiliza programação dinâmica e executa em tempo
$O(n^3)$ e espaço $O(n^2)$.

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWA}{t}
  \COM {$\wAj{j_2}{j}=\wbestScoreAj{t}{j_2}{j'}{j}$}
  \DOFORI {j'} {0} {|t|}
    \SET{j}{j'}
    \SET{j_2}{0}
	\SET{\wAj{j_2}{j}}{0}
	\SET{\wA{j'}{j}}{\wAj{j_2}{j}}
    \DOFORI {j_2} {1} {j'}
		\SET{\wAj{j_2}{j}}{\max(0,\wAj{j_2-1}{j}+\homegad{t}{j_2})}
		\SET{\wA{j'}{j}}{\max(\wA{j'}{j},\wAj{j_2}{j})}
	\OD		
	\DOFORI {j} {j'+1} {|t|}
	    \SET{j_2}{0}
		\SET{\wAj{j_2}{j}}{\wAj{j_2}{j-1}+\vomegad{t}{j}}
		\SET{\wA{j'}{j}}{\wAj{j_2}{j}}
    	\DOFORI {j_2} {1} {j'}
    		\SET{h}{\wAj{j_2-1}{j}+\homegad{t}{j_2}}
    		\SET{v}{\wAj{j_2}{j-1}+\vomegad{t}{j}}
    		\SET{d}{\wAj{j_2-1}{j-1}+\domegad{t}{t}{j_2}{j}}
			\SET{\wAj{j_2}{j}}{\max(h, v, d)}
			\SET{\wA{j'}{j}}{\max(\wA{j'}{j},\wAj{j_2}{j})}
		\OD
  	\OD
  \OD 
\RETURN {\WA} 
\caption[BUILDWA]{Algoritmo para a construção da matriz \wbestScoreAm{t}}
  \label{alg:buildwa}
  \end{algo}
\end{algorithm}



% Se existe $\seqbaseLetter \in \setA{t}{j'}{j}$ tal que o alinhamento ótimo sem 
% duplicações de $\seqbaseLetter \times t[j' \Rng j]$ é igual a 
% $\bestScoreA{t}{j'}{j}$ então $\bestScoreA{t}{j'}{j} = 
% \wbestScoreA{t}{j'-1}{j}$, $1 \leq j' \leq j \leq m$.
% 
% Para o calculo de \dupw{t}{j'}{j}, consideraremos que $\bestScoreA{t}{j'}{j} =
% \wbestScoreA{t}{j'-1}{j}$, $1 \leq j' \leq j \leq m$.

\subsection{Função \bestScoreB{t}{j'}{j}}

Equivalentemente como feito para a matriz \wbestScoreAjm{t}, vamos definir a 
matriz \wbestScoreBjm{t} tal que, \wbestScoreBj{t}{j_3}{j'}{j} contém a 
pontuação de um alinhamento ótimo \alignsym\ de $t[j'+1 \Rng j] \times t[j_3+1 
\Rng j_4]$ e não existe outro alinhamento ótimo de $t[j'+1 \Rng j] \times 
t[j_3+1 \Rng j_4']$ cuja pontuação seja maior que a de \alignsym, onde 
$t[j_3+1 \Rng j_4] \in \setB{t}{j'+1}{j}$ e $t[j_3+1 \Rng j_4'] \in 
\setB{t}{j'+1}{j}$.

Seja \wbestScoreBjm{t} a matriz $(m+1) \times (m+1) \times (m+1)$ definida por
\begin{itemize}
  \item $\wbestScoreBj{t}{m}{j'}{j}=0$, se $0 \leq j'= j \leq m$,
  \item 
  $\wbestScoreBj{t}{m}{j'}{j}=\wbestScoreBj{t}{m}{j'+1}{j}+\vomegad{t}{j'+1}$, 
  se $0 \leq j' < j \leq m$,
  \item $\wbestScoreBj{t}{j_3}{j'}{j}=\max\left(\begin{array}{l}0,\\
  \wbestScoreBj{t}{j_3+1}{j'}{j}+\homegad{t}{j_3+1}\end{array}\right)$, se $0 
  \leq j' = j \leq m$ e $j \leq j_3 < m$,
  \item $\wbestScoreBj{t}{j_3}{j'}{j}=\max\left(\begin{array}{l} 
  \wbestScoreBj{t}{j_3+1}{j'}{j}+\homegad{t}{j_3+1},\\
  \wbestScoreBj{t}{j_3}{j'+1}{j}+\vomegad{t}{j'+1},\\
  \wbestScoreBj{t}{j_3+1}{j'+1}{j}+\domegad{t}{t}{j_3+1}{j'+1}\end{array}\right)$, 
  se $0 \leq j' < j \leq m$ e $j \leq j_3 < m$,
  \item $\wbestScoreBj{t}{j_3}{j'}{j}=-\infty$, se $0 \leq j < j' \leq m$ ou $0 
  \leq j_3 < j$.
\end{itemize}

Ou seja, \wbestScoreBj{t}{j_3}{j'}{j} contém o valor máximo do alinhamento 
ótimo sem duplicações de $t[j'+1 \Rng j]\times t[j_3+1 \Rng j_4]$, $\forall\ j_4 \tq\ 
j_3 \leq j_4 \leq m$.

A Figura~\ref{fig:semigalignB} ilustra os caminhos num \gred\ para a obtenção 
do valor de \wbestScoreBj{t}{j_3}{j'}{j}.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{semigalignB}
% \end{center}
\caption[Caminhos para calcular \wbestScoreBj{t}{j_3}{j'}{j}]{Ilustração das 3 possibilidades de um 
caminho ótimo de pontuação máxima a partir de $(j',j_3)$ até qualquer vértice 
da linha $j$. As linhas tracejadas indicam caminhos ótimos de pontuação máxima 
de $(j',j_3+1)$, $(j'+1,j_3+1)$ e $(j'+1,j_3)$  até qualquer vértice da linha 
$j$.}
 \label{fig:semigalignB}
\end{figure}


Seja \wbestScoreBm{t} a matriz $(m+1) \times (m+1)$ tal que
\begin{displaymath}
\wbestScoreB{t}{j'}{j} = \maxnew{j_3}{j \leq j_3 \leq m}{
\wbestScoreBj{t}{j_3}{j'}{j}}\textrm{.}
\end{displaymath}

Ou seja, \wbestScoreB{t}{j'}{j} contém o valor máximo do alinhamento ótimo sem 
duplicações de $t[j'+1 \Rng j]\times \seqbaseLetter$, $\forall\ \seqbaseLetter \in 
\setB{t}{j'+1}{j}$.

Para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ temos que 
$\bestScoreB{t}{j'}{j} = \wbestScoreB{t}{j'-1}{j}$.

O Algoritmo~\ref{alg:buildwb} constrói a matriz \wbestScoreBm{t} utilizando as 
recorrências descritas acima. O algoritmo utiliza programação dinâmica e 
executa em tempo $O(n^3)$ e espaço $O(n^2)$.

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWB}{t}
  \COM {$\wBj{j_3}{j'}=\wbestScoreBj{t}{j_3}{j'}{j}$}   
  \DOFORI {j} {0} {|t|}
    \SET{j_3}{|t|}
    \SET{j'}{j}
	\SET{\wBj{j_3}{j'}}{0}
	\SET{\wB{j'}{j}}{0}
    \DOFORD {j_3} {|t|-1} {j}
		\SET{\wBj{j_3}{j'}}{\max(0,\wBj{j_3+1}{j'}+\homegad{t}{j_3+1})}
		\SET{\wB{j'}{j}}{\max(\wB{j'}{j},\wBj{j_3}{j'})}
	\OD		
	\DOFORD {j'} {j-1} {0}
		\SET{j_3}{|t|}
		\SET{\wBj{j_3}{j'}}{\wBj{j_3}{j'+1}+\vomegad{t}{j'+1}}
		\SET{\wB{j'}{j}}{\wBj{j_3}{j'}}
    	\DOFORI {j_3} {|t|-1} {j}
    		\SET{h}{\wBj{j_3+1}{j'}+\homegad{t}{j_3+1}}
    		\SET{v}{\wBj{j_3}{j'+1}+\vomegad{t}{j'+1}}
    		\SET{d}{\wBj{j_3+1}{j'+1}+\domegad{t}{t}{j_3+1}{j'+1}}
			\SET{\wBj{j_3}{j'}}{\max(h, v, d)}
			\SET{\wB{j'}{j}}{\max(\wB{j'}{j},\wBj{j_3}{j'})}
		\OD
  	\OD
  \OD
\RETURN {\WB} 
\caption[BUILDWB]{Algoritmo para a construção da matriz \wbestScoreBm{t}}
  \label{alg:buildwb}
  \end{algo}
\end{algorithm}


\subsection{Função \bestScoreC{t}{j'}{j}}

Seja \wbestScoreCjm{t} a matriz $(m+1) \times (m+1)$ tal que
\begin{displaymath}
\wbestScoreCj{t}{j'}{j}=\wbestScoreAj{t}{j'}{j'}{j}\textrm{, }\forall\ j', j 
\tq\ 0 \leq j'\leq j \leq m \textrm{.}
\end{displaymath}

Ou seja, \wbestScoreCj{t}{j'}{j}, $0 \leq j' \leq j$, contém o valor máximo do 
alinhamento ótimo sem duplicações de $t[j'+1 \Rng j]\times t[j_5+1 \Rng j']$, $\forall\ 
j_5 \tq 0 \leq j_5 \leq j'$.

Seja \wbestScoreCjjm{t} a matriz $(m+1) \times (m+1)$ tal que
\begin{displaymath}
\wbestScoreCjj{t}{j'}{j}=\wbestScoreBj{t}{j}{j'}{j}\textrm{, }\forall\ j', j 
\tq\ 0 \leq j'\leq j \leq m \textrm{.}
\end{displaymath}

Ou seja, \wbestScoreCjj{t}{j'}{j}, $0 \leq j' \leq j$, contém o valor máximo do 
alinhamento ótimo sem duplicações de $t[j'+1 \Rng j]\times t[j+1 \Rng j_6]$, $\forall\ 
j_6 \tq j \leq j_6 \leq m$.

Seja \wbestScoreCm{t} a matriz $(m+1) \times (m+1)$ tal que
\begin{displaymath}
\wbestScoreC{t}{j'}{j} = \maxnew{j_7}{j' \leq j_7 \leq j}{
\wbestScoreCj{t}{j'}{j_7}+\wbestScoreCjj{t}{j_7}{j}}\textrm{, }\forall\ j', j 
\tq\ 0 \leq j'\leq j \leq m \textrm{.}
\end{displaymath}

Ou seja, \wbestScoreC{t}{j'}{j} contém o valor máximo do alinhamento ótimo sem 
duplicações de $t[j'+1 \Rng j]\times \seqbaseLetter$, $\forall\ \seqbaseLetter \in 
\setC{t}{j'+1}{j}$.

A Figura~\ref{fig:semigalignC} ilustra os caminhos num \gred\ para a obtenção 
do valor de \wbestScoreC{t}{j'}{j}.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{semigalignC}
% \end{center}
\caption[Caminhos para calcular \wbestScoreC{t}{j'}{j}]{Os caminhos ótimos de $(j',j_5)$ a $(j_7,j')$ 
e de $(j_7,j)$ a $(j,j_6)$ são utilizados para obter o valor de
\wbestScoreC{t}{j'}{j}.}
 \label{fig:semigalignC}
\end{figure}

Para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ temos que 
$\bestScoreC{t}{j'}{j} = \wbestScoreC{t}{j'-1}{j}$.

Os Algoritmos~\ref{alg:buildwc1}~e~\ref{alg:buildwc2} constroem as matrizes 
\WCj e \WCjj, respectivamente. Com estas matrizes, o 
Algoritmo~\ref{alg:buildwc} constrói a matriz \wbestScoreCm{t}. Esses 
algoritmos utilizam as equações descritas acima. Os algoritmos utilizam 
programação dinâmica e executam em tempo $O(n^3)$ e espaço $O(n^2)$.

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWC1}{t}
  \COM {$\wAj{j_2}{j}=\wbestScoreAj{t}{j_2}{j'}{j}$}
  \COM {$\wCj{j'}{j}=\wAj{j'}{j}=\wbestScoreAj{t}{j'}{j'}{j}$}
  \DOFORI {j'} {0} {|t|}
    \SET{j}{j'}
    \SET{j_2}{0}
	\SET{\wAj{j_2}{j}}{0}
    \DOFORI {j_2} {1} {j'}
		\SET{\wAj{j_2}{j}}{\max(0,\wAj{j_2-1}{j}+\homegad{t}{j_2})}
	\OD		
	\SET{\wCj{j'}{j}}{\wAj{j'}{j}}
	\DOFORI {j} {j'+1} {|t|}
		\SET{j_2}{0}
		\SET{\wAj{j_2}{j}}{\wAj{j_2}{j-1}+\vomegad{t}{j}}
    	\DOFORI {j_2} {1} {j'}
    		\SET{h}{\wAj{j_2-1}{j}+\homegad{t}{j_2}}
    		\SET{v}{\wAj{j_2}{j-1}+\vomegad{t}{j}}
    		\SET{d}{\wAj{j_2-1}{j-1}+\domegad{t}{t}{j_2}{j}}
			\SET{\wAj{j_2}{j}}{\max(h, v, d)}
		\OD
		\SET{\wCj{j'}{j}}{\wAj{j'}{j}}
  	\OD
  \OD 
\RETURN {\WCj} 
\caption[BUILDWC1]{Algoritmo para a construção da matriz \WCj}
  \label{alg:buildwc1}
  \end{algo}
\end{algorithm}

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWC2}{t}
  \COM {$\wBj{j_3}{j'}=\wbestScoreBj{t}{j_3}{j'}{j}$}   
  \COM {$\wCjj{j'}{j}=\wBj{j}{j'}=\wbestScoreBj{t}{j}{j'}{j}$}
  \DOFORI {j} {0} {|t|}
    \SET{j_3}{|t|}
    \SET{j'}{j}
	\SET{\wBj{j_3}{j'}}{0}
    \DOFORD {j_3} {|t|-1} {j}
		\SET{\wBj{j_3}{j'}}{\max(0,\wBj{j_3+1}{j'}+\homegad{t}{j_3+1})}
	\OD		
	\SET{\wCjj{j'}{j}}{\wBj{j}{j'}}
	\DOFORD {j'} {j-1} {0}
		\SET{j_3}{|t|}
		\SET{\wBj{j_3}{j'}}{\wBj{j_3}{j'+1}+\vomegad{t}{j'+1}}
    	\DOFORI {j_3} {|t|-1} {j}
    		\SET{h}{\wBj{j_3+1}{j'}+\homegad{t}{j_3+1}}
    		\SET{v}{\wBj{j_3}{j'+1}+\vomegad{t}{j'+1}}
    		\SET{d}{\wBj{j_3+1}{j'+1}+\domegad{t}{t}{j_3+1}{j'+1}}
			\SET{\wBj{j_3}{j'}}{\max(h, v, d)}
		\OD
		\SET{\wCjj{j'}{j}}{\wBj{j}{j'}}
  	\OD
  \OD
\RETURN {\WCjj} 
\caption[BUILDWC2]{Algoritmo para a construção da matriz \WCjj}
  \label{alg:buildwc2}
  \end{algo}
\end{algorithm}

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWC}{t}
  \SET{\WCj}{BUILDWC1(t)}
  \SET{\WCjj}{BUILDWC2(t)}
   \DOFORI {j'} {0} {|t|}
  	\DOFORI {j} {j'} {|t|}
		\SET{\wC{j'}{j}}{\wCj{j'}{j'}+\wCjj{j'}{j}}
   		\DOFORI {j_7} {j'+1} {j}
			\SET{\wC{j'}{j}}{\max(\wC{j'}{j},\wCj{j'}{j_7}+\wCjj{j_7}{j})}
  		\OD
  	\OD
  \OD
\RETURN {\WC} 
\caption[BUILDWC]{Algoritmo para a construção da matriz \WC}
  \label{alg:buildwc}
  \end{algo}
\end{algorithm}


\subsection{Função \bestScoreD{t}{s}{j'}{j}}

Equivalentemente como foi feito para a matriz \wbestScoreAjm{t}, vamos definir a
 matriz \wbestScoreDjm{t}{s} tal que, \wbestScoreDj{t}{s}{i_2}{j'}{j} contém a 
pontuação de um alinhamento ótimo \alignsym\ de $t[j'+1 \Rng j] \times s[i_1+1 
\Rng i_2]$ e não existe outro alinhamento ótimo de $t[j'+1 \Rng j] \times 
s[i_1'+1 \Rng i_2]$ cuja pontuação seja maior que a de \alignsym, onde 
$s[i_1+1 \Rng i_2] \in \setD{s}$ e $s[i_1'+1 \Rng i_2] \in 
\setD{s}$.

Seja \wbestScoreDjm{t}{s} a matriz $(n+1) \times (m+1) \times (m+1)$ definida 
por
\begin{itemize}
  \item $\wbestScoreDj{t}{s}{0}{j'}{j}=0$, se $0 \leq j'= j \leq m$,
  \item 
  $\wbestScoreDj{t}{s}{0}{j'}{j}=\wbestScoreDj{t}{s}{0}{j'}{j-1}+\vomegad{t}{j}$, se 
  $0 \leq j' < j \leq m$,
  \item $\wbestScoreDj{t}{s}{i_2}{j'}{j}=\max\left(\begin{array}{l}0,\\
  \wbestScoreDj{t}{s}{i_2-1}{j'}{j}+\homegad{s}{i_2}\end{array}\right)$, se $0 
  \leq j' = j \leq m$ e $1 \leq i_2 \leq n$,
  \item $\wbestScoreDj{t}{s}{i_2}{j'}{j}=\max\left(\begin{array}{l} 
  \wbestScoreDj{t}{s}{i_2-1}{j'}{j}+\homegad{s}{i_2},\\
  \wbestScoreDj{t}{s}{i_2}{j'}{j-1}+\vomegad{t}{j},\\
  \wbestScoreDj{t}{s}{i_2-1}{j'}{j-1}+\domegad{s}{t}{i_2}{j}\end{array}\right)$, 
  se $0 \leq j' < j \leq m$ e $1 \leq i_2 \leq n$,
  \item $\wbestScoreDj{t}{s}{i_2}{j'}{j}=-\infty$, se $0 \leq j < j' \leq m$.
\end{itemize}

Ou seja, \wbestScoreDj{t}{s}{i_2}{j'}{j} contém o valor máximo do alinhamento 
ótimo sem duplicações de $t[j'+1 \Rng j]\times s[i_1+1 \Rng i_2]$, $\forall\ i_1 \tq\ 0 
\leq i_1 \leq n$.

A Figura~\ref{fig:semigalignD} ilustra os caminhos num \gred\ para a obtenção 
do valor de \wbestScoreDj{t}{s}{i_2}{j'}{j}.

\begin{figure}[htbp] \centering 
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{semigalignD}
% \end{center}
\caption[Caminhos para calcular \wbestScoreDj{t}{s}{i_2}{j'}{j}]{Ilustração das 3 possibilidades de um 
caminho ótimo de pontuação máxima a partir de qualquer vértice da linha $j'$ 
até $(j,i_2)$. As linhas tracejadas indicam caminhos ótimos de pontuação máxima 
de qualquer vértice da linha $j'$ até $(j,i_2-1)$, $(j-1,i_2-1)$ e $(j-1,i_2)$.}
 \label{fig:semigalignD}
\end{figure}

Seja \wbestScoreDm{t}{s} a matriz $(m+1) \times (m+1)$ tal que
\begin{displaymath}
\wbestScoreD{t}{s}{j'}{j} = \maxnew{i_2}{0 \leq i_2 \leq n}{
\wbestScoreDj{t}{s}{i_2}{j'}{j}}\textrm{.}
\end{displaymath}

Ou seja, \wbestScoreD{t}{s}{j'}{j} contém o valor máximo do alinhamento ótimo 
sem duplicações de $t[j'+1 \Rng j]\times \seqbaseLetter$, $\forall\ \seqbaseLetter 
\in \setD{s}$.

Para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ temos que 
$\bestScoreD{t}{s}{j'}{j} = \wbestScoreD{t}{s}{j'-1}{j}$.

O Algoritmo~\ref{alg:buildwd} constrói a matriz \wbestScoreDm{t}{s} utilizando as 
recorrências descritas acima. O algoritmo utiliza programação dinâmica e 
executa em tempo $O(n^3)$ e espaço $O(n^2)$.

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWD}{t,s}
  \COM {$\wDj{i_2}{j}=\wbestScoreDj{t}{s}{i_2}{j'}{j}$}
  \DOFORI {j'} {0} {|t|}
    \SET{i_2}{0}
    \SET{j}{j'}
	\SET{\wDj{i_2}{j}}{0}
	\SET{\wD{j'}{j}}{\wDj{i_2}{j}}
    \DOFORI {i_2} {1} {|s|}
		\SET{\wDj{i_2}{j}}{\max(0,\wDj{i_2-1}{j}+\homegad{s}{i_2})}
		\SET{\wD{j'}{j}}{\max(\wD{j'}{j},\wDj{i_2}{j})}
	\OD		
	\DOFORI {j} {j'+1} {|t|}
	    \SET{i_2}{0}
		\SET{\wDj{i_2}{j}}{\wDj{i_2}{j-1}+\vomegad{t}{j}}
		\SET{\wD{j'}{j}}{\wDj{i_2}{j}}
    	\DOFORI {i_2} {1} {|s|}
    		\SET{h}{\wDj{i_2-1}{j}+\homegad{s}{i_2}}
    		\SET{v}{\wDj{i_2}{j-1}+\vomegad{t}{j}}
    		\SET{d}{\wDj{i_2-1}{j-1}+\domegad{s}{t}{i_2}{j}}
			\SET{\wDj{i_2}{j}}{\max(h, v, d)}
			\SET{\wD{j'}{j}}{\max(\wD{j'}{j},\wDj{i_2}{j})}
		\OD
  	\OD
  \OD  
\RETURN {\WD} 
\caption[BUILDWD]{Algoritmo para a construção da matriz \wbestScoreDm{t}{s}}
  \label{alg:buildwd}
  \end{algo}
\end{algorithm}


\subsection{Função \dupw{t}{j'}{j} e \mt{i}{j}}
\label{sec:dupmt}
Utilizando as matrizes definidas anteriormente, temos que
\begin{displaymath}
\dupw{t}{j'}{j}=\max\left( \begin{array}{l}
\wbestScoreA{t}{j'-1}{j}\\
\wbestScoreB{t}{j'-1}{j}\\
\wbestScoreC{t}{j'-1}{j}\\
\wbestScoreD{t}{s}{j'-1}{j}
\end{array}\right)+\uomega{t}{j'}{j} \textrm{.}
\end{displaymath} 

Analogamente, temos que
\begin{displaymath}
\dupw{s}{i'}{i}=\max\left( \begin{array}{l}
\wbestScoreA{s}{i'-1}{i}\\
\wbestScoreB{s}{i'-1}{i}\\
\wbestScoreC{s}{i'-1}{i}\\
\wbestScoreD{s}{t}{i'-1}{i}
\end{array}\right)+\xomega{s}{i'}{i} \textrm{.}
\end{displaymath} 

Logo, temos que 
$$\mt{i}{j}=\maxnew{j'}{1\leq j'\leq j}{M[i,j'-1]+\max\left( \begin{array}{l}
\wbestScoreA{t}{j'-1}{j}\\
\wbestScoreB{t}{j'-1}{j}\\
\wbestScoreC{t}{j'-1}{j}\\
\wbestScoreD{t}{s}{j'-1}{j}
\end{array}\right)+\uomega{t}{j'}{j}}\textrm{,}$$

e que

$$\ms{i}{j}=\maxnew{i'}{1\leq i'\leq 
i}{M[i'-1,j]+\max\left( \begin{array}{l}
\wbestScoreA{s}{i'-1}{i}\\
\wbestScoreB{s}{i'-1}{i}\\
\wbestScoreC{s}{i'-1}{i}\\
\wbestScoreD{s}{t}{i'-1}{i}
\end{array}\right)+\xomega{s}{i'}{i}}\textrm{.}$$

\subsection{Algoritmo DUP}

O Algoritmo~\ref{alg:dup} constrói a matriz $M$ de acordo com a 
recorrência~\ref{eq:dupM} da página \pageref{eq:dupM} e executa em tempo 
$O(n^3)$ e espaço $O(n^2)$. Os valores de \mt{i}{j} e \ms{i}{j} são obtidos de 
acordo com as equações descritas na seção~\ref{sec:dupmt}.

\begin{algorithm}[htbp]
  \begin{algo}{DUP}{s,t}
% 	\ACTT{Seja $G=(V,E,\omega)$ o grafo de edição de $s$ e $t$}
% 	\COM{Vamos estender o grafo $G$ para um grafo de edição estendido $\widehat G$
% 	de $s$ e $t$. }
	\COM {$M[i,j]=\aligndupoptscorest{s}{t}{1}{i}{1}{j}$}
    \COM {$\dupw{t}{j'}{j}=\wt{j'-1}{j}+\uomega{t}{j'}{j}$}
    \COM {$\dupw{s}{i'}{i}=\ws{i'-1}{i}+\xomega{s}{i'}{i}$}
    \SET {\Wt}{BUILDMAXW(t,s)} \label{alg:dup:buildwt}
    \SET {\Ws}{BUILDMAXW(s,t)} \label{alg:dup:buildws}
    \SET {M[0,0]}{0}
%     \SET {\wj{0}{0}}{0}
    \DOFORI {j} {1} {|t|}
    	\SET {M[0,j]}{M[0,j-1]+\homega{t}{j}}
    	\COM{Obtém \mt{0}{j}}
	    \DOFORI {j'} {0} {j-1}
	    	\SET{dup_t}{\wt{j'}{j}+\uomega{t}{j'+1}{j}}
	    	\SET {M[0,j]}{\max(M[0,j],M[0,j']+dup_t)}
		\OD
	\OD
    
    \DOFORI {i} {1} {|s|} \label{dup4:loop1}
    	\SET {M[i,0]}{M[i-1,0]+\vomega{s}{i})}
    	\COM{Obtém \ms{i}{0}}
	    \DOFORI {i'} {0} {i-1}
	    	\SET{dup_s}{\ws{i'}{i}+\xomega{s}{i'+1}{i}}
	    	\SET {M[i,0]}{\max(M[i,0],M[i',0]+dup_s)}
		\OD
      	\DOFORI {j} {1} {|t|}
      		\SET{h}{M[i,j-1]+\homega{t}{j}}
      		\SET{v}{M[i-1,j]+\vomega{s}{i}}
      		\SET{d}{M[i-1,j-1]+\domega{s}{t}{i}{j}}
    		\SET {M[i,j]}{\max(h,v,d)}
    		\COM{Obtém \mt{i}{j}}
	    	\DOFORI {j'} {0} {j-1}
	    		\SET{dup_t}{\wt{j'}{j}+\uomega{t}{j'+1}{j}}
	    		\SET {M[i,j]}{\max(M[i,j],M[i,j']+dup_t)}
			\OD
    		\COM{Obtém \ms{i}{j}}
			\DOFORI {i'} {0} {i-1}
	    		\SET{dup_s}{\ws{i'}{i}+\xomega{s}{i'+1}{i}}
	    		\SET {M[i,j]}{\max(M[i,j],M[i',j]+dup_s)}
			\OD
		\OD \label{dup4:dirfim} 
	\OD 
\RETURN {M}
 \caption[DUP]{Algoritmo $O(n^3)$ para obter a pontuação de um alinhamento com
 \dups}
  \label{alg:dup}
  \end{algo}
\end{algorithm}


\begin{algorithm}[htbp]
  \begin{algo}{BUILDMAXW}{t,s}
  \SET{\wbestScoreAm{t}}{BUILDWA(t)}
  \SET{\wbestScoreBm{t}}{BUILDWB(t)}
  \SET{\wbestScoreCm{t}}{BUILDWC(t)}
  \SET{\wbestScoreDm{t}{s}}{BUILDWD(t,s)}
  \DOFORI {j} {0} {|t|}
	\DOFORI {j'} {0} {|t|}
		\SET{W[j',j]]}{\max(\wbestScoreA{t}{j'}{j},\wbestScoreB{t}{j'}{j},\wbestScoreC{t}{j'}{j},\wbestScoreD{t}{s}{j'}{j})}
  	\OD
  \OD
  
\RETURN {W} 
\caption[BUILDW]{Algoritmo para a construção da matriz \Wt}
  \label{alg:buildw}
  \end{algo}
\end{algorithm}


O Algoritmo \ref{alg:buildw} constrói as matrizes \Wt\ e \Ws\ quando chamados 
nas linhas~\ref{alg:dup:buildwt}~e~\ref{alg:dup:buildws} do 
Algoritmo~\ref{alg:dup}, respectivamente. O algoritmo executa em tempo $O(n^3)$ 
e espaço $O(n^2)$. O elemento \wt{j'}{j} contém o máximo de 
$(\wbestScoreA{t}{j'}{j}, \wbestScoreB{t}{j'}{j}, \wbestScoreC{t}{j'}{j}, 
\wbestScoreD{t}{s}{j'}{j})$, assim como o elemento \ws{i'}{i} contém o máximo 
de $(\wbestScoreA{s}{i'}{i}, \wbestScoreB{s}{i'}{i}, \wbestScoreC{s}{i'}{i}, 
\wbestScoreD{s}{t}{i'}{i})$.

Fazendo algumas alterações no algoritmo, podemos obter também, além da 
pontuação do alinhamento com \dups\ de $s$ e $t$, o alinhamento propriamente 
dito sem alterar as complexidades de tempo e espaço de execução.

% Neste modelo consideraremos que qualquer fator $t[j_3 \Rng j_4]$, onde $0 < j_3 \leq
% j_4 \leq m$, pode ser uma duplicação de um fator $t[j_1 \Rng j_2]$, tal que 
% \begin{itemize}
%   \item $0 < j_1 \leq j_2 < j_3$ ou
%   \item $j_4 < j_1 \leq j_2 \leq m$ ou
%   \item $t[j_1 \Rng j_2]=t[j_1 \Rng j_3-1]t[j_4+1 \Rng j_2]$ onde $0 < j_1 < j_3$ e $j_4 < j_2 \leq m$.
% \end{itemize}
%   A pontuação da operação de 
%   duplicação dependerá da comparação de $t[j_3 \Rng j_4]$ com $t[j_1 \Rng j_2]$ ou da 
%   comparação de $t[j_3 \Rng j_4]$ com $s[i_1 \Rng i_2]$, onde $s[i_1 \Rng i_2]$ é o fator 
%   de $s$ que alinha com $t[j_1 \Rng j_2]$. As mesmas considerações são feitas para 
%   as duplicações em $s$.
% 
% Seja $\fmiv{s}{t}{i'}{i}{j'}{j}$ o valor da operação de duplicação que 
% considera que $t[j' \Rng j]$ foi duplicado e cuja cópia original é igual à um fator 
% de $s[i' \Rng i]$. Quando consideramos que a cópia original é igual à um sufixo ou 
% a um prefixo de $s[i' \Rng i]$, definimos $\fmiva{s}{t}{i'}{i}{j'}{j}$ e 
% $\fmivb{s}{t}{i'}{i}{j'}{j}$, respectivamente, como o valor da operação de 
% duplicação de $t[j' \Rng j]$.
% 
% Diremos que
% \begin{itemize}
%   \item se $0<j' \leq j \leq |t|\textrm{ e } 0 < i' \leq i \leq |s|$ então 
%   \begin{itemize}
%     \item $\fmiv{s}{t}{i'}{i}{j'}{j}=\maxnew{i_1,i_2}{i' \leq i_1 
%   \leq i_2+1 \leq i+1} {\aligndupoptscorest{s}{t}{i_1}{i_2}{j'}{j}+\romega}= $
% \begin{displaymath}
% =\max\left\{\fmiv{s}{t}{i'}{i-1}{j'}{j},\fmiva{s}{t}{i'}{i}{j'}{j}
% \right\}=\max\left\{\fmiv{s}{t}{i'+1}{i}{j'}{j},\fmivb{s}{t}{i'}{i}{j'}{j}\right\}\textrm{, } 
% \end{displaymath}
%    \item $\fmiva{s}{t}{i'}{i}{j'}{j}=\maxnew{i_1}{i' \leq i_1 \leq 
%   i+1} {\aligndupoptscorest{s}{t}{i_1}{i}{j'}{j}+\romega}=$
% \begin{displaymath}
% =\max\left\{\begin{array}{l}
% \fmiva{s}{t}{i'}{i-1}{j'}{j}+\vomega{s}{i}\\
% \fmiva{s}{t}{i'}{i-1}{j'}{j-1}+\domega{s}{t}{i}{j}\\
% \fmiva{s}{t}{i'}{i}{j'}{j-1}+\homega{t}{j}
% \end{array}\right\}\textrm{, }
% \end{displaymath}
%    \item $\fmivb{s}{t}{i'}{i}{j'}{j}=\maxnew{i_2}{i'-1 \leq i_2 
%   \leq i} {\aligndupoptscorest{s}{t}{i'}{i_2}{j'}{j}+\romega}=$
% \begin{displaymath}
% =\max\left\{\begin{array}{l}
% \fmivb{s}{t}{i'+1}{i}{j'}{j}+\vomega{s}{i'}\\
% \fmivb{s}{t}{i'+1}{i}{j'+1}{j}+\domega{s}{t}{i'}{j'}\\
% \fmivb{s}{t}{i'}{i}{j'+1}{j}+\homega{t}{j'}
% \end{array}\right\}\textrm{.}
% \end{displaymath}
% \end{itemize}
%   \item senão se $0<j' = j+1 \leq |t|+1 \textrm{ e } 0 < i' \leq i \leq |s|$ 
%   então
% \begin{itemize}
% \item $\fmiv{s}{t}{i'}{i}{j'}{j}= \max\left\{\begin{array}{l}
%   \fmiv{s}{t}{i'}{i-1}{j'}{j}\\
%   \fmiva{s}{t}{i'}{i-1}{j'}{j}+\vomega{s}{i}\\
% \end{array}\right\}\textrm{, } $
% \item $\fmiva{s}{t}{i'}{i}{j'}{j}= 
%   \max\left\{\begin{array}{l}\romega\\
% \fmiva{s}{t}{i'}{i-1}{j'}{j}+\vomega{s}{i}
% \end{array}\right\}\textrm{, } $
% \item $\fmivb{s}{t}{i'}{i}{j'}{j}= 
%   \max\left\{\begin{array}{l}\romega\\
% \fmivb{s}{t}{i'+1}{i}{j'}{j}+\vomega{s}{i'}
% \end{array}\right\}\textrm{, } $
% \end{itemize}
%   \item senão se $0<j' \leq j \leq |t| \textrm{ e } 0 < i' = i+1 \leq |s|+1$ 
%   então
% \begin{displaymath}\fmiv{s}{t}{i'}{i}{j'}{j}= \fmiva{s}{t}{i'}{i}{j'}{j}=\fmivb{s}{t}{i'}{i}{j'}{j}=\fmiv{s}{t}{i'}{i}{j'}{j-1}+\homega{t}{j}\textrm{, } \end{displaymath}
%   \item senão se $0<j' = j+1 \leq |t|+1 \textrm{ e } 0 < i' = i+1 \leq |s|+1$ 
%   então
% \begin{displaymath}\fmiv{s}{t}{i'}{i}{j'}{j}= \fmiva{s}{t}{i'}{i}{j'}{j}=\fmivb{s}{t}{i'}{i}{j'}{j}= \romega \textrm{, } \end{displaymath}
%   \item senão \begin{displaymath}\fmiv{s}{t}{i'}{i}{j'}{j}= 
%   \fmiva{s}{t}{i'}{i}{j'}{j}=
% \fmivb{s}{t}{i'}{i}{j'}{j}= -\infty\textrm{.} \end{displaymath}
% \end{itemize}
% 
% Neste modelo consideraremos que
% \begin{itemize}
%   \item se $0 <j' \leq j \leq |t|\textrm{ e } 0 \leq i \leq |s|$ então
% \begin{displaymath}\dupi{s}{t}{i}{j'}{j} = \max\left(\fmiv{s}{t}{1}{i}{j'}{j}\textrm{, }
% \fmiv{s}{t}{i+1}{|s|}{j'}{j}\textrm{, }\fmiv{t}{t}{1}{j'-1}{j'}{j}\textrm{, }\fmiv{t}{t}{j+1}{|t|}{j'}{j}
%   \right)\textrm{.}\end{displaymath}
%   \item senão
% \begin{displaymath}\dupi{s}{t}{i}{j'}{j} = -\infty \textrm{.}\end{displaymath}
% \end{itemize}
% 
% Temos que o máximo dos valores $\fmiv{t}{t}{1}{j'-1}{j'}{j}\textrm{ e 
% }\fmiv{t}{t}{j+1}{|t|}{j'}{j}$ é igual ao valor de $\fmii{t}{j'}{j}$ no modelo 3
% e portanto será obtido do mesmo modo que no modelo 3.
% 
% De forma análoga obtemos os valores de $\dupi{t}{s}{j}{i_1}{i}$.
% 
% Os valores de $\mt{i}{j}$ e $\ms{i}{j}$ são definidos como no modelo 1.
% 
% Deste modo construímos as matrizes com os valores de $\mt{i}{j}$
% e $\ms{i}{j}$ em tempo $O(n^3)$ e espaço $O(n^2)$.


\section{Duplicações em \emph{tandem}}
\label{sec:alignduptintro}

Há um tipo de ocorrência muito comum em \seqs\ \bioas\ que espera-se estar 
relacionado às \dups: a ocorrência de um mesmo trecho da \seq\ várias vezes um
ao lado do outro. Estes trechos são chamados de \reps\ em \emph{tandem}. Quando
a \rep\ de uma \oped\ de \dup\ é inserida imediatamente após (ou antes) da \seq\
original, produzimos uma \rep\ em \emph{tandem}. Nesta seção, vamos considerar
que as \opeds\ de \dup\ e excisão somente inserem e removem, respectivamente,
\reps\ em \emph{tandem}. Vamos considerar somente estes tipos de \opedspara
\dup\ ou excisão. 

O exemplo~\ref{ex:tandemrepeats} mostra uma \seq\ real onde aparecem repetições 
em \emph{tandem}. A \seq\ \emph{TGGCTG} aparece 11 vezes em seguida na \seq\ de 
DNA da \emph{Pseudomonas aeruginosa PA01} das posições 98902 a 99067.

\begin{exemplo}[Repetições em \emph{tandem}]
\label{ex:tandemrepeats}
\Seq\ da \emph{Pseudomonas aeruginosa PA01}  das posições 98902 a 99067:\\
\textbf{TGGCTG}TGGCTG\textbf{TGGCTG}TGGCTG\textbf{TGGCTG}TGGCTG\textbf{TGGCTG} 
\\TGGCTG\textbf{TGGCTG}TGGCTG\textbf{TGGCTG}\\
\end{exemplo}

Vamos considerar que a \seq\ da \rep\ é a \seq\ que está na posição posterior a 
da \seq\ original. Apesar da \rep\ poder ser colocada na posição anterior a da 
\seq\ original em uma \oped\ de \dup, o resultado é sempre o mesmo se 
colocarmos a \rep\ na posição posterior em uma \oped\ de \dup. Portanto, é 
indiferente a escolha por uma ou outra destas \opeds\ de \dup. Isto também é 
válido para a \oped\ de excisão.

Como já visto, $\aligndupsetgapdupsym=\aligndupsetgapdupsym_s \cup 
\aligndupsetgapdupsym_t$, onde $\aligndupsetgapdupsym_s=\{(s,x)\tq x \in 
[1,n]\}$ e $\aligndupsetgapdupsym_t=\{(t,y)\tq y \in [1,m]\}$.

A seguir vamos definir um alinhamento com \dups\ em \emph{tandem} de $s$ e $t$.
Esta definição é muito parecida com a definição de alinhamento com \dups\ de
$s$ e $t$, sendo que a única diferença é o espaço de busca da \seq\ base de um
\intrep, ou seja, são as possibilidades das \seqs\ $X$ ou $Y$ na
definição a seguir.

\begin{definicao}[Alinhamento com \dups\ em \emph{tandem} de $s$ e $t$] Um 
alinhamento com \dups\ em \emph{tandem} de $s$ e $t$ é uma matriz \aligndupsym\ 
de 3 linhas e $r$ colunas, tal que:
\begin{itemize}
  \item $r \geq \max(m,n)$ e $r \leq m+n$;
  \item para toda coluna $k$ de $\aligndupsym$ temos que:
  \begin{itemize}
      \item $\aligndupsym[0,k]\in [1,n] \cup \{\aligngapd\} \cup 
      \aligndupsetgapdupsym$,
      \item $\aligndupsym[1,k]\in [1,m] \cup \{\aligngapd\} \cup 
      \aligndupsetgapdupsym$,
      \item $\aligndupsym[2,k]\in 
      \{\aligndupdirectsym,\aligndupinicdupsym,\aligndupextdupsym\}$,
      \item se $\aligndupsym[0,k]=\aligndupsym[1,k]$ então $\aligndupsym[0,k] 
      \in [1,n]$,
      \item se $\aligndupsym[0,k]\in \aligndupsetgapdupsym$ então 
      $\aligndupsym[1,k] \notin \aligndupsetgapdupsym$,
      \item se $\aligndupsym[0,k] \in \aligndupsetgapdupsym$ ou 
      $\aligndupsym[1,k] \in \aligndupsetgapdupsym$ então $\aligndupsym[2,k] 
      \in \{\aligndupinicdupsym,\aligndupextdupsym\}$;
      \item se $\aligndupsym[0,k] \in [1,n]$ e $\aligndupsym[1,k] \in [1,m]$ 
      então $\aligndupsym[2,k] = \aligndupdirectsym$;
      \item se $\aligndupsym[2,k] = \aligndupextdupsym$ então 
      $\aligndupsym[2,k-1] \in \{\aligndupinicdupsym,\aligndupextdupsym\}$;
  \end{itemize} 
      \item $\excludefunc(\aligndupsym[0,0 \Rng r-1],\aligndupsetgapdupsym \cup 
      \{\aligngapd\} )=(1,2,\ldots,n)$;
      \item $\excludefunc(\aligndupsym[1,0 \Rng r-1],\aligndupsetgapdupsym \cup 
      \{\aligngapd\} )=(1,2,\ldots,m)$;
      \item Para todo \intrep\ $[k_1,k_2]$ em $\aligndupsym$ temos que:
  \begin{enumerate}
      \item se $\aligndupsym[0,k_1] \in [1,n] \cup \{\aligngapd\} $ e 
      $\aligndupsym[1,k_1] \in \aligndupsetgapdupsym \cup \{\aligngapd\}$ então 
      $\excludefunc(\aligndupsym[0,$ $k_1\Rng k_2], 
      \{\aligngapd\})=(i_1,i_1+1,\ldots,i_1+x_1)$, onde $1\leq i_1 \leq i_1+x_1 
      \leq n$, e $\excludefunc(\aligndupsym[1,k_1\Rng k_2], \{\aligngapd\})=X$, 
      onde $X$ é uma das seguintes \seqs:
      \begin{enumerate}
          \item $((s,i_2),(s,i_2+1),\ldots,(s,i_1-1))$, onde $1 \leq i_2 \leq 
          i_1$,\label{def:aligndupt:casossnormal}
          \item $((t,j),(t,j+1),\ldots,(t,j+x_2))$, onde $1 \leq j \leq j+x_2+1 
          \leq m+1$ e $\excludefunc(\aligndupsym[1,0\Rng 
          k_1-1],\aligndupsetgapdupsym \cup \{\aligngapd\} 
          )=(1,2,\ldots,j+x_2)$;\label{def:aligndupt:casost}
      \end{enumerate}
          \item se $\aligndupsym[1,k_1] \in [1,m] \cup \{\aligngapd\} $ e 
          $\aligndupsym[0,k_1] \in \aligndupsetgapdupsym \cup \{\aligngapd\} $ 
          então $\excludefunc(\aligndupsym[1,$ $k_1\Rng k_2], 
          \{\aligngapd\})=(j_1,j_1+1,\ldots,j_1+y_1)$, onde $1\leq j_1 \leq 
          j_1+y_1 \leq m$, e $\excludefunc(\aligndupsym[0,k_1\Rng k_2], 
          \{\aligngapd\})=Y$, onde $Y$ é uma das seguintes \seqs:
      \begin{enumerate}
          \item $((t,j_2),(t,j_2+1),\ldots,(t,j_1-1))$, onde $1 \leq j_2 \leq 
          j_1$,\label{def:aligndupt:casottnormal}
          \item $((s,i),(s,i+1),\ldots,(s,i+y_2))$, onde $1 \leq i \leq i+y_2+1 
          \leq n+1$ e $\excludefunc(\aligndupsym[0,0\Rng 
          k_1-1],\aligndupsetgapdupsym \cup \{\aligngapd\} 
          )=(1,2,\ldots,i+y_2)$.\label{def:aligndupt:casots}
      \end{enumerate}
  \end{enumerate}
\end{itemize}
\label{def:aligndupt}
\end{definicao}

Repare que um alinhamento com \dups\ em \emph{tandem} de $s$ e $t$ é sempre um 
alinhamento com \dups\ de $s$ e $t$, porém o inverso nem sempre é verdade. Ou
seja, o alinhamento com \dups\ em \emph{tandem} é um subcaso do alinhamento com
\dups.

O alinhamento \aligndupsym\ com \dups\ do Exemplo~\ref{ex:alignduptcasost}, que
é exatamente igual ao alinhamento com \dups\ do Exemplo~\ref{ex:aligndupcasost},
que também é um alinhamento com \dups\ em \emph{tandem}. O intervalo de \rep\ 
$[5,8]$ de \aligndupsym\ é um \intrep\ por excisão e está de acordo com o caso 
\ref{def:aligndupt:casost} de um \intrep\ na Definição~\ref{def:aligndupt}. A 
\seq\ $s[4 \Rng 6]$ é a \rep\ e $t[3 \Rng 5]$ é a \seq\ base do \intrep\ 
$[5,8]$ de \aligndupsym. Repare que $t[3 \Rng 5]$ está alinhado com um sufixo 
de $s[1 \Rng 3]$, ou seja, com um trecho de $s$ que está exatamente antes da 
\rep.

\begin{exemplo}[Alinhamento com \dups\ em \emph{tandem}]
\label{ex:alignduptcasost}
\[\aligndupsym=\left[\begin{array}{cccccccccc} 
\aligngapd&1&2&3&\aligngapd&4&5&6&\aligngapd&7\\
1&2&3&4&5&(t,3)&\aligngapd&(t,4)&(t,5)&6\\
+&+&+&+&+&\aligndupinicdupsym&\aligndupextdupsym&\aligndupextdupsym&\aligndupextdupsym&+ \end{array}\right]\]
\end{exemplo}

Vale a pena ressaltar que o grafo de \dups\ $G$ de um alinhamento com \dups\ em 
\emph{tandem} é acíclico, pois para toda aresta $(u,v)$ de $G$, o vértice $v$ 
correspondente a um símbolo que é alinhado numa coluna cujo índice é inferior à 
da coluna onde é alinhado o símbolo correspondente ao vértice $u$.

Utilizaremos neste capítulo, o mesmo sistema de pontuação definido na 
seção~\ref{sec:aligndupintro} e que já é utilizado no capítulo de alinhamento
com \dups. 

% 
% Utilizando o sistema de pontuação de \emph{gap} linear \alignscore\ tal que, 
% para qualquer coluna $k$ de um alinhamento $A$ temos que 
% $\alignscore(A[0,k],A[1,k])$ é igual a:
% \begin{itemize}
%   \item $\vomegad{s}{i}$ se $A[0,k]=s[i]$ e $A[1,k]=\aligngap$,
%   \item $\homegad{t}{j}$ se $A[0,k]=\aligngap$ e $A[1,k]=t[j]$,
%   \item $\domegad{s}{t}{i}{j}$ se $A[0,k]=s[i]$ e $A[1,k]=t[j]$,
% \end{itemize}
%   diremos que $\alignoptscore{s'}{t'}$ é a pontuação do alinhamento global 
%   ótimo sem \dups\ de $s' \times t'$.
%    
% Utilizaremos este sistema de pontuação para obter a pontuação de um alinhamento 
% ótimo entre a \seq\ base e a \rep\ de um \intrep\ num alinhamento com \dups\ em 
% \emph{tandem}.
% 
% 
Vamos redefinir as matrizes $\mttandem{i}{j}$ e $\mstandem{i}{j}$ de tal forma
que os alinhamentos com \dups\ estão restritos aos alinhamentos com \dups\ em
\emph{tandem}.

Definimos $\mttandem{i}{j}$ como a pontuação máxima de um alinhamento com 
\dups\ em \emph{tandem} \aligndupsym\ de $s[1 \Rng i] \times t[1 \Rng j]$ tal 
que, a última coluna de \aligndupsym\ pertence a um \intrep\ por \dup, $\forall 
i,j \tq 0\leq i\leq n$ e $1 \leq j\leq m$. De forma análoga, definimos 
$\mstandem{i}{j}$ como a pontuação máxima de um alinhamento com \dups\  em 
\emph{tandem} \aligndupsym\ de $s[1 \Rng i] \times t[1 \Rng j]$ tal que, a 
última coluna de \aligndupsym\ pertence a um \intrep\ por excisão, $\forall i,j 
\tq 1 \leq i\leq n$ e $0\leq j\leq m$.

Para obter os valores de $M[i,j]$, utilizaremos a mesma 
recorrência~\ref{eq:dupM} da página~\pageref{eq:dupM} já utilizada no 
algoritmo~\ref{alg:dup}.

Vamos dizer que \dupwt{t}{j'}{j}{s}{i} é o valor máximo para a soma das 
pontuações das colunas do \intrep\ por \dup\ $[k_1,k_2]$ de um alinhamento com 
\dups\ em \emph{tandem} \aligndupsym\ de $s$ e $t$ tal que, 
$\excludefunc(\aligndupsym[1,k_1\Rng k_2]$, $\{\aligngapd\})=(j',j'+1,\ldots,j)$ 
e $\excludefunc(\aligndupsym[0,1\Rng k_1-1], \aligndupsetgapdupsym \cup 
\{\aligngapd\} )=(1,2,\ldots,i)$. De modo similar, vamos dizer que, o valor de 
\dupwt{s}{i'}{i}{t}{j} é o valor máximo para a soma das pontuações das colunas 
do \intrep\ por excisão $[k_1,k_2]$ de um alinhamento com \dups\ em 
\emph{tandem} \aligndupsym\ de $s$ e $t$ tal que, 
$\excludefunc(\aligndupsym[0,k_1\Rng k_2], \{\aligngapd\})=(i',i'+1,\ldots,i)$ 
e $\excludefunc(\aligndupsym[1,1\Rng k_1-1], \aligndupsetgapdupsym \cup 
\{\aligngapd\} )=(1,2,\ldots,j)$.

Portanto, temos que $$\mttandem{i}{j}= \maxnew{j'}{1\leq j'\leq j 
}{M[i,j'-1]+\dupwt{t}{j'}{j}{s}{i}}$$

Analogamente, temos que $$\mstandem{i}{j}= \maxnew{i'}{1\leq i'\leq 
i}{M[i'-1,j]+\dupwt{s}{i'}{i}{t}{j}}$$

Seja $G=(V,E,\egweigsym)$ um \gredes\ de $s$ e $t$, onde \egweigsym\ é tal que:
\begin{itemize}
  \item $\egweigsym(\egeh{(i,j)})=\homega{t}{j}$,
  \item $\egweigsym(\eged{(i,j)})=\domega{s}{t}{i}{j}$,
  \item $\egweigsym(\egev{(i,j)})=\vomega{s}{i}$,
  \item $\egweigsym(\egex{(i',j')}{(i,j)})=\dupwt{s}{i'}{i}{t}{j}}$, se $i' \neq i$ e 
  $j' = j$,
  \item $\egweigsym(\egex{(i',j')}{(i,j)})=\dupwt{t}{j'}{j}{s}{i}}$, se $i' = i$ e $j' 
  \neq j$,
  \item $\egweigsym(\egex{(i',j')}{(i,j)})=-\infty$ se $i' \neq i$ e $j' \neq 
  j$.
\end{itemize}

Pode-se verificar que o peso de um caminho ótimo em $G$ é igual a pontuação de
um alinhamento ótimo com \dups\ de $s$ e $t$.

\section{Algoritmo para alinhamento de \dups\ em \emph{tandem}}
\label{sec:alignduptalg}

Seja $\setE{t}{j}$ o conjunto de todos os sufixos de $t[1\Rng j]$, assim como
$\setE{s}{i}$ é o conjunto de todos os sufixos de $s[1\Rng i]$, ou seja, se $i$
e $j$ são tais que $1 \leq j \leq m$ e $1 \leq i \leq n$ definimos
os conjuntos de fatores das \seqs\ $s$ e $t$, \setE{t}{j} e
\setE{s}{i} da seguinte forma:
\begin{enumerate}
  \item $\setE{t}{j} = \{t[j_1 \Rng j]\tq 1 \leq j_1 \leq j+1\}$ e
  \item $\setE{s}{i} = \{s[i_1 \Rng i]\tq 1 \leq i_1 \leq i+1\}$.
\end{enumerate}

Para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ definimos, para cada 
conjunto \setE{t}{j} e  \setE{s}{i}, a pontuação máxima do alinhamento ótimo 
sem \dups\ de $t[j' \Rng j]$ com um elemento do conjunto, da seguinte forma: 
\begin{align*}\bestScoreE{t}{j'}{j}&= \max(\alignoptscore{t[j'\Rng 
j]}{\seqbaseLetter}\tq \seqbaseLetter \in \setE{t}{j'-1})\\
&= \maxnew{j_1}{1 \leq j_1 \leq 
j'}{\alignoptscorest{t}{t}{j'}{j}{j_1}{j'-1}}\textrm{,}\end{align*}

\begin{align*}\bestScoreF{t}{j'}{j}{s}{i}&= \max(\alignoptscore{t[j'\Rng 
j]}{\seqbaseLetter}\tq \seqbaseLetter \in \setE{s}{i})\\
&= \maxnew{i_1}{1 \leq i_1 \leq 
i+1}{\alignoptscorest{t}{s}{j'}{j}{i_1}{i}}\textrm{,}\end{align*}

Analogamente, para o fator $s[i'\Rng i]$, definimos
\begin{align*}\bestScoreE{s}{i'}{i}&= \max(\alignoptscore{s[i'\Rng 
i]}{\seqbaseLetter}\tq \seqbaseLetter \in \setE{s}{i'-1})\\
&= \maxnew{i_1}{1 \leq i_1 \leq 
i'}{\alignoptscorest{s}{s}{i'}{i}{i_1}{i'-1}}\textrm{,}\end{align*}

\begin{align*}\bestScoreF{s}{i'}{i}{t}{j}&= \max(\alignoptscore{s[i'\Rng 
i]}{\seqbaseLetter}\tq \seqbaseLetter \in \setE{t}{j})\\
&= \maxnew{j_1}{1 \leq j_1 \leq 
j+1}{\alignoptscorest{s}{t}{i'}{i}{j_1}{j}}\textrm{,}\end{align*}

Portanto, para todos $i$, $j'$ e $j$ tais que $0 \leq i \leq n$ e $1 \leq
j' \leq j \leq m$, temos que

\begin{displaymath}
\dupwt{t}{j'}{j}{s}{i}=\max\left( \begin{array}{l}
\bestScoreE{t}{j'}{j}\\
\bestScoreF{t}{j'}{j}{s}{i}\\
\end{array}\right)+\uomega{t}{j'}{j} \textrm{.}
\end{displaymath} 

Analogamente, para todos $j$, $i'$ e $i$ tais que $0 \leq j \leq m$ e $1 \leq i' 
\leq i \leq n$, temos que

\begin{displaymath}
\dupwt{s}{i'}{i}{t}{j}=\max\left( \begin{array}{l}
\bestScoreE{s}{i'}{i}\\
\bestScoreF{s}{i'}{i}{t}{j}\\
\end{array}\right)+\xomega{s}{i'}{i} \textrm{.}
\end{displaymath} 

A seguir, vamos definir matrizes  que armazenam valores pré-computados de 
\bestScoreE{t}{j'}{j} e \bestScoreF{t}{j'}{j}{s}{i} e propor algoritmos para 
construir estas matrizes.

\subsection{Função \bestScoreE{t}{j'}{j}}

Vamos armazenar o valor de \bestScoreE{t}{j'}{j} em \wbestScoreE{t}{j'-1}{j}, 
ou seja, para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ temos que 
$\bestScoreE{t}{j'}{j} = \wbestScoreE{t}{j'-1}{j}$.

Assim, para todos $j'$ e $j$ tais que $1 \leq j' \leq j \leq m$ temos que, 
\wbestScoreE{t}{j'}{j} contém o valor máximo do alinhamento ótimo sem 
duplicações de $t[j'+1 \Rng j]\times \seqbaseLetter$, $\forall\ \seqbaseLetter 
\in \setE{t}{j'+1}$.

Para obter os valores de \wbestScoreEm{t}, utilizaremos a matriz 
\wbestScoreEjm{t} $(m+1) \times (m+1) \times (m+1)$ definida por \\
$$\wbestScoreEj{t}{j_2}{j'}{j}=\maxnew{j_1}{0 \leq j_1 \leq 
j_2}{\alignoptscore{t[j'+1\Rng j]}{t[j_1+1 \Rng j_2]}}$$, se $0 \leq j_2 
\leq j' \leq j \leq m$ e \\
$\wbestScoreEj{t}{j_2}{j'}{j}=-\infty$, caso contrário.

Portanto,  \wbestScoreEm{t} é a matriz $(m+1) \times (m+1)$ tal que
\begin{displaymath}
\wbestScoreE{t}{j'}{j} = \wbestScoreEj{t}{j'}{j'}{j}\textrm{.}
\end{displaymath}

Os valores dos elementos de \wbestScoreEjm{t} são obtidos da seguinte forma:
\begin{itemize}
  \item $\wbestScoreEj{t}{0}{j'}{j}=0$, se $0 \leq j'= j \leq m$,
  \item 
  $\wbestScoreEj{t}{0}{j'}{j}=\wbestScoreEj{t}{0}{j'}{j-1}+\vomegad{t}{j}$, se 
  $0 \leq j' < j \leq m$,
  \item $\wbestScoreEj{t}{j_2}{j'}{j}=\max\left(\begin{array}{l}0,\\
  \wbestScoreEj{t}{j_2-1}{j'}{j}+\homegad{t}{j_2}\end{array}\right)$, se $0 \leq 
  j' = j \leq m$ e $1 \leq j_2 \leq j'$,
  \item $\wbestScoreEj{t}{j_2}{j'}{j}=\max\left(\begin{array}{l} 
  \wbestScoreEj{t}{j_2-1}{j'}{j}+\homegad{t}{j_2},\\
  \wbestScoreEj{t}{j_2}{j'}{j-1}+\vomegad{t}{j},\\
  \wbestScoreEj{t}{j_2-1}{j'}{j-1}+\domegad{t}{t}{j_2}{j}\end{array}\right)$, se 
  $0 \leq j' < j \leq m$ e $1 \leq j_2 \leq j'$,
  \item $\wbestScoreEj{t}{j_2}{j'}{j}=-\infty$, se $0 \leq j < j' \leq m$ ou 
  $j' < j_2 \leq m$.
\end{itemize}

A Figura~\ref{fig:semigalignE} ilustra as 3 possibilidades de um caminho ótimo 
num \gred\ até $(j,j')$ a partir de qualquer vértice da linha $j'$. As linhas 
tracejadas indicam caminhos ótimos de qualquer vértice da linha $j'$ até 
$(j-1,j')$, $(j-1,j'-1)$ e $(j,j'-1)$, cujos pesos são, respectivamente, 
\wbestScoreEj{t}{j'}{j'}{j-1}, \wbestScoreEj{t}{j'-1}{j'}{j-1} e 
\wbestScoreEj{t}{j'-1}{j'}{j}.


\begin{figure}[htbp] \centering 
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{semigalignE}
% \end{center}
\caption[Caminhos para calcular \wbestScoreEj{t}{j'}{j'}{j}]{Ilustração das 3 possibilidades de um 
caminho ótimo num \gred\ até $(j,j')$ a partir de qualquer vértice da linha 
$j'$ para a obtenção de $\wbestScoreE{t}{j'}{j} = \wbestScoreEj{t}{j'}{j'}{j}$.}
 \label{fig:semigalignE}
\end{figure}


Repare que $\wbestScoreEj{t}{j_2}{j'}{j}=\wbestScoreAj{t}{j_2}{j'}{j}$. No 
entanto,  $\wbestScoreE{t}{j'}{j} \neq \wbestScoreA{t}{j'}{j}$, pois 
\wbestScoreE{t}{j'}{j} é o valor de \wbestScoreAj{t}{j_2}{j'}{j} quando 
$j_2=j'$, diferente de \wbestScoreA{t}{j'}{j} que é a pontuação máxima de
\wbestScoreAj{t}{j_2}{j'}{j} para $j'$ e $j$ fixos.

O Algoritmo~\ref{alg:buildwe} constrói a matriz \wbestScoreEm{t} utilizando as 
recorrências descritas acima. O algoritmo é muito parecido com o 
Algoritmo~\ref{alg:buildwa} que constrói a matriz \wbestScoreAm{t}. O algoritmo 
utiliza programação dinâmica e executa em tempo $O(n^3)$ e espaço $O(n^2)$.

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWE}{t}
  \COM {$\wEj{j_2}{j}=\wbestScoreEj{t}{j_2}{j'}{j}$}
  \DOFORI {j'} {0} {|t|}
    \SET{j}{j'}
    \SET{j_2}{0}
	\SET{\wEj{j_2}{j}}{0}
    \DOFORI {j_2} {1} {j'}
		\SET{\wEj{j_2}{j}}{\max(0,\wEj{j_2-1}{j}+\homegad{t}{j_2})}
	\OD		
	\SET{\wE{j'}{j}}{\wEj{j'}{j}}
	\DOFORI {j} {j'+1} {|t|}
	    \SET{j_2}{0}
		\SET{\wEj{j_2}{j}}{\wEj{j_2}{j-1}+\vomegad{t}{j}}
    	\DOFORI {j_2} {1} {j'}
    		\SET{h}{\wEj{j_2-1}{j}+\homegad{t}{j_2}}
    		\SET{v}{\wEj{j_2}{j-1}+\vomegad{t}{j}}
    		\SET{d}{\wEj{j_2-1}{j-1}+\domegad{t}{t}{j_2}{j}}
			\SET{\wEj{j_2}{j}}{\max(h, v, d)}
		\OD
		\SET{\wE{j'}{j}}{\wEj{j'}{j}}
  	\OD
  \OD 
\RETURN {\WE{t}} 
\caption[BUILDWE]{Algoritmo para a construção da matriz \wbestScoreEm{t}}
  \label{alg:buildwe}
  \end{algo}
\end{algorithm}


\subsection{Funções \bestScoreF{t}{j'}{j}{s}{i} e \bestScoreF{s}{i'}{i}{t}{j}}

Vamos armazenar o valor de \bestScoreF{t}{j'}{j}{s}{i} em 
\wbestScoreF{t}{j'-1}{j}{s}{i}, ou seja, para todos $i$, $j'$ e $j$ tais que $0 
\leq i \leq n$ e $1 \leq j' \leq j \leq m$, temos que 
$\bestScoreF{t}{j'}{j}{s}{i} = \wbestScoreF{t}{j'-1}{j}{s}{i}$.

Assim temos que, para todos $i$, $j'$ e $j$ tais que $0 \leq i \leq n$ e $1 
\leq j' \leq j \leq m$, \wbestScoreF{t}{j'}{j}{s}{i} contém o valor máximo do 
alinhamento ótimo sem duplicações de $t[j'+1 \Rng j]\times \seqbaseLetter$, 
$\forall\ \seqbaseLetter \in \setE{s}{i}$.

Os valores dos elementos da matriz \wbestScoreFm{t}{s} $(m+1) \times (m+1) 
\times (n+1)$ são obtidos da seguinte forma:
\begin{itemize}
  \item $\wbestScoreF{t}{j'}{j}{s}{0}=0$, se $0 \leq j'= j \leq m$,
  \item 
  $\wbestScoreF{t}{j'}{j}{s}{0}=\wbestScoreF{t}{j'}{j-1}{s}{0}+\vomegad{t}{j}$, 
  se $0 \leq j' < j \leq m$,
  \item $\wbestScoreF{t}{j'}{j}{s}{i}=\max\left(\begin{array}{l}0,\\
  \wbestScoreF{t}{j'}{j}{s}{i-1}+\homegad{s}{i}\end{array}\right)$, se $0 \leq 
  j' = j \leq m$ e $1 \leq i \leq n$,
  \item $\wbestScoreF{t}{j'}{j}{s}{i}=\max\left(\begin{array}{l} 
  \wbestScoreF{t}{j'}{j}{s}{i-1}+\homegad{s}{i},\\
  \wbestScoreF{t}{j'}{j-1}{s}{i}+\vomegad{t}{j},\\
  \wbestScoreF{t}{j'}{j-1}{s}{i-1}+\domegad{t}{s}{j}{i}\end{array}\right)$, 
  se $0 \leq j' < j \leq m$ e $1 \leq i \leq n$,
  \item $\wbestScoreF{t}{j'}{j}{s}{i}=-\infty$, se $j < j'$.
\end{itemize}

A Figura~\ref{fig:semigalignF} ilustra as 3 possibilidades de um caminho ótimo 
num \gred\ até $(j,i)$ a partir de qualquer vértice da linha $j'$. As linhas 
tracejadas indicam caminhos ótimos de qualquer vértice da linha $j'$ até 
$(j-1,i)$, $(j-1,i-1)$ e $(j,i-1)$, cujos pesos são, respectivamente, 
\wbestScoreF{t}{j'}{j-1}{s}{i}, \wbestScoreF{t}{j'}{j-1}{s}{i-1} e 
\wbestScoreF{t}{j'}{j}{s}{i-1}.


\begin{figure}[htbp] \centering 
\includegraphics[width=0.7\textwidth,height=0.5\textwidth]{semigalignF}
% \end{center}
\caption[Caminhos para calcular \wbestScoreF{t}{j'}{j}{s}{i}]{Ilustração das 3 possibilidades de um 
caminho ótimo num \gred\ até $(j,i)$ a partir de qualquer vértice da linha $j'$ 
para a obtenção de $\wbestScoreF{t}{j'}{j}{s}{i}$.}
 \label{fig:semigalignF}
\end{figure}

Similarmente como feito para a matriz \wbestScoreFm{t}{s}, definimos a matriz
\wbestScoreFm{s}{t} $(n+1) \times (n+1) \times (m+1)$  da seguinte forma:
\begin{itemize}
  \item $\wbestScoreF{s}{i'}{i}{t}{0}=0$, se $0 \leq i'= i \leq n$,
  \item 
  $\wbestScoreF{s}{i'}{i}{t}{0}=\wbestScoreF{s}{i'}{i-1}{t}{0}+\vomegad{s}{i}$, 
  se $0 \leq i' < i \leq n$,
  \item $\wbestScoreF{s}{i'}{i}{t}{j}=\max\left(\begin{array}{l}0,\\
  \wbestScoreF{s}{i'}{i}{t}{j-1}+\homegad{t}{j}\end{array}\right)$, se $0 \leq 
  i' = i \leq n$ e $1 \leq j \leq m$,
  \item $\wbestScoreF{s}{i'}{i}{t}{j}=\max\left(\begin{array}{l} 
  \wbestScoreF{s}{i'}{i}{t}{j-1}+\homegad{t}{j},\\
  \wbestScoreF{s}{i'}{i-1}{t}{j}+\vomegad{s}{i},\\
  \wbestScoreF{s}{i'}{i-1}{t}{j-1}+\domegad{s}{t}{i}{j}\end{array}\right)$, 
  se $0 \leq i' < i \leq n$ e $1 \leq j \leq m$,
  \item $\wbestScoreF{s}{i'}{i}{t}{j}=-\infty$, se $i < i'$.
\end{itemize}

Sejam as matrizes $\WFi{t}{s}{i}$ $(|t|+1) \times (|t|+1)$ e $\WFi{s}{t}{i}$ 
$(|s|+1) \times (|t|+1)$ tais que, 
$\wFi{t}{s}{i}{j'}{j}=\wbestScoreF{t}{j'}{j}{s}{i}$ e 
$\wFi{s}{t}{i}{i'}{j}=\wbestScoreF{s}{i'}{i}{t}{j}$.

Os Algoritmos~\ref{alg:buildwft}~e~\ref{alg:buildwfs} constroem as matrizes
$\WFi{t}{s}{i}$ e $\WFi{s}{t}{i}$, respectivamente, utilizando as recorrências 
descritas acima. Os algoritmos utilizam programação dinâmica e executam em tempo 
$O(n^2)$ e espaço $O(n^2)$.

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWFt}{t,s,i,\WFi{t}{s}{i-1}}
  \COM {$\wFi{t}{s}{i}{j'}{j}=\wbestScoreF{t}{j'}{j}{s}{i}$}
  \IF{i=0}
  	\DOFORI {j'} {0} {|t|}
    	\SET{j}{j'}
		\SET{\wFi{t}{s}{i}{j'}{j}}{0}
    	\DOFORI {j} {j'+1} {|t|}
			\SET{\wFi{t}{s}{i}{j'}{j}}{\wFi{t}{s}{i}{j'}{j-1}+\vomegad{t}{j}}
		\OD
	\OD		
  \ELSE
  	\DOFORI {j'} {0} {|t|}
    	\SET{j}{j'}
		\SET{\wFi{t}{s}{i}{j'}{j}}{\max(0,\wFi{t}{s}{i-1}{j'}{j}+\homegad{s}{i})}
		\DOFORI {j} {j'+1} {|t|}
    		\SET{h}{\wFi{t}{s}{i-1}{j'}{j}+\homegad{s}{i}}
    		\SET{v}{\wFi{t}{s}{i}{j'}{j-1}+\vomegad{t}{j}}
    		\SET{d}{\wFi{t}{s}{i-1}{j'}{j-1}+\domegad{t}{s}{j}{i}}
			\SET{\wFi{t}{s}{i}{j'}{j}}{\max(h, v, d)}
  		\OD
  	\OD 
  \FI
  \RETURN{\WFi{t}{s}{i}}
\caption[BUILDWFt]{Algoritmo para a construção da matriz $\WFi{t}{s}{i}$}
  \label{alg:buildwft}
  \end{algo}
\end{algorithm}

\begin{algorithm}[htbp]
  \begin{algo}{BUILDWFs}{s,t,i,\WFi{s}{t}{i-1}}
  \COM {$\wFi{s}{t}{i}{i'}{j}=\wbestScoreF{s}{i'}{i}{t}{j}$}
  \DOFORI {i'} {0} {i}
    \SET{j}{0}
   	\IF{i'=i}
   		\SET{\wFi{s}{t}{i}{i'}{j}}{0}
    \ELSE
   		\SET{\wFi{s}{t}{i}{i'}{j}}{\wFi{s}{t}{i-1}{i'}{j}+\vomegad{s}{i}}    	
    \FI
  	\DOFORI {j} {1} {|t|}
   		\IF{i'=i}
   			\SET{\wFi{s}{t}{i}{i'}{j}}{\max(0,\wFi{s}{t}{i}{i'}{j-1}+\homegad{t}{j})}
    	\ELSE
    		\SET{h}{\wFi{s}{t}{i}{i'}{j-1}+\homegad{t}{j}}
    		\SET{v}{\wFi{s}{t}{i-1}{i'}{j}+\vomegad{s}{i}}
    		\SET{d}{\wFi{s}{t}{i-1}{i'}{j-1}+\domegad{s}{t}{i}{j}}
			\SET{\wFi{s}{t}{i}{i'}{j}}{\max(h, v, d)}
    	\FI
  	\OD 
  \OD
  \RETURN{\WFi{s}{t}{i}}
\caption[BUILDWFs]{Algoritmo para a construção da matriz $\WFi{s}{t}{i}$}
  \label{alg:buildwfs}
  \end{algo}
\end{algorithm}

\subsection{Função \dupwt{t}{j'}{j}{s}{i} e \mt{i}{j}}
\label{sec:duptmt}

Para todos $i$, $j'$ e $j$ tais que $0 \leq i \leq n$ e $1 \leq
j' \leq j \leq m$, temos que

\begin{displaymath}
\dupwt{t}{j'}{j}{s}{i}=\max\left( \begin{array}{l}
\wbestScoreE{t}{j'-1}{j}\\
\wFi{t}{s}{i}{j'-1}{j}\\
\end{array}\right)+\uomega{t}{j'}{j} \textrm{.}
\end{displaymath} 

Analogamente, para todos $j$, $i'$ e $i$ tais que $0 \leq j \leq m$ e $1 \leq i' 
\leq i \leq n$, temos que

\begin{displaymath}
\dupwt{s}{i'}{i}{t}{j}=\max\left( \begin{array}{l}
\wbestScoreE{s}{i'-1}{i}\\
\wFi{s}{t}{i}{i'-1}{j}\\
\end{array}\right)+\xomega{s}{i'}{i} \textrm{.}
\end{displaymath} 


Temos que   \begin{displaymath} \mt{i}{j}= \maxnew{j'}{1\leq j'\leq j 
}{M[i,j'-1]+\max\left( \begin{array}{l}
\wbestScoreE{t}{j'-1}{j}\\
\wFi{t}{s}{i}{j'-1}{j}\\
\end{array}\right)+\uomega{t}{j'}{j}}.
  \end{displaymath}

Do mesmo modo temos que \begin{displaymath} \ms{i}{j}= \maxnew{i'}{1\leq i'\leq 
i}{M[i'-1,j]+\max\left( \begin{array}{l}
\wbestScoreE{s}{i'-1}{i}\\
\wFi{s}{t}{i}{i'-1}{j}\\
\end{array}\right)+\xomega{s}{i'}{i}}.
  \end{displaymath}

\subsection{Algoritmo DUPTandem}

O Algoritmo~\ref{alg:dupt} constrói a matriz $M$ de acordo com a 
recorrência~\ref{eq:dupM} na página~\pageref{eq:dupM} e executa em tempo 
$O(n^3)$ e espaço $O(n^2)$. Os valores de \mt{i}{j} e \ms{i}{j} são obtidos de 
acordo com as equações descritas na seção~\ref{sec:duptmt}.

Fazendo algumas alterações no algoritmo, podemos obter também, além da 
pontuação do alinhamento com \dups\ de $s$ e $t$, o alinhamento propriamente 
dito sem alterar as complexidades de tempo e espaço de execução.

O espaço de busca das \seqs\ base de um \intrep\ utilizado neste modelo, é maior 
que o espaço de busca utilizado no modelo proposto por Benson~\cite{267526}. 
Contudo a complexidade do tempo de execução $O(n^3)$ do algoritmo~\ref{alg:dupt}
que propomos  é muito menor do que as complexidades de tempo dos 
algoritmos exatos propostos por Benson, que são $O(n^5)$ e $O(n^4)$, sendo que o
 $O(n^4)$ utiliza $O(n^3)$ de memória e o $O(n^5)$ utiliza $O(n^2)$ de memória.

Acreditamos que como verificamos mais opções de \dups, o algoritmo que propomos 
deve obter alinhamentos, em geral, mais realistas que os alinhamentos propostos 
por Benson.


\begin{algorithm}[htbp]
  \begin{algo}{DUPTandem}{s,t}
    \SET {\WE{t}}{BUILDWE(t)}
    \SET {\WE{s}}{BUILDWE(s)}
    \SET {\WFi{t}{s}{i}}{BUILDWFt(t,s,0,\emptyset)}
    \SET {M[0,0]}{0}
%     \SET {\wj{0}{0}}{0}
    \DOFORI {j} {1} {|t|}
    	\SET {M[0,j]}{M[0,j-1]+\homega{t}{j}}
    	\COM{Obtém \mt{0}{j}}
	    \DOFORI {j'} {0} {j-1}
	    	\SET{dup_t}{\max(\WE{t}[j',j],\wFi{t}{s}{i}{j'}{j})+\uomega{t}{j'+1}{j}}
	    	\SET {M[0,j]}{\max(M[0,j],M[0,j']+dup_t)}
		\OD
	\OD
    
    \DOFORI {i} {1} {|s|} \label{dup4:loop1}
    	\SET {M[i,0]}{M[i-1,0]+\vomega{s}{i})}
     	\SET {\WFi{t}{s}{i}}{BUILDWFt(t,s,i,\WFi{t}{s}{i-1})}
    	\SET {\WFi{s}{t}{i}}{BUILDWFs(s,t,i,\WFi{s}{t}{i-1})}
    	\COM{Obtém \ms{i}{0}}
	    \DOFORI {i'} {0} {i-1}
	    	\SET{dup_s}{\max(\WE{s}[i',i],\wFi{s}{t}{i}{i'}{0})+\xomega{s}{i'+1}{i}}
	    	\SET {M[i,0]}{\max(M[i,0],M[i',0]+dup_s)}
		\OD
      	\DOFORI {j} {1} {|t|}
      		\SET{h}{M[i,j-1]+\homega{t}{j}}
      		\SET{v}{M[i-1,j]+\vomega{s}{i}}
      		\SET{d}{M[i-1,j-1]+\domega{s}{t}{i}{j}}
    		\SET {M[i,j]}{\max(h,v,d)}
    		\COM{Obtém \mt{i}{j}}
	    	\DOFORI {j'} {0} {j-1}
	    		\SET{dup_t}{\max(\WE{t}[j',j],\wFi{t}{s}{i}{j'}{j})+\uomega{t}{j'+1}{j}}
	    		\SET {M[i,j]}{\max(M[i,j],M[i,j']+dup_t)}
			\OD
    		\COM{Obtém \ms{i}{j}}
			\DOFORI {i'} {0} {i-1}
	    		\SET{dup_s}{\max(\WE{s}[i',i],\wFi{s}{t}{i}{i'}{j})+\xomega{s}{i'+1}{i}}
	    		\SET {M[i,j]}{\max(M[i,j],M[i',j]+dup_s)}
			\OD
		\OD \label{dup4:dirfim} 
	\OD 
\RETURN {M}

\caption[DUPTandem]{Algoritmo $O(n^3)$ 
para obter a pontuação de um alinhamento com \dups\ em \emph{tandem}}
  \label{alg:dupt}
  \end{algo}
\end{algorithm}



% \subsubsection{Variante A}
% 
% Nesta variante iremos considerar que as duplicações têm o mesmo comprimento.
% 
% \subsection{Modelo 2}
% 
% Neste modelo consideraremos que a duplicação de qualquer fator $t[j_3 \Rng j_4]$ 
% foi obtida de um fator anterior $t[j_1 \Rng j_2]$, $0 < j_1 \leq j_2 < j_3 \leq j_4 
% \leq m$, e a pontuação da operação de duplicação dependerá da comparação de 
% $t[j_3 \Rng j_4]$ com $t[j_1 \Rng j_2]$. As mesmas considerações são feitas para as
% duplicações em $s$.
% 
% Definimos assim $\fmii{t}{j_1}{j}$, $1<j_1\leq j \leq m$, como a pontuação da 
% operação que considera que o trecho $t[j_1 \Rng j]$ é uma duplicação. De forma 
% análoga, definimos $\fmii{s}{i_1}{i}$, $1<i_1\leq i \leq n$, como a pontuação 
% da operação que considera que o trecho $s[i_1 \Rng i]$ é uma duplicação.
% 
% Neste modelo iremos considerar que 
% \begin{displaymath}\fmii{t}{j_1}{j} = \maxnew{j_2,j_3}{0 < j_2 \leq j_3 < j_1} 
% {\aligndupoptscorest{t}{t}{j_2}{j_3}{j_1}{j}+\romega}\textrm{ e}\end{displaymath} 
%  \begin{displaymath}\fmii{s}{i_1}{i} = \maxnew{i_2,i_3}{0 < i_2 \leq i_3 < i_1} 
% {\aligndupoptscorest{s}{s}{i_2}{i_3}{i_1}{i}+\romega}\textrm{.}\end{displaymath}
% 
% Para este modelo, os valores de $\mt{i}{j}$ e $\ms{i}{j}$ são obtidos da
% seguinte forma:
% \begin{itemize}
%   \item $\forall i \tq 0 \leq i \leq n$, $\mt{i}{1}= -\infty$,
%   \item $\forall j \tq 0 \leq j \leq m$, $\ms{1}{j}= -\infty$,
%   \item $\forall i,j \tq 2 \leq j \leq m$ e $0 \leq i \leq n$,
%   \begin{displaymath} \mt{i}{j}= \maxnew{j_1}{1<j_1\leq j \leq m}{M[i,j_1-1]+\fmii{t}{j_1}{j}}
%   \end{displaymath}
%   \item $\forall i,j \tq 2 \leq i \leq n$ e $0 \leq j \leq m$,
%   \begin{displaymath} \ms{i}{j}= \maxnew{i_1}{1<i_1\leq i \leq n}{M[i_1-1,j]+\fmii{s}{i_1}{i}}
%   \end{displaymath}
% \end{itemize}
%  
% Seja $\fmiia{t}{j_1}{j}{j_3}=\maxnew{j_2}{0<j_2\leq
% j_3}{\aligndupoptscorest{t}{t}{j_1}{j}{j_2}{j_3}}$, $0<j_3<j_1\leq j \leq m$.
% 
% Logo, podemos dizer que
% \begin{displaymath}
% \fmii{t}{j_1}{j}=\maxnew{j_3}{0 < j_3 < j_1} {\fmiia{t}{j_1}{j}{j_3}+\romega}=
% \end{displaymath}
%   \begin{displaymath}
% =\maxnew{j_3}{0 < j_3 < j_1} {\max\left\{\begin{array}{l}
%           \fmiia{t}{j_1}{j}{j_3-1}+\homega{t}{j_3}\textrm{,}\\
%           \fmiia{t}{j_1}{j-1}{j_3-1}+\domega{t}{t}{j}{j_3}\textrm{,}\\
%           \fmiia{t}{j_1}{j-1}{j_3}+\vomega{t}{j}
%                                                 \end{array}\right\}}+\romega
% \end{displaymath}
% 
% Logo, podemos construir uma matriz com os valores de $\fmii{t}{j_1}{j}$ em
% tempo $O(n^3)$ e espaço $O(n^2)$.
% De modo análogo construímos a matriz com os valores de $\fmii{s}{i_1}{i}$ em
% tempo $O(n^3)$ e espaço $O(n^2)$.
% 
% Portanto construímos as matrizes com os valores de $\mt{i}{j}$ e $\ms{i}{j}$ em
% tempo $O(n^3)$ e espaço $O(n^2)$.
% 
% \subsection{Modelo 3}
% 
% Neste modelo consideraremos que a duplicação de qualquer fator $t[j_3 \Rng j_4]$ 
% foi obtida de um fator $t[j_1 \Rng j_2]$, $0 < j_1 \leq j_2 < j_3 \leq j_4 \leq m$ 
% ou $0 < j_3 \leq j_4 < j_1 \leq j_2 \leq m$, e a pontuação da operação de 
% duplicação dependerá da comparação de $t[j_3 \Rng j_4]$ com $t[j_1 \Rng j_2]$. As 
% mesmas considerações são feitas para as duplicações em $s$.
% 
% Neste modelo iremos considerar que 
% \begin{displaymath}\fmii{t}{j_1}{j} = 
% \maxnew{j_2,j_3}{0 < j_2 \leq j_3 < j_1\textrm{ ou } j < j_2 \leq j_3 \leq m} 
% {\aligndupoptscorest{t}{t}{j_2}{j_3}{j_1}{j}+\romega}
% \textrm{ e}\end{displaymath} 
%  \begin{displaymath}\fmii{s}{i_1}{i} = 
%  \maxnew{i_2,i_3}{0 < i_2 \leq i_3 < i_1 \textrm{ ou } i < i_2 \leq i_3 \leq n} 
% {\aligndupoptscorest{s}{s}{i_2}{i_3}{i_1}{i}+\romega}
% \textrm{.}\end{displaymath} 
% 
% % Para este modelo diremos que:
% % \begin{itemize}
% %   \item $\forall i \tq 0 \leq i \leq n$, $\mt{i}{1}= -\infty$,
% %   \item $\forall j \tq 0 \leq j \leq m$, $\ms{1}{j}= -\infty$,
% %   \item $\forall i,j \tq 2 \leq j \leq m$ e $0 \leq i \leq n$,
% %   \begin{displaymath} \mt{i}{j}= \maxnew{j_1}{1<j_1\leq j \leq m}{M[i,j_1-1]+\fmii{t}{j_1}{j}}
% %   \end{displaymath}
% %   \item $\forall i,j \tq 2 \leq i \leq n$ e $0 \leq j \leq m$,
% %   \begin{displaymath} \ms{i}{j}= \maxnew{i_1}{1<i_1\leq i \leq n}{M[i_1-1,j]+\fmii{s}{i_1}{i}}
% %   \end{displaymath}
% % \end{itemize}
% %  
% 
% Os valores de $\mt{i}{j}$ e $\ms{i}{j}$ são obtidos do mesmo modo que no
% modelo 2.
% 
% Consideraremos neste modelo que 
% \begin{displaymath}\fmiia{t}{j_1}{j}{j_3}=\left\{\begin{array}{ll}0 &\textrm{
% se } 0=j_3 <j_1 = j \leq m \textrm{, }\\ \maxnew{j_2}{0<j_2\leq
% j_3}{\aligndupoptscorest{t}{t}{j_1}{j}{j_2}{j_3}} &\textrm{ se } 0<j_3<j_1\leq j \leq
% m\textrm{, }\\ 
% \maxnew{j_2}{j<j_2\leq j_3}{\aligndupoptscorest{t}{t}{j_1}{j}{j_2}{j_3}} &\textrm{ se }
% 0<j_1\leq j<j_3 \leq m\textrm{, }\\
% -\infty &\textrm{ se caso contrário }
% \end{array}\right\}\textrm{.}\end{displaymath}
% 
% Logo 
% \begin{displaymath}
% \fmii{t}{j_1}{j}=
% \maxnew{j_3}{0 < j_3 < j_1 \textrm{ ou }j < j_3 \leq m} {\fmiia{t}{j_1}{j}{j_3}+\romega}=
% \end{displaymath}
%   \begin{displaymath}=
% \maxnew{j_3}{0 < j_3 < j_1 \textrm{ ou }j < j_3 \leq m} {\max\left\{\begin{array}{l}
%           \fmiia{t}{j_1}{j}{j_3-1}+\homega{t}{j_3}\textrm{,}\\
%           \fmiia{t}{j_1}{j-1}{j_3-1}+\domega{t}{t}{j}{j_3}\textrm{,}\\
%           \fmiia{t}{j_1}{j-1}{j_3}+\vomega{t}{j}
%                                          \end{array}\right\}}
% +\romega\end{displaymath}
% 
% Portanto, como no modelo 2, construímos as matrizes com os valores de $\mt{i}{j}$
% e $\ms{i}{j}$ em tempo $O(n^3)$ e espaço $O(n^2)$.
% 

\chapter{Conclusão}
\label{cap:conclusao}

Para a comparação de duas \seqs, desenvolvemos e apresentamos algoritmos exatos
que acreditamos serem inéditos e que obtêm alinhamentos que consideram a 
possibilidade da ocorrência de outros eventos biológicos além dos eventos de 
inserção, remoção e substituição de um símbolo da \seq, comumente utilizados em 
outros algoritmos usuais para obtenção de alinhamentos ótimos.

Consideramos, além dos eventos usuais que agem sobre um único símbolo da \seq, 
alguns rearranjos comumente observados no processo evolutivo, tais como \inv,
\dup\ por transposição e \dup\ em \emph{tandem},  que agem sobre segmentos de 
vários símbolos. Esperamos com isto, que o alinhamento obtido esteja mais 
próximo de mostrar o que realmente ocorreu na evolução.

Apesar do problema da obtenção de um alinhamento ótimo com \invnsobs\ ser um 
problema já bem estudado e com alguns algoritmos já publicados, conseguimos 
desenvolver algoritmos com complexidade de tempo significativamente melhor  
que os já existentes.

Apesar das complexidades de tempo dos algoritmos que propomos serem melhores 
que as complexidades de tempo dos algoritmos até então conhecidos, ainda assim 
os tempos ($O(n^3)$) são elevados para \seqs\ de grande comprimento. Por 
exemplo, um teste realizado com duas \seqs\ de DNA com 700 bases levou 872 
segundos (14,53 minutos) para executar o algoritmo $O(n^3)$ que obtém o 
alinhamento ótimo com \invnsobs\footnote{A execução deste mesmo teste no 
algoritmo $O(n^3 \log n)$ que obtém o alinhamento ótimo com \invnsobs, levou 
42,27 minutos.}. A solução que adotamos para obter alinhamentos ótimos com 
\invnsobs\ de \seqs\ muito longas, foi fragmentar as \seqs\ (por exemplo em 
fragmentos de comprimento 100), estabelecer quais os fragmentos que se 
emparelham\footnote{Isto foi feito, nos testes que realizamos, com o programa 
BLAST e com um limite mínimo para considerar que dois fragmentos se 
emparelham.} e considerar as \seqs\ dos fragmentos como as \seqs\ para o 
alinhamento com \invnsobs.

No caso do alinhamento com \dups, não conhecemos nenhum outro trabalho que 
utilize os modelos de \dups\ que apresentamos. O modelo mais próximo ao modelo 
que propomos para alinhamentos com \dups\ em \emph{tandem}, que conhecemos, é o 
modelo proposto por Benson~\cite{267526}, que propôs dois algoritmos exatos 
para a obtenção de um alinhamento ótimo com \dups\ em \emph{tandem}: um que 
executa com tempo $O(n^5)$ e espaço $O(n^2)$ e outro que executa em tempo 
$O(n^4)$ e espaço $O(n^3)$. Portanto, estes algoritmos têm complexidades de 
tempo e memória muito piores que as do algoritmo que propomos. O modelo 
proposto por Benson para considerar \dups\ em \emph{tandem}, além da restrição 
de só considerar \reps\ em \emph{tandem}, tem mais duas restrições, que são as 
seguintes.
\begin{enumerate}
  \item Sejam $s$ e $t$ as \seqs\ a serem alinhadas. Se um trecho de $s$ é uma 
  \rep\ então a \seq\ base a ser comparada (ou alinhada) com esta \rep\ em $s$ 
  deve ser um trecho de $t$. Portanto este modelo do Benson não considera que a 
  \seq\ original da \rep\ pode estar na própria \seq\ onde está a \rep.
  
  \item A \seq\ base deve ser a mesma para \intreps\ consecutivos, ou seja, 
  como as \reps\ consideradas são em \emph{tandem} e a \seq\ original 
  considerada está sempre na outra \seq, as \seqs\ base dos \intreps\ 
  consecutivos devem ter o mesmo tamanho.
\end{enumerate}

Nos modelos que propomos para o alinhamento com \dups\ em \emph{tandem}, não 
impomos estas restrições e portanto nosso espaço de busca é maior que o do 
Benson. No entanto, é possível obter um alinhamento ótimo com estas mesmas 
restrições propostas por Benson, com um algoritmo com tempo de execução 
$O(n^3)$ e espaço $O(n^2)$ utilizando as técnicas utilizados no algoritmo 
$O(n^3)$ para alinhamentos ótimos com \invnsobs, e portanto, mesmo considerando 
o mesmo modelo mais restritivo proposto por Benson, ainda assim conseguimos um 
algoritmo com complexidade de tempo $O(n^3)$, melhor que os algoritmos exatos
propostos por Benson.

Infelizmente os algoritmos de alinhamento com \dups\ e com \dups\ em 
\emph{tandem}, não puderam ser implementados, de forma que faltam testes 
experimentais.

Acreditamos que com um sistema de pontuação bem elaborado, os algoritmos para 
obter um alinhamento ótimo com \dups\ (e com \dups\ em \emph{tandem}) conseguem 
obter alinhamentos que estão mais próximos à realidade na comparação de \seqs\ 
de espécies próximas.




\chapter{Trabalhos futuros}
\label{cap:todo}

\section[Alinhamento com \invnsobs\ e \dups]{Alinhamento ótimo com \invnsobs\ e \dups}

Neste texto, desenvolvemos algoritmos para a obtenção da pontuação de 
alinhamentos ótimos com \invnsobs, e algoritmos para a obtenção da pontuação de 
alinhamentos ótimos com \dups, mas não desenvolvemos um algoritmo para a 
obtenção da pontuação de um alinhamento ótimo com \invnsobs\ \textbf{e} \dups, 
ou seja, não consideramos a possibilidade da ocorrência dos eventos de 
\invnsobs\ e de \dups\ no mesmo alinhamento.

Pretendemos, num trabalho futuro, desenvolver um algoritmo para a obtenção da 
pontuação de alinhamentos ótimos que consideram a possibilidade da ocorrência 
dos eventos de \invnsobs\ e de \dups\ no mesmo alinhamento.

Como temos um algoritmo para obter a pontuação de um alinhamento ótimo com 
\invnsobs\ em tempo $O(n^3)$ e espaço  $O(n^2)$, e temos dois algoritmos para 
obter a pontuação de um alinhamento ótimo com \dups\ (alinhamento com \dups\ e 
alinhamento com \dups\ em \emph{tandem}) também em tempo $O(n^3)$ e espaço $O(n^2)$, 
pretendemos desenvolver um algoritmo que obtenha a pontuação de um alinhamento 
ótimo com \invnsobs\ e \dups\ também em tempo $O(n^3)$ e espaço $O(n^2)$.

Talvez algumas hipóteses simplificadoras podem ser adotadas, como a não
sobreposição de \invs\ e \dups.

\section[Implementação e testes para \dups]{Implementação e testes para os 
algoritmos de alinhamento com \dups}

Um trabalho a ser feito é a implementação dos algoritmos apresentados para a 
obtenção da pontuação de alinhamentos ótimos com \dups\ e com \dups\ em
\emph{tandem}, assim como testes em dados reais e comparações com outras
ferramentas de alinhamento, a fim de saber a relevância da consideração das
\dups\ em um alinhamento.

Acreditamos que estes testes sejam necessários para estabelecermos 
cri\-té\-rios para os pesos das \opeds\ pontuais (inserção, remoção e 
substituição) nos \intreps, assim como para a \oped\ de \dup\ (e excisão). 
Esperamos que com um sistema de pontuação com pesos bem ajustados, o problema 
da ocorrência dos ciclos num grafo de \dup\ pode ser minimizado em dados reais.

\section{Pesos para abertura de \emph{gaps}}
Uma das características que não são contempladas no processo de obtenção do peso
do alinhamento com \invnsobs\ de duas seqüências utilizando a estrutura de
grafos de
edição, e que são muito utilizadas nos sistemas de pontuação para alinhamento de
seqüências biológicas, é a pontuação fixa para a abertura de \emph{gaps}. 

Um \emph{gap} corresponde a uma operação de inserção ou remoção. O peso para a 
abertura de \emph{gaps} corresponde a um peso fixo $\phi_{gapOpen}$, para cada seqüência consecutiva de 
remoções e de inserções, que é 
adicionado ao peso do alinhamento, ou seja, dado um caminho $P$ num grafo de edição $G$, 
o peso $w_p$ de $P$ é dado pela soma dos pesos das arestas que formam $P$ mais 
$(k_r+k_i)\phi_{gapOpen}$, onde $k_r$ é a quantidade de seqüências de arestas 
consecutivas de remoção e $k_i$ é a quantidade de seqüências de arestas 
consecutivas de inserção no caminho $P$.

Um trabalho a ser feito é tentar adaptar os algoritmos para obtenção da 
pontuação de um alinhamento ótimo (ou criar novos algoritmos) que considerem a 
possibilidade de pesos na abertura de \emph{gaps}.

Para os algoritmo que obtêm a pontuação do alinhamento ótimo de um alinhamento 
com \dups\ (ou \dups em \emph{tandem}), apesar de não considerarmos pesos para 
a abertura de \emph{gaps}, temos idéia de como, com pequenas modificações nos 
algoritmos, introduzir esta nova característica. Um trabalho a ser feito é 
formalizar estas idéias e comprovar a sua corretude.

\section{Função $\opedweiginv$ dependente do comprimento da inversão}

Em 2002 Pinter e Skiena \cite{Pinter_et_al_2002} desenvolveram um trabalho onde 
o peso de uma reversão é dependente do comprimento das seqüências revertidas. 
As seqüências consideradas neste trabalho são seqüências de genes. A motivação 
para isto vem da biologia, onde muitas vezes se verifica que pequenos 
rearranjos são mais comuns, ou seja, é muito mais comum pequenas regiões 
sofrerem rearranjos do que grandes regiões.

Em 2004 Benderet al.\ \cite{982930} consideraram o caso onde o peso da reversão 
é generalizado pela função $f(l)=l^\alpha$, onde $l$ é o comprimento da 
reversão e $\alpha$ é uma constante.

Para o problema de alinhamento de duas seqüências com inversões não 
sobrepostas, podemos querer considerar que a penalidade $\opedweiginv$ de uma 
operação de inversão tenha alguma relação com o comprimento da inversão, ou das 
seqüências invertidas.

Pode ser interessante estudar a viabilidade da adaptação dos algoritmos 
\ref{alg:bimn3logn} e~\ref{alg:bimn3} para considerar este novo conceito de 
pontuação das inversões.

Vale a pena lembrar que nos algoritmos para alinhamento com \dups\ já 
consideramos o tamanho da \rep\ na pontuação de uma \oped\ de \dup\ e excisão.

\section{Inversão com um nível de sobreposição}

Para o problema de encontrar o peso de um alinhamento com inversões, assumimos 
a simplificação da não sobreposição das inversões, ou seja, se uma região 
$s[i'\Rng i]$ é invertida para ser melhor alinhada com uma região $t[j'\Rng j]$ então 
nenhuma outra inversão será considerada nas regiões $s[i'\Rng i]$ e $t[j'\Rng j]$. 
Com esta simplificação qualquer letra da seqüência $s$ ou da seqüência $t$ pode 
estar contida em uma única operação de inversão.

Quando dizemos que pode haver até um nível de sobreposição, estamos querendo
dizer que qualquer letra da seqüência $s$ ou da seqüência $t$ pode estar
contida em até duas regiões que sofreram inversões.

Esta é uma outra visão para o problema do alinhamento com inversões. Esta nova 
visão foi motivada por uma teoria desenvolvida por Ross et al.\ 
\cite{Ross_et_al_2005} que diz que os cromossomos \emph{X} e \emph{Y} do ser 
humano podem diferir em 4 grandes inversões, além dos outros eventos menores de 
mutação do DNA (inclusive inversões). Assim, necessitaríamos analisar as 
seqüências considerando que algumas regiões podem ser invertidas duas vezes 
(uma pequena inversão e uma grande inversão).

\section[Rearranjos nas \reps]{Rearranjos nas \reps} Quando fazemos um 
alinhamento com \dups, consideramos que o alinhamento das \reps\ com a \seq\ 
original é uma alinhamento com somente \opeds\ pontuais (inserção, remoção e 
substituição). Acreditamos que seria interessante obter a pontuação de um 
\intrep\ utilizando outras \opeds, tais como, as \dups\ e as \invs. 

Para tanto, um trabalho a ser feito é a alteração dos algoritmos para a 
obtenção de pontuação de um alinhamento ótimo com \dups, ou a criação de 
algoritmos totalmente novos, que considerem estes rearranjos nos alinhamentos 
das \reps\ dos \intreps.

\section[Diminuir a memória utilizada]{Diminuir a memória utilizada pelos algoritmos}

Os algoritmos para a obtenção da pontuação de alinhamentos ótimos com 
\invnsobs\ ou \dups\ necessitam ambos de espaço de memória $O(n^2)$.

Um trabalho a ser feito é tentar desenvolver algoritmos que resolvam os mesmos 
problemas com a mesma complexidade no tempo de execução, mas uma melhor 
complexidade na utilização de memória.

\section[Análise e comparação dos tempos de execução]{Análise e comparação de
tempos de exe\-cu\-ção dos algoritmos}
Um trabalho a ser feito é verificar na prática as diferenças de tempo entre os
algoritmos~\ref{alg:bimn3logn} e~\ref{alg:bimn3}, ou
seja, implementar e executar os algoritmos contra seqüências reais de dados e
analisar os tempos de execução.

Na realidade este trabalho já começou a ser feito, pois uma implementação dos 
algoritmos~\ref{alg:bimn3logn} $(O(n^3 \log n))$ e~\ref{alg:bimn3} $(O(n^3))$  
já foi feita e alguns testes também, porém é necessário uma análise mais 
criteriosa do código implementado, assim como a obtenção de tempos de execução 
estatisticamente mais confiáveis.

Além destes algoritmos, também já foi implementado para fins de análise 
comparativa, os algoritmos descritos em \cite{MR2132586}, que têm tempo de execução
$O(n^4)$ e $O(n^4 \log^2 n / M^2)$, onde $M=(n^2/\#\ arestas)$ é o fator de
esparsidade. Em alguns testes que realizamos $M$ estava na ordem de grandeza de
$10^{-4}$. 

Verificamos, em testes preliminares que realizamos, que o algoritmo $O(n^3)$ foi
mais rápido, como já era esperado, que os algoritmos $O(n^4)$ e $O(n^3 \log n)$.

\section{Esparsidade}

Se um sistema de pontuação adota o valor zero para as operações de inserção, 
remoção e substituição com grau de similaridade abaixo de um certo limite, 
podemos obter um grafo de edição $G$ de $s$ e $t$ com poucas arestas diagonais 
com valores positivos. Se isto ocorre, o algoritmo não precisa verificar todos 
os vértices e todas as arestas de $G$ para obter o peso de um caminho ótimo de 
$(0,0)$ e $(n,m)$. Quanto menos arestas com peso positivo o grafo de edição 
tiver, mais esparso será o grafo.

Já existem algoritmos, como em \cite{MR2132586}, \cite{965960} e \cite{146656}, 
que se aproveitam da esparsidade do grafo de edição para obter um caminho ótimo 
no grafo.


O aproveitamento desta esparsidade mostrou-se bem útil em alguns testes
realizados com uma implementação do algoritmo esparso para a obtenção da
pontuação de um alinhamento ótimo com \invnsobs, descrito em
\cite{MR2132586}. Para alguns testes realizados, o tempo de execução foi centenas
de vezes mais rápido do que os algoritmos que não se aproveitavam desta
esparsidade.

Um trabalho futuro, é tentar adaptar os algoritmos para obter um alinhamento 
ótimo com \dups, com \dups\ em \emph{tandem} ou com \invnsobs\ a utilizarem 
a esparsidade do grafo de edição.

\clearpage
\bibliographystyle{plain}
\bibliography{tese}
\end{document}
